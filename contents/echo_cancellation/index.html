<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Echo Cancellation</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'>Echo Cancellation</h2>
 <div class='author'><a href='https://vicente-gonzalez-ruiz.github.io/'><span class='ecrm-1200'>Vicente González Ruiz</span></a> <span class='ecrm-1200'>&amp; </span><a href='https://hpca.ual.es/~savins/'><span class='ecrm-1200'>Savins Puertas Martín</span></a> <span class='ecrm-1200'>&amp; </span><a href='https://www.marcoslupion.com/'><span class='ecrm-1200'>Marcos Lupión Lorente</span></a></div><br />
<div class='date'><span class='ecrm-1200'>October 3, 2024</span></div>
   </div>
   <h3 class='sectionHead'><span class='titlemark'>1   </span> <a id='x1-10001'></a>The problem</h3>
<!-- l. 9 --><p class='noindent'>One of the first problems we encounter with the use the <span class='ectt-1000'>buffer.py</span>
module<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-1001f1'></a>
is that, if we don’t use headphones, the sound that comes out of our PC’s speaker
reaches our microphone some time later, and more some time later, that sound
reaches our interlocutor in the form of an echo, which is reproduced by his/her
speaker, which can be captured again (some time later) by his microphone and
sent it back to us ... and so on, generating a rather unpleasant feedback
(echo) signal. In other words, if \(\mathbf s\) is the (analog) signal played by our speaker
and that reaches our mic(rophone), \(\mathbf n\) is the signal emited by the “near-end”
person<span class='footnote-mark'><a href='#fn2x0' id='fn2x0-bk'><sup class='textsuperscript'>2</sup></a></span><a id='x1-1002f2'></a>
that reaches our mic (i.e., the same signal that would be captured by our mic if I
were using a headset), and \(\mathbf m\) is the (mixed) signal recorded by our microphone (when
the headset is not used), we have that
</p><!-- l. 29 --><p class='indent'>   \begin {equation}  m(t) = n(t) + s(t), \label {eq:echo_problem}  \end {equation}
where \(m(t)\) is the signal that hits the membrane of our mic.
</p><!-- l. 32 --><p class='indent'>   Our problem here is to minimize the energy of \(s(t)\).
</p><!-- l. 34 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>2   </span> <a id='x1-20002'></a>The trivial (and definitive) solution</h3>
<!-- l. 36 --><p class='noindent'>Use a headset. In this case, \begin {equation}  m(t) \approx n(t) \label {eq:headset_solution}  \end {equation}
because \(s(t)\approx 0\).
                                                                  

                                                                  
</p><!-- l. 43 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>3   </span> <a id='x1-30003'></a>The trivial (but limited) solution</h3>
<!-- l. 45 --><p class='noindent'>Decrease the gain of our speaker to do \(s(t)\approx 0\). Unfortunately this also decreases the volume
of the far-end signal (the voice of our interlocutor) :-/
</p><!-- l. 49 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>4   </span> <a id='x1-40004'></a>The simplest substract solution</h3>
<!-- l. 50 --><p class='noindent'>Lets \(\mathbf m\) the digital version of \(m(t)\) and \({\mathbf m}[t]\) it’s \(t\)-the
sample<span class='footnote-mark'><a href='#fn3x0' id='fn3x0-bk'><sup class='textsuperscript'>3</sup></a></span><a id='x1-4001f3'></a>.
In this solution, we send \begin {equation}  \tilde {\mathbf n}[i] = {\mathbf m}[i] - a{\mathbf s}[i-d], \label {eq:simplest}  \end {equation}
where \(a\) is an attenuation (scalar) value and \(d\) represents the delay (measured in
frame-times) required to propagate the sound from our speaker to our mic. We define
\begin {equation}  \hat {\mathbf e}[t] = a{\mathbf s}[i-d]  \end {equation}
as the estimated echo signal.
</p><!-- l. 65 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>5   </span> <a id='x1-50005'></a>Considering the frequency response of the near-end to estimate the echo
signal</h3>
<!-- l. 66 --><p class='noindent'>We can improve the performance of the echo cancellation process if we take also into
consideration that echo signal that finally reaches our mic is the convolution of \(s(t)\) and
the signal \(h(t)\) that represents the echo response of our local audioset (speaker, mic,
walls, monitor, keyboard, our body, etc.) to the impulse signal \(\delta (t)\). In other “words”, we
can compute \begin {equation}  \tilde {\mathbf n}[i] = {\mathbf m}[i] - ({\mathbf s}*{\mathbf h})[i-d], \label {eq:using_convolution}  \end {equation}
where \(*\) represents the convolution between digital signals, and \(\mathbf h\) is the digitalized
(discrete + quantized) version of \(h(t)\), the response of the near audioset to \(\delta (t)\).
</p><!-- l. 80 --><p class='indent'>   The convolution of digital signals in the time domain can be expensive
\((O^2\)) if the number of samples is high. Fortunately, thanks to the theorem of
the convolution of signals in the frequency domain <span class='cite'>[<a href='#Xkovacevic2013fourier'>1</a>, <a href='#XOppenheim2'>2</a>]</span>, the convolution
can be replaced by the dot product, when we consider the signals in the
frequency domain. Thanks to this, we can rewrite the Eq. \eqref{eq:simplest} as
\begin {equation}  \tilde {\mathbf n}[i] = {\mathbf m}[i] - {\mathcal F}^{-1}\{{\mathbf S}{\mathbf H}\}[i-d], \label {eq:simplest_and_faster}  \end {equation}
where \(\mathbf S\) is the Fourier transform<span class='footnote-mark'><a href='#fn4x0' id='fn4x0-bk'><sup class='textsuperscript'>4</sup></a></span><a id='x1-5001f4'></a>
of \(\mathbf s\), \(\mathbf H\) is the Fourier transform of \(\mathbf h\), and \({\mathcal F}^{-1}\) represents the inverse Fourier transform.
Notice that all these transforms are applied to digital signals, and there exist fast
algorithms (\(O\log _2O\)).
</p><!-- l. 103 --><p class='noindent'>
                                                                  

                                                                  
</p>
   <h3 class='sectionHead'><span class='titlemark'>6   </span> <a id='x1-60006'></a>Estimation of the echo signal using LMS (Least Mean Squares)</h3>
<!-- l. 105 --><p class='noindent'>The LMS (Least Mean Squares) algorithm is an algorithm designed to minimize the
mean square error of a target function. LMS is adaptive, which means that it suitable
when there are near-end acoustic variations. In the previous section we have
computed the near-end audioset impulse response using the frequency domain. In this
case, we will use the time domain, i.e., \begin {equation}  \hat {\mathbf e}[t] = \sum _{k=0}^{N-1}{\mathbf h}_k^{(t)}{\mathbf s}[t-k]  \end {equation}
where \(\mathbf h\) is the near-end impulse response and \(N\) is the length of the LMS filter.
</p><!-- l. 117 --><p class='indent'>   LMS minimizes the energy of the residue signal \begin {equation}  r[t] = {\mathbf m}[t] - {\mathbf n}[t-d]  \end {equation}
(the difference between the signal captured by the mic and the signal generated by
the near-end user) that ideally, after a delay of \(d\) samples (an input parameter of this
technique) should be the echo signal. More concretely, LMS minimizes \(E\{|r|^2_2\}\) (the
expectation of the square of \(r\)) using an interative algorithm where, in the iteration \(i\)
computes \begin {equation}  h^{(i+1)} = h^{(i)} + \mu r^{(i)}{\mathbf m}[i],  \end {equation}
where \begin {equation}  r^{(i)} = {\mathbf s}[i] - \hat {\mathbf e}[i],  \end {equation}
and \(\mu \) is the “learning rate” of the LMS algorithm.
</p><!-- l. 137 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>7   </span> <a id='x1-70007'></a>Deliverables</h3>
<!-- l. 139 --><p class='noindent'>A Python module called <span class='ectt-1000'>echo_cancellation.py </span>that inherits from <span class='ectt-1000'>buffer.py </span>and
that implements at least one of the previously described solutions. More
concretely:
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-7002x1'>If you implement the “delay and substract solution”, you must estimate
     \(a\), \(d\) and perform the signals substraction to remove the echo signal. For
     example, Skype finds \(d\) and \(a\) using a “call signal” (a sequence of more-or-less
     tonal sounds). \(d\) is determined measuring the propagation time of the call
     signal between our speaker and our mic, and \(a\) measuring the ratio between
     the  energy  of  the  call  signal  played  and  the  energy  of  the  call  signal
     recorded.
     </li>
<li class='enumerate' id='x1-7004x2'>If  you  also  consider  the  (discrete)  frequency  response  of  the  near-end
     audioset to estimate a better echo signal, first you will need to find \(\mathbf H\) (the
     discrete frequency response of the audioset). For this, the local-end speaker
     should generate an impulse signal \(\mathbf \delta \), and in absence of any other sound
     signal, record the echo and compute its Fourier transform. Likely, it is a
     good idea to repeat this process several times to obtain a better estimation
                                                                  

                                                                  
     of \(\mathbf H\). Finally, notice that \({\mathbf H}[\omega ]\) (the \(\omega \)-th frequency component of \(\mathbf H\)) is a complex
     number.
     </li>
<li class='enumerate' id='x1-7006x3'>In both cases (simple delay and substract solution and considering also
     the frequency response of the near-end audioset), the parameters that
     determine the estimation of the echo signal should be continously<span class='footnote-mark'><a href='#fn5x0' id='fn5x0-bk'><sup class='textsuperscript'>5</sup></a></span><a id='x1-7007f5'></a>
     monitored becase the physical composition of the near-end audioset can
     be dynamic (for example, the inclination of the screen of our laptop can
     be modified).
     </li>
<li class='enumerate' id='x1-7009x4'>Finally, try to use LMS to find a estimation of the echo signal that takes
     into consideration the impulse response of the local-end audioset.</li></ol>
<!-- l. 173 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>8   </span> <a id='x1-80008'></a>Resources</h3>
   <div class='thebibliography'>
   <p class='bibitem'><span class='biblabel'>
 [1]<span class='bibsp'>   </span></span><a id='Xkovacevic2013fourier'></a>J. Kovačević,  V.K.  Goyal,  and  M. Vetterli.   <a href='https://foundationsofsignalprocessing.org/FWSP_a3.2_2013.pdf'><span class='ecti-1000'>Fourier and Wavelet
   </span><span class='ecti-1000'>Signal Processing</span></a>. <a class='url' href='http://www.fourierandwavelets.org/'><span class='ectt-1000'>http://www.fourierandwavelets.org/</span></a>, 2013.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [2]<span class='bibsp'>   </span></span><a id='XOppenheim2'></a>Alan V. Oppenheim, Alan S. Willsky, and S. Hamid Nawab.  <a href='http://materias.df.uba.ar/l5a2021c1/files/2021/05/Alan-V.-Oppenheim-Alan-S.-Willsky-with-S.-Hamid-Signals-and-Systems-Prentice-Hall-1996.pdf'><span class='ecti-1000'>Signals
   </span><span class='ecti-1000'>and Systems (2nd edition)</span></a>. Prentice Hall, 1997.
</p>
   </div>
   <div class='footnotes'><!-- l. 11 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>And obviously, any other parent version of </span><span class='ectt-0800'>buffer.py</span><span class='ecrm-0800'>.</span></p>
<!-- l. 21 --><p class='indent'>     <span class='footnote-mark'><a href='#fn2x0-bk' id='fn2x0'><sup class='textsuperscript'>2</sup></a></span><span class='ecrm-0800'>Our interlocutor would be the “far-end” person.</span></p>
<!-- l. 51 --><p class='indent'>     <span class='footnote-mark'><a href='#fn3x0-bk' id='fn3x0'><sup class='textsuperscript'>3</sup></a></span><span class='ecrm-0800'>Or frame if we work in stereo</span></p><!-- l. 97 --><p class='indent'> <span class='footnote-mark'><a href='#fn4x0-bk' id='fn4x0'><sup class='textsuperscript'>4</sup></a></span><span class='ecrm-0800'>The Fourier transform is an special case of the Laplace transform where</span> \(\sigma =0\) <span class='ecrm-0800'>in the Laplace
</span><span class='ecrm-0800'>domain represented by the complex numbers</span> \(s=\sigma +j\omega \)<span class='ecrm-0800'>. This simplification can be used for the
</span><span class='ecrm-0800'>characterization of our local-end audioset because it can be considered a FIR (Finite
</span><span class='ecrm-0800'>Impulse Response) system (in ausence of an audio signal, the echo always decays with the
</span><span class='ecrm-0800'>time).</span></p>
<!-- l. 165 --><p class='noindent'><span class='footnote-mark'><a href='#fn5x0-bk' id='fn5x0'><sup class='textsuperscript'>5</sup></a></span><span class='ecrm-0800'>A 1-seconds cadence should be enought.</span></p>                                                                </div>
 
</body> 
</html>