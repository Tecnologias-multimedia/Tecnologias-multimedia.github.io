<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Echo Cancellation</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'>Echo Cancellation</h2>
 <div class='author'><a href='https://vicente-gonzalez-ruiz.github.io/'><span class='ecrm-1200'>Vicente González Ruiz</span></a> <span class='ecrm-1200'>&amp; </span><a href='https://www.marcoslupion.com/'><span class='ecrm-1200'>Marcos Lupión Lorente</span></a></div><br />
<div class='date'><span class='ecrm-1200'>October 14, 2023</span></div>
   </div>
   <h3 class='sectionHead'><span class='titlemark'>1   </span> <a id='x1-10001'></a>Description</h3>
<!-- l. 10 --><p class='noindent'>One of the first problems we encounter when we use the <span class='ectt-1000'>buffer.py</span>
version<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-1001f1'></a>
of InterCom is that if we don’t use headphones, the sound that comes out of our PC’s
speaker reaches our microphone and some time later, that sound reaches our
interlocutor in the form of an echo, which is reproduced by his speaker, which is
captured again by his microphone, and so on, until generating a rather unpleasant
feedback.
</p><!-- l. 19 --><p class='indent'>   One way to minimize this problem is (apart from using headphones) to
reduce as much as possible (as long as it is audible, of course) the gain of the
amplifier that feeds our speaker. Unfortunately, this is not always possible,
among other reasons, because if the volume is too low, we will not hear our
interlocutor.
</p><!-- l. 25 --><p class='indent'>   Another way is to subtract from the signal \(\mathbf m\) that our microphone picks up, the
signal that our speaker is reproducing \(\mathbf s\), resulting in an echo cancellation, and
therefore, of the coupling that it generates. The key in this process is to find
out:
</p><!-- l. 31 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-1003x1'>What delay \(d\) exists between the time the received signal \(\mathbf s\) is reproduced by
     our speaker until the said signal is captured by our ADC? This time will
     depend fundamentally on the distance between the speaker/s and the mic
     of our PC, and we can assume that it is constant.
                                                                  

                                                                  
     </li>
<li class='enumerate' id='x1-1005x2'>What attenuation \(a\) should be applied to \(\mathbf s\) to achieve the elimination of the
     sent signal.</li></ol>
<!-- l. 42 --><p class='indent'>   If we have calculated \(d\) and \(a\) correctly, echo cancellation will occur after performing
the operation \begin {equation}  {\mathbf c}_i = {\mathbf m}_i - a{\mathbf s}_{i+d},  \end {equation}
where \({\mathbf c}=\{{\mathbf c}_i\}\) is the signal sent with the echo cancelled.
</p><!-- l. 49 --><p class='indent'>   Since \(d\) depends exclusively on the physical configuration of our PC (assuming that
there are no other sources of echo, such as walls), we can estimate its value before
starting the conversation by locally generating a sound through our speaker that it is
easy to locate in time after being digitized by our microphone, and measuring with a
stopwatch the time that elapses from when the sound is reproduced until it is
registered again.
</p><!-- l. 57 --><p class='indent'>   To calculate \(a\) what we can do is to check if, in the absence of local sound (only
having the speaker as sound source), \({\mathbf c}\approx {\mathbf 0}\), or at least a sound where \(\mathbf s\) is not recognized.
Otherwise, the value of \(a\) is too high or too low and therefore, what we will do is
increase \(a\) and see if the <a href='https://en.wikipedia.org/wiki/Energy_(signal_processing)'>energy</a> <span class='cite'>[<a href='#Xvetterli2014foundations'>3</a>]</span> decreases, and if it doesn’t, then we will decrease \(a\).
In general we will never cancel the echo completely, but we should always
be able to find a value for \(a\) that minimizes the energy \(\mathbf c\) (as long as we are
silent).
</p><!-- l. 69 --><p class='indent'>   Notice that in this discussion we have supposed that the spectrums <span class='cite'>[<a href='#Xkovacevic2013fourier'>1</a>, <a href='#XOppenheim2'>2</a>]</span> of \(\mathbf s\) and \(\mathbf m\)
are identical. If this is not true, we should also compute the filter that should be
applied to \(\mathbf s\) to minimize the energy of \(\mathbf c\).
</p><!-- l. 74 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>2   </span> <a id='x1-20002'></a>Deliverables</h3>
<!-- l. 76 --><p class='noindent'>A Python module called <span class='ectt-1000'>cancel_echo.py </span>that inherits from <span class='ectt-1000'>buffer.py </span>and that
implements the previously presented idea.
</p><!-- l. 79 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>3   </span> <a id='x1-30003'></a>Resources</h3>
   <div class='thebibliography'>
   <p class='bibitem'><span class='biblabel'>
 [1]<span class='bibsp'>   </span></span><a id='Xkovacevic2013fourier'></a>J. Kovačević,  V.K.  Goyal,  and  M. Vetterli.   <a href='https://foundationsofsignalprocessing.org/FWSP_a3.2_2013.pdf'><span class='ecti-1000'>Fourier and Wavelet
   </span><span class='ecti-1000'>Signal Processing</span></a>. <a class='url' href='http://www.fourierandwavelets.org/'><span class='ectt-1000'>http://www.fourierandwavelets.org/</span></a>, 2013.
                                                                  

                                                                  
   </p>
   <p class='bibitem'><span class='biblabel'>
 [2]<span class='bibsp'>   </span></span><a id='XOppenheim2'></a>Alan V. Oppenheim, Alan S. Willsky, and S. Hamid Nawab.  <a href='http://materias.df.uba.ar/l5a2021c1/files/2021/05/Alan-V.-Oppenheim-Alan-S.-Willsky-with-S.-Hamid-Signals-and-Systems-Prentice-Hall-1996.pdf'><span class='ecti-1000'>Signals
   </span><span class='ecti-1000'>and Systems (2nd edition)</span></a>. Prentice Hall, 1997.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [3]<span class='bibsp'>   </span></span><a id='Xvetterli2014foundations'></a>M. Vetterli, J. Kovačević, and V.K. Goyal.  <a href='http://www.fourierandwavelets.org/FSP_v1.1_2014.pdf'><span class='ecti-1000'>Foundations of Signal
   </span><span class='ecti-1000'>Processing</span></a>. Cambridge University Press, 2014.
</p>
   </div>
<p><a id='Q1-1-4'></a></p>
   <div class='footnotes'><!-- l. 12 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>And obviously, any other parent version of </span><span class='ectt-0800'>buffer.py</span><span class='ecrm-0800'>.</span></p>                                        </div>
 
</body> 
</html>