<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Echo Cancellation</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'>Echo Cancellation</h2>
 <div class='author'><a href='https://vicente-gonzalez-ruiz.github.io/'><span class='ecrm-1200'>Vicente González Ruiz</span></a> <span class='ecrm-1200'>&amp; </span><a href='https://hpca.ual.es/~savins/'><span class='ecrm-1200'>Savins Puertas Martín</span></a> <span class='ecrm-1200'>&amp; </span><a href='https://www.marcoslupion.com/'><span class='ecrm-1200'>Marcos Lupión Lorente</span></a></div><br />
<div class='date'><span class='ecrm-1200'>September 28, 2024</span></div>
   </div>
   <h3 class='sectionHead'><span class='titlemark'>1   </span> <a id='x1-10001'></a>Description</h3>
<!-- l. 9 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.1   </span> <a id='x1-20001.1'></a>The simplified problem</h4>
<!-- l. 11 --><p class='noindent'>One of the first problems we encounter with the use the <span class='ectt-1000'>buffer.py</span>
module<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-2001f1'></a> is
that, if we don’t use headphones, the sound that comes out of our PC’s speaker reaches
our microphone and some time later, that sound reaches our interlocutor in the form of
an echo<span class='footnote-mark'><a href='#fn2x0' id='fn2x0-bk'><sup class='textsuperscript'>2</sup></a></span><a id='x1-2003f2'></a>,
which is reproduced by his/her speaker, which can be captured again by his
microphone, and so on, until generating a rather unpleasant feedback. In other words,
if \(\mathbf s\) is the signal played by the speaker, \(\mathbf n\) is the signal generated by the “near-end”
person<span class='footnote-mark'><a href='#fn3x0' id='fn3x0-bk'><sup class='textsuperscript'>3</sup></a></span><a id='x1-2005f3'></a>,
and \(\mathbf m\) is the signal recorded by our microphone, we have that \begin {equation}  {\mathbf m}_i = {\mathbf n}_i + a{\mathbf s}_{i-d}, \label {eq:echo_problem}  \end {equation}<a id='x1-2007r1'></a> where \({\mathbf m}_i\)
is the \(i\)-th sample of the signal \({\mathbf m} = \{{\mathbf m}_i\}\), \(a\) is a real number that expresses an
attenuation<span class='footnote-mark'><a href='#fn4x0' id='fn4x0-bk'><sup class='textsuperscript'>4</sup></a></span><a id='x1-2008f4'></a>,
and \(d\) is an integer number that indicates the delay (in
sample-times<span class='footnote-mark'><a href='#fn5x0' id='fn5x0-bk'><sup class='textsuperscript'>5</sup></a></span><a id='x1-2010f5'></a>)
that exists between when the received signal \(\mathbf s\) is reproduced by our speaker until such
signal is captured by our ADC (Analog Digital Converter).
</p><!-- l. 40 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.2   </span> <a id='x1-30001.2'></a>The trivial partial solution</h4>
                                                                  

                                                                  
<!-- l. 41 --><p class='noindent'>One way to minimize this problem<span class='footnote-mark'><a href='#fn6x0' id='fn6x0-bk'><sup class='textsuperscript'>6</sup></a></span><a id='x1-3001f6'></a>
is to reduce as much as possible (as long as it is audible, of course) the gain of the
amplifier that feeds our speaker(s). In terms of the Eq. \eqref{eq:echo_problem},
this means to make \(a\) close to zero. Unfortunately, this is not always possible, among
other reasons, because if the volume is too low, we will not hear our interlocutor (the
“far-end”).
</p><!-- l. 50 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.3   </span> <a id='x1-40001.3'></a>Delay-and-substract solution</h4>
<!-- l. 51 --><p class='noindent'>Another simple<span class='footnote-mark'><a href='#fn7x0' id='fn7x0-bk'><sup class='textsuperscript'>7</sup></a></span><a id='x1-4001f7'></a>
solution is to determine \(a\) and \(d\), and compute \begin {equation}  {\mathbf n}_i = {\mathbf m}_i - a{\mathbf s}_{i-d}. \label {eq:echo_cancellation}  \end {equation}<a id='x1-4003r2'></a>
</p><!-- l. 60 --><p class='indent'>   \(d\) can be found by measuring the time that a played signal spends to be recorded
by our mic, and \(a\) computing the ratio between the energies of \(\mathbf s\) (the played
signal) and \(\mathbf m\) (the recorded signal). For example, Skype finds \(d\) and \(a\) at the
beginning of the session using a “call signal” (a sequence of more-or-less tonal
sounds).
</p><!-- l. 67 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.4   </span> <a id='x1-50001.4'></a>Considering the frequency respose of the near audioset</h4>
<!-- l. 68 --><p class='noindent'>In general, Eq. \eqref{eq:echo_problem} is oversimplified because our local audioset
(speaker, mic, walls, our body, etc.) does not have a flat response in the frequency
domain. Therefore, a more realistic model of the echo effect is \begin {equation}  {\mathbf m}_i = {\mathbf n}_i + \{f({\mathbf s})\}_{i-d}, \label {eq:more_realistic_echo_problem}  \end {equation}<a id='x1-5001r3'></a> where \(f({\mathcal s})\) is a filtered
version of the signal \(\mathbf s\), in which some frequencies are partially attenuated
(notice that now there is a possiblely different \(a\)-value for each frequency of
\(\mathbf s\)).
</p><!-- l. 81 --><p class='indent'>   Now the problem (apart from finding \(d\), obviously) is how to determine \(f(\cdot )\). Again, a
simple way of doing this is to use a call signal to measure the frequency response
of the near-end audioset. For this, a good call signal can be a sequence of
impulses<span class='footnote-mark'><a href='#fn8x0' id='fn8x0-bk'><sup class='textsuperscript'>8</sup></a></span><a id='x1-5002f8'></a> of a sequence of
uniform random noise signals<span class='footnote-mark'><a href='#fn9x0' id='fn9x0-bk'><sup class='textsuperscript'>9</sup></a></span><a id='x1-5004f9'></a>.
Notice that the frequency response (the filter coefficients of \(f(\cdot )\)) can be found
comparing the flat spectrum signal \(\mathbf s\) generated by the speaker with the supposedly
non-flat spectrum of the signal \(\mathbf m\) captured by the microphone. To apply \(f(\cdot )\) we can
multiply \({\mathcal F}({\mathbf s})\) by the filter coefficients of \(f(\cdot )\) in the Fourier domain, being \({\mathcal F}(\cdot )\) the Fourier
Transform <span class='cite'>[<a href='#Xkovacevic2013fourier'>1</a>, <a href='#XOppenheim2'>2</a>]</span>.
</p><!-- l. 99 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.5   </span> <a id='x1-60001.5'></a>Continuous monitoring of \(d\) and \(f(\cdot )\)</h4>
                                                                  

                                                                  
<!-- l. 100 --><p class='noindent'>Both parameters can change if we change, for example, the inclination of the screen
of our laptop. Therefore, \(d\) and \(f(\cdot )\) (or only \(a\) in the case of using the simplified model
described in the Eq. \eqref{eq:echo_problem}) should be monitorized constantly,
maybe with a cadence of one second.
</p><!-- l. 106 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>2   </span> <a id='x1-70002'></a>Deliverables</h3>
<!-- l. 107 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-7002x1'>A  Python  module  called  <span class='ectt-1000'>echo_cancellation.py </span>that  inherits  from
     <span class='ectt-1000'>buffer.py </span>and that implements at least one of the previously described
     solutions.
     </li>
<li class='enumerate' id='x1-7004x2'>A  working  experimental  setup  using  a  “localhost  connection”  to  check
     the performance of your implementation. You will requested to run your
     experiment during the presentation.</li></ol>
<!-- l. 115 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>3   </span> <a id='x1-80003'></a>Resources</h3>
   <div class='thebibliography'>
   <p class='bibitem'><span class='biblabel'>
 [1]<span class='bibsp'>   </span></span><a id='Xkovacevic2013fourier'></a>J. Kovačević,  V.K.  Goyal,  and  M. Vetterli.   <a href='https://foundationsofsignalprocessing.org/FWSP_a3.2_2013.pdf'><span class='ecti-1000'>Fourier and Wavelet
   </span><span class='ecti-1000'>Signal Processing</span></a>. <a class='url' href='http://www.fourierandwavelets.org/'><span class='ectt-1000'>http://www.fourierandwavelets.org/</span></a>, 2013.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [2]<span class='bibsp'>   </span></span><a id='XOppenheim2'></a>Alan V. Oppenheim, Alan S. Willsky, and S. Hamid Nawab.  <a href='http://materias.df.uba.ar/l5a2021c1/files/2021/05/Alan-V.-Oppenheim-Alan-S.-Willsky-with-S.-Hamid-Signals-and-Systems-Prentice-Hall-1996.pdf'><span class='ecti-1000'>Signals
   </span><span class='ecti-1000'>and Systems (2nd edition)</span></a>. Prentice Hall, 1997.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [3]<span class='bibsp'>   </span></span><a id='Xvetterli2014foundations'></a>M. Vetterli, J. Kovačević, and V.K. Goyal.  <a href='http://www.fourierandwavelets.org/FSP_v1.1_2014.pdf'><span class='ecti-1000'>Foundations of Signal
   </span><span class='ecti-1000'>Processing</span></a>. Cambridge University Press, 2014.
                                                                  

                                                                  
</p>
   </div>
   <div class='footnotes'><a id='x1-2002x1.1'></a>
<!-- l. 13 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>And obviously, any other parent version of </span><span class='ectt-0800'>buffer.py</span><span class='ecrm-0800'>.</span></p><a id='x1-2004x1.1'></a>
<!-- l. 17 --><p class='indent'>     <span class='footnote-mark'><a href='#fn2x0-bk' id='fn2x0'><sup class='textsuperscript'>2</sup></a></span><span class='ecrm-0800'>Notice that the output of our speaker is the voice of our interlocutor.</span></p><a id='x1-2006x1.1'></a>
<!-- l. 22 --><p class='indent'>     <span class='footnote-mark'><a href='#fn3x0-bk' id='fn3x0'><sup class='textsuperscript'>3</sup></a></span><span class='ecrm-0800'>Our interlocutor would be the “far-end” person.</span></p><a id='x1-2009x1.1'></a>
<!-- l. 33 --><p class='indent'>     <span class='footnote-mark'><a href='#fn4x0-bk' id='fn4x0'><sup class='textsuperscript'>4</sup></a></span><span class='ecrm-0800'>Usually,</span> \(a&lt;1\) <span class='ecrm-0800'>because in general the amount of signal that our micro captures from our speaker
</span><span class='ecrm-0800'>is smaller (in </span><a href='https://en.wikipedia.org/wiki/Energy_(signal_processing)'><span class='ecrm-0800'>energy</span></a><span class='ecrm-0800'> </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xvetterli2014foundations'><span class='ecrm-0800'>3</span></a><span class='ecrm-0800'>]</span></span><span class='ecrm-0800'>) than the signal</span> \(\mathbf s\)<span class='ecrm-0800'>.</span></p><a id='x1-2011x1.1'></a>
<!-- l. 36 --><p class='indent'>     <span class='footnote-mark'><a href='#fn5x0-bk' id='fn5x0'><sup class='textsuperscript'>5</sup></a></span><span class='ecrm-0800'>A sample-time is the interval of time that separates two consecutive samples (or frames) and
</span><span class='ecrm-0800'>depends on the sampling frequency.</span></p><a id='x1-3002x1.2'></a>
<!-- l. 42 --><p class='indent'>     <span class='footnote-mark'><a href='#fn6x0-bk' id='fn6x0'><sup class='textsuperscript'>6</sup></a></span><span class='ecrm-0800'>Apart from using headphones, which is by far the better solution.</span></p><a id='x1-4002x1.3'></a>
<!-- l. 53 --><p class='indent'>     <span class='footnote-mark'><a href='#fn7x0-bk' id='fn7x0'><sup class='textsuperscript'>7</sup></a></span><span class='ecrm-0800'>The AEC (Audio Echo Cancellation) problem has been extensively estudied and there are
</span><span class='ecrm-0800'>several solutions. This one is probably the simplest one.</span></p><a id='x1-5003x1.4'></a>
<!-- l. 87 --><p class='indent'>     <span class='footnote-mark'><a href='#fn8x0-bk' id='fn8x0'><sup class='textsuperscript'>8</sup></a></span><span class='ecrm-0800'>A impulse generates a flat </span><a href='https://en.wikipedia.org/wiki/Spectral_density'><span class='ecrm-0800'>spectrum</span></a><span class='ecrm-0800'> </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xkovacevic2013fourier'><span class='ecrm-0800'>1</span></a><span class='ecrm-0800'>, </span><a href='#XOppenheim2'><span class='ecrm-0800'>2</span></a><span class='ecrm-0800'>]</span></span> <span class='ecrm-0800'>for a short period of time.</span></p><a id='x1-5005x1.4'></a>
<!-- l. 90 --><p class='indent'>     <span class='footnote-mark'><a href='#fn9x0-bk' id='fn9x0'><sup class='textsuperscript'>9</sup></a></span><span class='ecrm-0800'>Uniform random noise (or </span><a href='https://en.wikipedia.org/wiki/White_noise'><span class='ecrm-0800'>white noise</span></a><span class='ecrm-0800'>) has a flat spectrum.</span></p>                                 </div>
 
</body> 
</html>