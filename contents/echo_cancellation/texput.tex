% Emacs, this is -*-latex-*-

\title{Feedback supression}

\maketitle

\section{The problem}

One of the first problems we encounter with the use of the
\texttt{buffer.py} module\footnote{And obviously, any other parent
  version of \texttt{buffer.py}.} is that, if we don't use headphones,
the sound that comes out of our PC's speaker reaches our mic(rophone)
some time later, and more some time later, that sound reaches our
interlocutor (the ``far-end'' ... in the system we are the
``near-end'') in the form of an echo (signal), which is reproduced by
his/her speaker, which can be captured again (some time later) by his/her
mic and sent it back to us ... and so on, generating a rather
unpleasant signal. In other words, if ${\mathbf s}$ is the (analog)
signal played by our (loud)speaker and that reaches our mic,
${\mathbf n}$ is the signal emited by the near-end person (I) that
reaches our mic\footnote{I.e., the same signal that would be captured
  by our mic if I were using a headset.}, and ${\mathbf m}$ is the
(mixed) signal recorded by our microphone, we have that
\begin{equation}
  m(t) = n(t) + s(t),
  \label{eq:echo_problem}
\end{equation}
where $m(t)$ is the analog audio signal that hits the membrane of our mic.

Our problem here is to minimize the
\href{https://en.wikipedia.org/wiki/Energy_(signal_processing)}{energy}
of $s(t)$, i.e., to make
\begin{equation}
  s(t)\approx 0.
\end{equation}

\section{The trivial (and definitive) solution}

Use a \href{https://en.wikipedia.org/wiki/Audio_headset}{headset}. In
this case,
\begin{equation}
  m(t) \approx n(t)
  \label{eq:headset_solution}
\end{equation}
because $s(t)\approx 0$.

\section{The trivial (but limited) solution}

Decrease the gain of the amplifier of your speaker to do (the energy
of) $s(t)$ as small as possible. Unfortunately this also decreases the
volume of the far-end signal (the voice of our interlocutor) :-/

\section{The simplest subtract solution}
Lets ${\mathbf m}$ the digital version of $m(t)$ and ${\mathbf m}[t]$
it's $t$-th sample\footnote{Or frame if we work in stereo}. In this
solution, we send
\begin{equation}
  \tilde{\mathbf n}[t] = {\mathbf m}[t] - a{\mathbf s}[t-d],
  \label{eq:simplest}
\end{equation}
where $a$ is an attenuation (scalar) value, and $d$ represents the
delay\footnote{In a digital signal the sample index indicates the
  position of the sample in the sequence of samples. If we also know
  the sample-time, i.e., the cadency of the sampler, we can also
  compute at which time was taken a sample.} (measured in
sample-times) required to propagate the sound from our speaker to our
mic. We define
\begin{equation}
  \hat{\mathbf f}[t] = a{\mathbf s}[t-d]
\end{equation}
as the estimated\footnote{We use the word ``estimated'' because in
  this model we are ignoring several factors, such as echoes, unflat
  frequency responses, etc.  that modify the version of $\mathbf{s}$
  that is received by the microphone.} feedback signal.

Notice that we have used the symbol $\tilde{}$ to highlight that
$\tilde{\mathbf n}$ will be an approximation of ${\mathbf n}$.

\section{Considering the frequency response of the near-end to estimate feedback signal}
We can improve the performance of the feedback cancellation process if
we take also into consideration that the feedback signal that finally
reaches our mic is the
\href{https://en.wikipedia.org/wiki/Convolution}{convolution} of
$s(t)$ and a signal $h(t)$ that represents the echo response of our
local audioset (speaker, mic, walls, monitor, keyboard, our body,
etc.) to a impulse signal $\delta(t)$.\footnote{This technique is
  similar to the carried out by submarines when they user the sonar to
  perform echo-location, or by bats to fly in the darkness.} In other
words, we can compute
\begin{equation}
 \tilde{\mathbf n}[t] = {\mathbf m}[t] - ({\mathbf s}*{\mathbf h})[t-d],
  \label{eq:using_convolution}
\end{equation}
where $*$ represents the convolution between (in our case of) digital
signals, and ${\mathbf h}$ is the digitalized (discrete + quantized)
version of $h(t)$, the response (echo) of the near-end audioset to the
impact of $\delta(t)$.

The convolution of digital signals in the time domain can be expensive
(with
\href{https://en.wikipedia.org/wiki/Computational_complexity_theory}{computational
  complexity} $O^2$, where $O$ is the number of elements to process)
if the number of samples or/and filter coefficientsis is
high. Fortunately, thanks to the
\href{https://en.wikipedia.org/wiki/Convolution}{theorem of the
  convolution} of signals in the frequency
domain~\cite{kovacevic2013fourier,Oppenheim2}, the convolution can be
replaced by the \href{https://en.wikipedia.org/wiki/Dot_product}{dot
  product} (with complexity $O$), when we consider the signals in the
frequency domain. Thanks to this, we can rewrite the
Eq.~\eqref{eq:using_convolution} as
\begin{equation}
  \tilde{\mathbf n}[t] = {\mathbf m}[t] - ({\mathcal F}^{-1}\{{\mathbf S}{\mathbf H}\})[t-d],
  \label{eq:faster}
\end{equation}
where ${\mathbf S}$ is the (digital) Fourier transform\footnote{The
  Fourier transform is an special case of the Laplace transform where
  $\sigma=0$ in the complex (Laplace) domain represented by
  $s=\sigma+j\omega$ frequencies. This simplification can be used for
  the characterization of our near-end audioset because it can be
  considered as a FIR (Finite Impulse Response) system (in ausence of
  an audio signal, the echo signal always decays with the time).} of
${\mathbf s}$, ${\mathbf H}$ is the Fourier transform of
${\mathbf h}$, and ${\mathcal F}^{-1}$ represents the inverse Fourier
transform. Notice that all these transforms are applied to digital
signals, and there exist fast algorithms (with complexity $O\log_2O$).

\section{Estimation of the feedback signal using LMS (Least Mean Squares)}
We just have seen how it is possible to find better estimations of the
feedback signal $\hat{\mathbf f}$ using convolutions. By definition,
convolutions are performed by filters. 

As we have seen, filters can be implemented in the frequency domain or
in the signal (time in our case) domain. Signal domain (digital)
convolutions are efficient when the length\footnote{The number of
  coefficients.} of the (digital) filters is small.\footnote{Take in
  mind that convolution is a $O^2$ operation, and therefore, we can
  only handle in real-time with our computers small filter.} For
estimating the feedback signal at the sample-time $t$,
${\mathbf f}[t]$, the length of a
\href{https://en.wikipedia.org/wiki/Finite_impulse_response}{FIR
  filter} should be at least $d$, because at least we need $d$ samples
to detect the feedback signal. Therefore, we have that
\begin{equation}
  \hat{\mathbf f}[t] = \sum_{k=0}^{d-1}{\mathbf h}_k^{(t)}{\mathbf s}[t-k],
  \label{eq:LMS_feedback}
\end{equation}
where ${\mathbf h}$ is the near-end impulse response in the time
domain.

Also, as we have seen in the previous section, it is possible to adapt
the filter to the acoustic conditions, measuring the echo generated by
the impulse signal. In the time domain, one of the most used
techniques for computing the coefficients of a FIR filter is the
\href{https://en.wikipedia.org/wiki/Least_mean_squares_filter}{LMS
  (Least Mean Squares)
  algorithm}~\cite{haykin1995adaptive,boyd2004convex}, among other
reasons because the filter (coefficients) can be adapted to variations
in the signal to filter (the filter can learn).

LMS was invented by professor Bernard Widrow and his first
Ph.D. student, Ted Hoff, to train the
\href{https://en.wikipedia.org/wiki/ADALINE}{ADALINE} artificial
neural network.\footnote{See
  \url{https://www.youtube.com/watch?v=hc2Zj55j1zU}} Using LMS,
ADALINE is able to distinguish between patterns, even
using a part of a single neuron.\footnote{If we do not consider the
  \href{https://en.wikipedia.org/wiki/Activation_function}{activation
    function}, an artificial neuron and a FIR filter perform the same
  computation.}

LMS can be used to compute the coefficients of a filter to provide a
desired output for a given input. In our
context, the input signal is ${\mathbf m}$ (the digital signal
recorded by our soundcard) and the desired output signal is
${\mathbf n}$ (the digital version of our voice). LMS, iteratively
computes
\begin{align}
  {\mathbf h}^{(i+1)}_k & = & {\mathbf h}^{(i)}_k + 2\mu\tilde{\mathbf n}[i]{\mathbf s}[i-k] \label{eq:update} \\
  \tilde{\mathbf n}[i] & = & {\mathbf m}[i] - \hat{\mathbf e}[i],
\end{align}
where $i$ represents the iteration number, and $\mu$ is the learning
rate\footnote{High $\mu$ values spped-up the adaption process, but can
  generate worse $\mathbf{h}$ coefficients.}. These equations can be
found\footnote{Again, see
  \url{https://www.youtube.com/watch?v=hc2Zj55j1zU}!} using the
(steepest)
\href{https://en.wikipedia.org/wiki/Gradient_descent}{gradient descend
  algorithm}. Notice that we process the signals sample-by-sample (at
iteration $i$ we compute the $i$-th sample of $\tilde{\mathbf n}$ (the
signal without the feedback, supposely containing \emph{only} our
voice), and this is the signal that we will send to the far-end in the
next chunk).

\section{Deliverables}

A Python module called \texttt{feedback\_cancellation.py} that inherits
from \texttt{buffer.py} and that implements at least\footnote{More
  working implementations, higher grade.} one of the previously
described solutions. More concretely:

\begin{enumerate}

\item If you implement the ``$s(t)$ delay and subtract solution'',
  you must estimate $a$, $d$ and perform the signals subtraction to
  remove the feedback signal ($s(t)$). For example, Skype finds
  $d$ and $a$ using a ``call-signal'' (a sequence of more-or-less
  tonal sounds). $d$ is determined measuring the propagation time of
  the call-signal between our speaker and our mic, and $a$ measuring
  the ratio between the energy of the call-signal played and the
  energy of the call-signal recorded.

\item In a ``$s(t)$ delay and subtract solution'', if you also
  consider the frequency response of the near-end audioset to estimate
  a better feedback signal, first you will need to find ${\mathbf H}$ (the
  discrete frequency response of your audioset). For this, the
  near-end speaker should generate an impulse signal
  ${\mathbf \delta}$, and in absence of any other sound signal, record
  the echo and compute its Fourier transform (it is a good idea to
  repeat this process several times to obtain a better estimation of
  ${\mathbf H}$). Finally, notice that ${\mathbf H}[\omega]$ (the
  $\omega$-th frequency component of ${\mathbf H}$) is a complex
  number (the Fourier coefficients are complex numbers).

  Notice that the frequency characterization of the far-end audioset
  can be also used in a ``$n(t)$ delay and subtract
  solution''. Remember that filtering operations must be implemented
  with convolutions in the temporal domain, but are dot products in
  the frequency domain.
  
\item Use LMS to find a estimation of the echo signal and perform the
  echo cancellation. In this case, consider the use of a thread to
  compute the coefficients of the LMS filter
  (Equation~\eqref{eq:update} can run with a cadence much higher than
  a sample-time) and compute the estimated feedback signal
  (Equation~\eqref{eq:LMS_feedback}) for every chunk. Notice that for
  doing that, we will require the first $k$ samples of the next chunk.
\end{enumerate}

Optionally, but interesting for your mark, use any other technique
(for example, an artificial neural network\footnote{ADALINE is the
  simplest
  \href{https://en.wikipedia.org/wiki/Neural_network_(machine_learning)}{AAN}
  ever developed!}) for estimating the echo, and use it for removing
the echo (obviously, in real-time). Take also into consideration that
the parameters that determine the estimation of the echo signal should
be continously\footnote{A 1-seconds cadence should be enought.}
monitored becase the physical composition of the audiosets can
be dynamic (for example, the inclination of the screen of our laptop
can be modified at any moment).

Finally, notice that signals
\href{https://en.wikipedia.org/wiki/Correlation}{correlation}
operation can help to fine-tune $d$.

\section{Resources}

\bibliography{signal_processing,optimization}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \begin{comment}
  At the same time you can also implement a ``$n(t)$ delay and
  subtract solution'', where you have to estimate $a$ for your voice
  $n(t)$ delayed the buffering time + average RTT + $d$ at the
  far-end. The average RTT can be estimated using\footnote{Remember
    that \texttt{ping} only works between public devices.} a local
  clock, storing in a list when the last $N$ chunks were sent, and
  sending with each chunk a new field in the packet header with the
  last chunk number that was received. Thus, when we receive the chunk
  $n$-th\footnote{Remember that the chunks have a chunk number in the
    packet header.}, we can copy this number in the next sent chunk
  and the receiver will be able to find the RTT subtracting to the
  time reception the corresponding time in the list.
  \end{comment}


\begin{comment}
http://www.seas.ucla.edu/dsplab/index.html
https://es.mathworks.com/help/signal/ug/echo-cancelation.html
https://dsp.stackexchange.com/questions/26617/echo-cancelling-using-autocorrelation-function
https://pypi.org/project/adaptfilt/
http://www.diva-portal.org/smash/get/diva2:280596/fulltext01
https://github.com/ThomasHaubner/e2e_dnn_ad_control_for_lin_aec
https://scicoding.com/4-ways-of-calculating-autocorrelation-in-python/



where ${\mathbf m}[i]$ is the $i$-th sample of the signal
${\mathbf m} = \{{\mathbf m}[i]\}$, $a$ is a real number that expresses
an attenuation\footnote{Usually, $a<1$ because in general the amount
  of signal that our micro captures from our speaker is smaller (in
  \href{https://en.wikipedia.org/wiki/Energy_(signal_processing)}{energy}~\cite{vetterli2014foundations})
  than the signal ${\mathbf s}$.}, and $d$ is an integer number that
indicates the delay (in sample-times\footnote{A sample-time is the
  interval of time that separates two consecutive samples (or frames)
  and depends on the sampling frequency.}) that exists between when
the received signal ${\mathbf s}$ is reproduced by our speaker until
such signal is captured by our ADC (Analog Digital Converter).

\section{The trivial partial solution}
One way to minimize this problem\footnote{Apart from using headphones,
  which is by far the better solution.} is to reduce as much as
possible (as long as it is audible, of course) the gain of the
amplifier that feeds our speaker(s). In terms of the
Eq.~\eqref{eq:echo_problem}, this means to make $a$ close to
zero. Unfortunately, this is not always possible, among other reasons,
because if the volume is too low, we will not hear our interlocutor
(the ``far-end'').


\section{Delay and subtract solution}

Another simple\footnote{The AEC (Audio Echo Cancellation) problem has
  been extensively estudied and there are several solutions. This one
  is probably the simplest one.} solution is to determine $a$ and $d$,
and compute
\begin{equation}
  {\mathbf n}[i] = {\mathbf m}[i] - a{\mathbf s}[i-d].
  \label{eq:echo_cancellation}
\end{equation}

$d$ can be found by measuring the time that a played signal spends to
be recorded by our mic, and $a$ computing the ratio between the
energies of ${\mathbf s}$ (the played signal) and ${\mathbf m}$ (the
recorded signal). For example, Skype finds $d$ and $a$ at the
beginning of the session using a ``call signal'' (a sequence of
more-or-less tonal sounds).

\subsection{Considering the frequency respose of the near-end audioset}
In general, Eq.~\eqref{eq:echo_problem} is oversimplified because our
local audioset (speaker, mic, walls, our body, etc.) does not have a
flat response in the frequency domain. Therefore, a more realistic
model of the echo effect is
\begin{equation}
   {\mathbf m}[i] = {\mathbf n}[i] + \{f({\mathbf s})\}[i-d],
  \label{eq:more_realistic_echo_problem}
\end{equation}
where $f({\mathcal s})$ is a filtered version of the signal
${\mathbf s}$, in which some frequencies are partially attenuated
(notice that now there is a possiblely different $a$-value for each
frequency of ${\mathbf s}$).

Now the problem (apart from finding $d$, obviously) is how to
determine $f(\cdot)$. Again, a simple way of doing this is to use a
call signal to measure the frequency response of the near-end
audioset. For this, a good call signal can be a sequence of
impulses\footnote{A impulse generates a flat
  \href{https://en.wikipedia.org/wiki/Spectral_density}{spectrum}~\cite{kovacevic2013fourier,Oppenheim2}
  for a short period of time.} of a sequence of uniform random noise
signals\footnote{Uniform random noise (or
  \href{https://en.wikipedia.org/wiki/White_noise}{white noise}) has a
  flat spectrum.}. Notice that the frequency response (the filter
coefficients of $f(\cdot)$) can be found comparing the flat spectrum
signal ${\mathbf s}$ generated by the speaker with the supposedly
non-flat spectrum of the signal ${\mathbf m}$ captured by the
microphone. To apply $f(\cdot)$ we can multiply
${\mathcal F}({\mathbf s})$ by the filter coefficients of $f(\cdot)$
in the Fourier domain, being ${\mathcal F}(\cdot)$ the Fourier
Transform~\cite{kovacevic2013fourier,Oppenheim2}.


Lets $H(s)$ the representation of $h(t)$ in the frequency (Laplace)
domain, where $s=\sigma+j\omega$ is a complex number that denotes a
frequency component.

If we consider that $h(t)$ in the frequency domain is denoted by
$H(s)$, (when $s=\sigma+j\omega$ we say that $H(s)$ is the Laplace
Transform of $h(t)$), that $S(s)$ is the representation in the
frequency domain of the signal $s(t)$, and that in our specific case,
where our near-end audioset is a FIR (Finite Impulse Response)
system\footnote{In ausence of an audio signal, the echo always decays
  with the time.}, we can also characterize it using the Fourier
Transform (where $sigma=0$), i.e., we can say that $H(j\omega)$ (the
Fourier Transform of $h(t)$) describes our local audioset from a
frequency perspective. Considering now the convolution theorem in the
Fourier domain, we can rewrite the Eq.~\eqref{eq:simplest} as
\begin{equation}
  \tilde{\mathbf n}[i] = {\mathbf m}[i] - {\mathbf h}({\mathbf S}{\mathbf H})[i-d],
  \label{eq:simplest2}
\end{equation}
where ${\mathbf S}$ is the Fast Discrete Fourier Transform of
${\mathbf s}$ and ${\mathbf H}$ is the Fast Discrete Fourier Transform
of ${\mathbf h}$, and ${\mathcal F}^{-1}$ represents the Fast Inverse
Discrete Fourier Transform.

Therefore, as it can be seen in Eq.~\eqref{eq:simplest2}, to find the
echo signal we need to mulplity  ${\mathbf S}$ (the played signal in the Fourier
domain) by ${\mathbf H}$ (the frequency response of the near-end
audioset).

The LMS (Least Mean Squares) algorithm is an algorithm designed to
minimize the mean square error of a target function.


LMS is adaptive,
which means that it suitable when there are near-end acoustic
variations. In the previous section we have computed the near-end
audioset impulse response using the frequency domain. In this case, we
will use the time domain, i.e.,
\begin{equation}
  \hat{\mathbf e}[t] = \sum_{k=0}^{N-1}{\mathbf h}_k^{(t)}{\mathbf s}[t-k]
\end{equation}
where ${\mathbf h}$ is the near-end impulse response and $N$ is the
length of the LMS filter.

LMS minimizes the energy of the residue signal
\begin{equation}
  r[t] = {\mathbf m}[t] - {\mathbf n}[t-d]
\end{equation}
(the difference between the signal captured by the mic and the signal
generated by the near-end user) that ideally, after a delay of $d$
samples (an input parameter of this technique) should be the echo
signal. More concretely, LMS minimizes $E\{|r|^2_2\}$ (the expectation
of the square of $r$) using an interative algorithm where, in the
iteration $i$ computes
\begin{equation}
  h^{(i+1)} = h^{(i)} + \mu r^{(i)}{\mathbf m}[i],
\end{equation}
where
\begin{equation}
  r^{(i)} = {\mathbf s}[i] - \hat{\mathbf e}[i],
\end{equation}
and $\mu$ is the ``learning rate'' of the LMS algorithm.


\end{comment}
