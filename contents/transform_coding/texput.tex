% Emacs, this is -*-latex-*-

\title{\href{https://en.wikipedia.org/wiki/Transform_coding}{Transform Coding} for \href{https://en.wikipedia.org/wiki/Data_redundancy}{Redundancy} Removal}

% Use 16 bits/coefficient and CTE (Chunk Truncation Encoding).

\maketitle
\tableofcontents

%{{{

\section{Spatial (stereo) decorrelation with the MST (Mid/Side Transform)}
%{{{

\subsection{Analysis transform}
%{{{ 
InterCom transmits a
\href{https://en.wikipedia.org/wiki/Stereophonic_sound}{stereo} (two
channels)
\href{https://en.wikipedia.org/wiki/Pulse-code_modulation}{PCM
  signal}. In most cases, the channels are
\href{https://en.wikipedia.org/wiki/Binaural_recording}{highly
  correlated}\footnote{Especially when the microphone is mono because both
channels are identical}, which means that we can find a more efficient
representation. To perform this inter-channel
\href{https://en.wikipedia.org/wiki/Decorrelation}{decorrelation}~\cite{thinkstats}
we can use the \href{https://en.wikipedia.org/wiki/Linear_map}{linear
  transform}~\cite{strang4linear}
\begin{equation}
  {\mathbf w} = {\mathbf K}{\mathbf x} =
\begin{bmatrix} \mathbf{K}_0 \\ \mathbf{K}_1 \end{bmatrix}{\mathbf x} =
\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}
{\mathbf x},
  \label{eq:forward_transform_matrix_form}
\end{equation}
that can also be written as
\begin{equation}
  \begin{bmatrix}
    {\mathbf w}_0 \\
    {\mathbf w}_1
  \end{bmatrix}
  = 
  \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}
  \begin{bmatrix}
    {\mathbf x}_0 \\
    {\mathbf x}_1
  \end{bmatrix},
  \label{eq:forward_transform_matrix_form2}
\end{equation}
where ${\mathbf x}\in\mathbb{Z}^2$ is a stereo frame, ${\mathbf K}$ is
the forward (or analysis) transform matrix, and
${\mathbf w}=\begin{bmatrix} {\mathbf w}_0 & {\mathbf
    w}_1\end{bmatrix}^{\text T}$ is the corresponding
\href{https://en.wikipedia.org/wiki/Discrete_wavelet_transform}{decomposition}. In
this particular transform, the decomposition has two
\href{https://en.wikipedia.org/wiki/Sub-band_coding}{subbands}
${\mathbf w}_0$ and ${\mathbf w}_1$, and each subband has only one
\href{https://web.stanford.edu/class/ee398a/handouts/lectures/07-TransformCoding.pdf}{coefficient} per frame. Notice
that ${\mathbf x}\in\mathbb{Z}^2$ is a vector space\footnote{Adding
  two vectors in the plane produces a third one also in the plane;
  multiplying a vector by a real scalar produces a second vector also
  in the plane. These two ingrained facts make the integer/real plane be a
  vector space.~\cite{vetterli2014foundations}} if we consider also
the required operations.

The proposed matrix ${\mathbf K}$ corresponds to the transform used in
\href{https://en.wikipedia.org/wiki/Joint_encoding#M/S_stereo_coding}{Mid/Side
  (M/S) stereo coding}~\cite{bosi2003intro} that we will call MST
(Mid/Side Transform). This is similar to the $2\times 2$ KLT
\href{https://en.wikipedia.org/wiki/Kosambi%E2%80%93Karhunen%E2%80%93Lo%C3%A8ve_theorem}{(Karhunen-Lo\`eve
  Transform)}, the
\href{http://wavelets.pybytes.com/wavelet/haar/}{Haar Transform} and
the $2\times 2$
\href{https://en.wikipedia.org/wiki/Hadamard_transform}{Discrete
  Walsh-Hadamard
  Transform}~\cite{sayood2017introduction,vetterli1995wavelets}.

In general (for all linear transforms),
Eqs.~\eqref{eq:forward_transform_matrix_form} and
\eqref{eq:forward_transform_matrix_form2} can also be expressed as
\begin{equation}
  {\mathbf w}_u = \sum_i {\mathbf K}_{u,i}{\mathbf x}_i,
  \label{eq:forward_transform_linear_combination_form}
\end{equation}
where ${\mathbf K}_{u,i}$ denotes the $i$ -th element of the $u$-th row of
the matrix ${\mathbf K}$.

A major difference between the transformed data ${\mathbf w}$ and the
original data ${\mathbf x}$ is that the characteristics of the
elements of ${\mathbf w}$ are determined by their position within the
decomposition ${\mathbf w}$~\cite{sayood2017introduction}. Thus, as a
consequence of how the matrix has been defined, the subband ${\mathbf
  w}_0$ represents (very roughly) the low frequencies of (the sequence) ${\mathbf
  x}$, and ${\mathbf w}_1$ the high frequencies. Therefore, the values
of ${\mathbf K}_0$ (the row 0 of ${\mathbf K}$) describe a
\href{https://en.wikipedia.org/wiki/Low-pass_filter}{low-pass filter},
the values of ${\mathbf K}_1$ describe a
\href{https://en.wikipedia.org/wiki/High-pass_filter}{high-pass
  filter}, and ${\mathbf K}$ represents the
\href{https://en.wikipedia.org/wiki/Digital_filter}{filters} of a
\href{https://en.wikipedia.org/wiki/Filter_bank}{filter bank (FB)} with two
filters. This can also be seen in the notebook
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/contents/transform_coding/stereo_transforms_RD.ipynb}{A RD-comparison of ``Stereo'' Transforms}.
%}}}

\subsection{Synthesis transform}
%{{{ 
The inverse (or synthesis) transform
\begin{equation}
  {\mathbf x} = {\mathbf K}^{-1}{\mathbf w}
  \label{eq:inverse_transform}
\end{equation}
can be deduced from Eq.~\eqref{eq:forward_transform_matrix_form}, where we have that
\begin{equation}
  \begin{array}{rcl}
  {\mathbf w}_0 & = & {\mathbf x}_0 + {\mathbf x}_1\\
  {\mathbf w}_1 & = & {\mathbf x}_0 - {\mathbf x}_1.
  \end{array}
\end{equation}
By solving ${\mathbf x}_0$ (adding) and ${\mathbf x}_1$ (subtracting) in
these equations, we obtain that
\begin{equation}
  \begin{array}{rcl}
  {\mathbf x}_0 & = & \frac{1}{2}({\mathbf w}_0 + {\mathbf w}_1)\\
  {\mathbf x}_1 & = & \frac{1}{2}({\mathbf w}_0 - {\mathbf w}_1),
  \end{array}
\end{equation}
that in matrix form becomes
\begin{equation}
  \begin{bmatrix}
    {\mathbf x}_0 \\
    {\mathbf x}_1
  \end{bmatrix}
  = \frac{1}{2}
  \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}
  \begin{bmatrix}
    {\mathbf w}_0 \\
    {\mathbf w}_1
  \end{bmatrix}.
\end{equation}
Therefore,
\begin{equation}
  {\mathbf x} = {\mathbf K}^{-1}{\mathbf w} = \frac{1}{2}{\mathbf K}^{\text T}{\mathbf w} = \frac{1}{2}{\mathbf K}{\mathbf w} = \frac{1}{2}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}{\mathbf w} = \begin{bmatrix} \frac{1}{2} & \frac{1}{2} \\ \frac{1}{2} & -\frac{1}{2} \end{bmatrix}{\mathbf w}.
  \label{eq:inverse_transform_matrix_form}
\end{equation}
%}}}

\subsection{Orthogonality of the transform}
%{{{ 
As can be seen (if we ignore the $\frac{1}{2}$ scale factor),
the inverse transform is the transpose of the forward transform
(${\mathbf K}^{-1}={\mathbf K}^{\text T}$). This is a characteristic
of all
\href{https://en.wikipedia.org/wiki/Orthogonal_transformation}{orthogonal
  transforms}~\cite{sayood2017introduction}. For the MST,
specifically, it also holds that ${\mathbf K}^{\text T}={\mathbf K}$
because ${\mathbf K}$ is
\href{https://en.wikipedia.org/wiki/Symmetric_matrix}{symmetric}.

In addition to verify that ${\mathbf K}^{-1}={\mathbf K}^{\text T}$,
${\mathbf K}$ is orthogonal if the
\href{https://en.wikipedia.org/wiki/Inner_product_space}{inner
  product}\footnote{The inner product between two vectors is in some
  sense a measure of how ``similar'' they are
  \cite{sayood2017introduction}. In fact, the dot product computes the
  norm (a measure of the distance between
  vectors).~\cite{vetterli2014foundations} Notice also, that the inner
  product is
  \href{https://math.stackexchange.com/questions/476738/difference-between-dot-product-and-inner-product}{also
    called} the \href{https://en.wikipedia.org/wiki/Dot_product}{dot
    product} and the scalar product when we work with
  \href{https://en.wikipedia.org/wiki/Real_number}{real}
  signals.~\cite{vetterli2014foundations}} of the
filters\footnote{When we are working with discrete signals, we usually
  talk about vectors instead of functions. These vectors are sampled
  versions of the corresponding functions, or as happen in our case,
  the
  \href{https://en.wikipedia.org/wiki/Finite_impulse_response}{coefficients}
  of the filters, each one representing a
  \href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis
    vectors}.} of ${\mathbf K}$ is $0$ between the different filters
(rows of the matrix)\footnote{If a set of vectors are linearly
  independent, then the set is called a basis for the subspace
  generated by linear combinations of this set. The basis set contains
  the smallest number of linearly independent vectors required to
  represent each element of the vector (sub)space. The number of basis
  vectors required to generate the space is called the dimension of
  the vector space~\cite{sayood2017introduction}. In our case, for the
  MST, we have two basis vectors.}. In our case
${\mathbf K}_0=\begin{bmatrix}1 & 1\end{bmatrix}$~ and
${\mathbf K}_1=\begin{bmatrix} 1 & -1\end{bmatrix}$~, and as we can
see
\begin{equation}
  \langle {\mathbf K}_0,{\mathbf K}_1 \rangle =
  \langle \begin{bmatrix}
    1 & 1
  \end{bmatrix}
  ,
  \begin{bmatrix}
    1 & -1
  \end{bmatrix}
  \rangle =
  \begin{bmatrix}
    1 & 1
  \end{bmatrix}
  \cdot
  \begin{bmatrix}
    1 & -1
  \end{bmatrix}
   = 1\times 1 + 1\times (-1) = 0,
\end{equation}
which means that the filters ${\mathbf K}_0$ and ${\mathbf K}_1$ are linearly
independent\footnote{In terms of orthogonality, this means that we
  cannot derive one from the other using the operations that define a
  vector space, and therefore the basis vectors can be a part a basis
  (set)~\cite{strang4linear}.}.

Notice also that
\begin{equation}
  {\mathbf w}_i = \langle {\mathbf x}, {\mathbf K}_i\rangle,
\end{equation}
which basically means\footnote{Remember that for the MST a subband has
  only one coefficient. For other transforms, ${\mathbf w}_i$ can be
  made up of more than one coefficient and therefore we would be
  speaking of the subband coefficients, instead of only one
  coefficient.} that ${\mathbf w}_i$ is proportional to the similarity
between the input signal ${\mathbf x}$ and the
\href{https://en.wikipedia.org/wiki/Finite_impulse_response}{coefficients} of
the filter ${\mathbf K}_i$. These
\href{https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf}{slides}
can help you with this key idea.

Orthogonality is important in compression applications because the
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{statistical
  correlation} between the subbands is 0, and therefore the
contributions of the subbands to the reconstruction of the original
signal ${\mathbf x}$ are independent\footnote{The total
  \href{https://en.wikipedia.org/wiki/Distortion}{distortion} is the
  sum of the distortion contribution of each
  subband~\cite{sayood2017introduction}.}. Another interesting
property satisfied by many famous transforms (such as the
\href{https://en.wikipedia.org/wiki/Fourier_transform}{Fourier
  Transform}) is also
\href{https://en.wikipedia.org/wiki/Orthonormality}{orthonormality},
which means that the transform is
\href{https://en.wikipedia.org/wiki/Energy_(signal_processing)}{energy}
preserving~\cite{sayood2017introduction} (or that the
\href{https://en.wikipedia.org/wiki/Parseval%27s_theorem}{Parseval's
  theorem} is satisfied, in both, the analysis and the synthesis
transform).

The MST is not orthonormal, because
\begin{equation}
  \sum_i {{\mathbf w}_i}^2 =
  ({\mathbf x}_0 + {\mathbf x}_1)^2 + ({\mathbf x}_0 - {\mathbf x}_1)^2 =
  ({\mathbf x}_0^2 + 2{\mathbf x}_0{\mathbf x}_1+{\mathbf x}_1^2) + ({\mathbf x}_0^2-2{\mathbf x_0}{\mathbf x}_1+{\mathbf x}_1^2) =
  2({\mathbf x}_0^2+{\mathbf x}_1^2) =
  2\sum_i {{\mathbf x}_i}^2.
  \label{eq:No_Parseval}
\end{equation}
For this reason, we must divide the synthesized samples by $2$ (see
Eq.~\eqref{eq:inverse_transform_matrix_form}). On the contrary, we
would get $2{\mathbf x}$ as the reconstructed signal instead of
${\mathbf x}$.
%}}}

\subsection{Quantization of the subbands}
\label{sec:quantization_subbands_spatial}
% {{{

Ideally, the QSS (Quantization Step Size) $\Delta_i$ used for a
subband ${\mathbf w}_i$ must operate in the RD curve $f_i$ with the
same slope as the rest of the
subbands~\cite{vetterli2014foundations,sayood2017introduction} (this
is the same as saying that we must satisfy $f'_0(x)=f'_1(x)$, where
$f'$ denotes the derivative of $f$). The main drawback of this
approach is that the finding of $f_i$ is computationally intensive (we
must analyze, quantize, compress, decompress, dequantize, synthesize,
and compute the distortion of the data for a sufficiently high number
of quantization steps), and usually we cannot do that in real
time.\footnote{This would solve the problem of controlling the
  bit-rate because using the RD curves we know how many bits will
  require each subband.} Notice that we can use this optimal
quantization scheme because the subbands are indepent one of the
other, and this is true because the transforms are orthogonal.

\begin{comment}
  An approximation to this could be to suppose that the RD curves of
  the subbands resulting from the analysis of our current
  piece\footnote{Remember, two samples of a stereo frame in our case
    because we are removing the spatial redundancy.} of data are
  similar to some the curves of previous pieces, that has already been
  compressed and transmitted, and therefore, we can compute also the
  distortion. Using this information, we can estimate a RD curve for
  the current piece and estimate the ``optimal'' QSSs. This procedure
  is much faster than the procedure described in the previous paragraph, but it
  may still be time consuming.
\end{comment}

For this reason, in the notebook
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/contents/transform_coding/stereo_transforms_RD.ipynb}{A
  RD-comparison of ``Stereo'' Transforms} we explore a different
solution based on the idea that the contribution (in terms of energy)
of the subbands to the reconstruction of the signal ${\mathbf x}$
should be proportional to the
\href{https://en.wikipedia.org/wiki/Filter_(signal_processing)}{gain}
of each synthesis\footnote{Notice that the quantization error is
  generated in the transform domain and perceived in the signal domain
  after appliying the inverse transform.} filter of ${\mathbf K}^{-1}$
(recall that we work with orthogonal transforms and, therefore, the contributions of the subbands are independent). Thus, if
the filters had different gains, the QSSs should consider this fact
using a smaller QSS where the gain is higher.\footnote{Notice that the
  important here is the relative gain of each subband. For example, if
  the gain of ${\mathbf K}_0^{-1}$ were $2$ and the gain of
  ${\mathbf K}_1^{-1}$ were $1$, we should use $\Delta_1=2\Delta_0$ to
  minimize the distortion, because a quantization error of a
  coefficient in $\mathbf{w}_0$ is two times the quantization error of
  a coefficient in $\mathbf{w}_0$.}

By definition, the contribution of the subband ${\mathbf w}_i$ to the reconstruction of the frame  is
proportional to the
\href{https://en.wikipedia.org/wiki/Lp_space}{L$^2$
  norm}\footnote{L$_2(f)$ (where $f$ is a function) is the set of all
  functions with finite energy and constitues a vector
  space~\cite{sayood2017introduction}. $L_2({\mathbb R})$ of simply
  $L_2$ is the space of all functions $f(t)$ with a well defined
  integral of the square of the modulus of the function. The $L$
  signifies a Lebesque integral, the ``2'' denotes the integral of the
  square of the modulus of the function, and ${\mathbb R}$ states that
  the independent variable of integration is a number over the whole
  real line. For a function $g(t)$ to be a member of that space is
  denoted: $g\in L^2({\mathbb R})$ or simply
  $g\in L^2$~\cite{burrus2013wavelets}. The computation of the L$^2$
  form is equivalent to compute the
  \href{https://en.wikipedia.org/wiki/Euclidean_distance}{Euclidean
    distance} in $N$-dimensional (in our case, $N=2$)
  \href{https://en.wikipedia.org/wiki/Vector_space}{spaces}.} (or the
``squared'' norm) of the (synthesis) filter ${\mathbf K}_i^{-1}$. Thus
\begin{equation}
  \begin{array}{l}
    \left\| {\mathbf K}_0^{-1} \right\|_2 := \sqrt{\langle \begin{bmatrix} \frac{1}{2} & \frac{1}{2} \end{bmatrix}, \begin{bmatrix} \frac{1}{2} & \frac{1}{2} \end{bmatrix} \rangle} = \sqrt{\begin{bmatrix}\frac{1}{2} & \frac{1}{2} \end{bmatrix} \cdot \begin{bmatrix} \frac{1}{2} & \frac{1}{2} \end{bmatrix}} = \frac{1}{\sqrt{2}},\\
    \left\| {\mathbf K}_1^{-1} \right\|_2 := \sqrt{\langle \begin{bmatrix} \frac{1}{2} & -\frac{1}{2} \end{bmatrix}, \begin{bmatrix} \frac{1}{2} & -\frac{1}{2} \end{bmatrix} \rangle} = \sqrt{\begin{bmatrix} \frac{1}{2} & -\frac{1}{2} \end{bmatrix}\cdot \begin{bmatrix} \frac{1}{2} & -\frac{1}{2} \end{bmatrix}} = \frac{1}{\sqrt{2}},
  \end{array}
\end{equation}
resulting in the fact that both subbands ${\mathbf w}_1$ and ${\mathbf w}_2$ have
the same gain ($1/\sqrt{2}$). This result tells us that both subbands
could use the same quantization step size ($\Delta_0=\Delta_1$). In
the notebook
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/contents/transform_coding/stereo_transforms_RD.ipynb}{A
  RD-comparison of "Stereo" Transforms} there is some evidence of
this.

Unfortunately, most of the transforms are not implemented using
matrix-vector operations, but using
\href{https://en.wikipedia.org/wiki/Fast_Fourier_transform}{faster
  algorithms} based on a lattice of
\href{https://en.wikipedia.org/wiki/Butterfly_diagram}{computational
  bufferflies} or filter
\href{https://en.wikipedia.org/wiki/Filter_(signal_processing)}{convolutions}
(and therefore, we do not know ${\mathbf K}$). Fortunately, we can
determine ${\mathbf K}_i^{-1}$ (and therefore, ${\mathbf K}$) by simply computing the inverse transform of
the decomposition
$\begin{bmatrix} 0 & \cdots & 0 & 1 & 0 & \cdots &
  0 \end{bmatrix}^{\text T}$, where the $1$ value is in the position
$i$ (only the subband ${\mathbf w}_i=1$, the rest are
``zeroed'').\footnote{Notice that this operation will ``extract'' the
  $i$-th column from ${\mathbf K}^{-1}$ that is equivalent to say that
  will ``extract'' the $i$-th row of ${\mathbf K}$, ${\mathbf K}_i$
  (remember that for orthogonal transforms,
  ${\mathbf K}^{-1}={\mathbf K}^{\text T}$).} In our example, we get
that

\begin{equation}
  \begin{array}{l}
    {\mathbf K}_0^{-1} = \frac{1}{2}
    \begin{bmatrix}
      1 & 1 \\
      1 & -1
    \end{bmatrix} 
          \begin{bmatrix}
            1 \\
            0
          \end{bmatrix}
    =  \frac{1}{2}
    \begin{bmatrix}
      1 & 1
    \end{bmatrix},
    \\
    {\mathbf K}_1^{-1} =  \frac{1}{2}
    \begin{bmatrix}
      1 & 1 \\
      1 & -1
    \end{bmatrix}
          \begin{bmatrix}
            0 \\
            1
          \end{bmatrix}
    =  \frac{1}{2}
    \begin{bmatrix}
      1 & -1
    \end{bmatrix}.
  \end{array}
\end{equation}
\begin{comment}
that, as you can see, correspond to the columns of the inverse
transform matrix ${\mathbf K}^{-1}$. Notice that this is true for all orthogonal transforms whose analysis and synthesis matrices are symmetric. % because in that case ${\mathbf K}^{-1}={\mathbf K}^{\text T}$.
\end{comment}

As a final remark, we could also consider that any alternative other
than $\Delta_0=\Delta_1$ will affect to the quality and the spatial
perception of the audio in a different degree. The notebook
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/contents/transform_coding/stereo_transforms_RD.ipynb}{A
  RD-comparison of "Stereo" Transforms} gives more information about
this.

%}}}

%}}}

\section{Temporal decorrelation using the DWT (Discrete Wavelet Transform)}
%{{{

\subsection{About temporal redundancy in audio}
%{{{

After exploiting spatial (stereo) redundancy, the next natural step in
the development of InterCom is to remove the temporal redundancy that
can be found inside of each subband\footnote{Here it is supposed that
  the MST has been used before. Notice that, beacuse the MST and the
  transform used in this milestone are both lineal, the order in which
  the transforms are applied is irrelevant. For this reason, we could
  also have used the temporal transform inside of each channel of
  samples, and then, remove the spatial redundancy.}. As it can be
seen in the notebook
\href{https://github.com/Tecnologias-multimedia/intercom/blob/master/tools/audio_viewer.ipynb}{Audio
  Viewer}, most audio signals show ``patterns'' of samples that tend
to repeat, especially locally. Another clear source of temporal
redundancy is that neighboring audio samples usually show similar
amplitude values.

% A decorrelating technique: DPCM
There are several techniques that can be used to remove the
temporal redundancy of a sequence of audio. One of the most
straightforward is
\href{https://en.wikipedia.org/wiki/Differential_pulse-code_modulation}{Differential
  Pulse Code Modulation
  (DPCM)~\cite{sayood2017introduction}}. However, there are more
efficient decorrelation algorithms based on
\href{https://en.wikipedia.org/wiki/Transform_coding}{Transform
  Coding}, such as the one described in the previous and in this
section.

% Another decorrelating technique: transform coding
As it has been explained before, Transform Coding is based on the idea
that we can decompose the input signal into a set of subbands, and if
the filters used are appropriate to remove the (in this case,
temporal) redundancy, we can achieve a high Transform Coding
Gain~\cite{sayood2017introduction}, accumulating the most of the
signal energy (and presumably most of the information) in a small
number of subbands. When this happens, the quantization of the
subbands will basically remove the least significant information
(usually
\href{https://en.wikipedia.org/wiki/Noise_(electronics)}{electronic
  noise}), allowing better compression ratios than those in which we
apply the same quantization process to the original
samples.\footnote{Notice that is we dead-zone quantize a decomposition
  and most of the coefficients are close to zero, the information
  removed from the signal will be those with a smaller energy.}

%}}}

\subsection{Subband Coding}
%{{{

% Relation between transform coding and subband coding

\href{https://en.wikipedia.org/wiki/Sub-band_coding}{Subband
  Coding}\footnote{\href{https://en.wikipedia.org/wiki/Sub-band_coding}{In
    signal processing, sub-band coding (SBC) is any form of transform
    coding that breaks a signal into a number of different frequency
    bands}.} is a particular case of Transform Coding where the rows
of the transform matrix are the coefficients\footnote{In theory, such
  rows could be any mathematical operation, not necessarily a filter.}
of digital filters that are used without splitting the signal into
blocks. In this context, our analysis transform matrix ${\mathbf K}$
(see the previous section) represents the coefficients of a 2-channels
analysis \href{https://en.wikipedia.org/wiki/Filter_bank}{Filter Bank
  (FB)}~\cite{vetterli1995wavelets}, and the forward transform is in
fact ``descomposing'' ${\mathbf x}$ into two subbands ${\mathbf w}_0$
and ${\mathbf w}_1$ (see the Figure~\ref{fig:PRFB}, and the notebook
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/contents/transform_coding/PRFB.ipynb}{A
  Perfect Reconstruction Filter Bank (PRFB)}). On the other hand, the
synthesis transform matrix ${\mathbf K}^{-1}$ denotes the coefficients
of the corresponding synthesis FB that allows to recover ${\mathbf x}$
from $\{{\mathbf w}_i\}$ (notice that in the figure,
${\mathbf x}={\mathbf l}^i$, ${\mathbf w}_0={\mathbf l}^{i+1}$,
${\mathbf w}_1={\mathbf h}^{i+1}$, $\tilde\phi={\mathbf K}_0$,
$\tilde\psi={\mathbf K}_1$, $\phi={\mathbf K}^{-1}_0$, and
$\psi={\mathbf K}^{-1}_1$) from ${\mathbf w}$.

\begin{figure}
  \centering
  \myfig{graphics/PRFB}{3.5cm}{350}
  \caption{A 2-channels PRFB (Perfect Reconstruction Filter Bank).}
  \label{fig:PRFB}
\end{figure}

% An intro to PRFBs
Let us suppose now that the analysis filters (represented by the
coefficients of) ${\mathbf K}_0$ and ${\mathbf K}_1$ are applied to
the input signal ${\mathbf x}$ (now a sequence of $N$ samples) using a
\href{https://en.wikipedia.org/wiki/Kernel_(image_processing)}{convolution}
(without splitting $\mathbf{x}$ into blocks as happens in Transform
Coding). Let us also suppose (as happens in the MST) that
${\mathbf K}_0$ is a low-pass filter and ${\mathbf K}_1$ is a
high-pass filter, and that the
\href{https://en.wikipedia.org/wiki/Filter_(signal_processing)}{frequency
  response}\footnote{The response (in the frequency domain) of the
  filter to the
  \href{https://en.wikipedia.org/?title=Unit_impulse&redirect=no}{unit
    impulse}.} of both filters
\href{https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks}{are
  one the inverse of the other}. Under these assumptions, the complete
(analysis/synthesis) transform is called a (2-channels)
\href{https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks}{Perfect
  Reconstruction Filter Bank (PRFB)}, and ${\mathbf x}$ can be
recovered (perfectly) from a subsampled version (in this case
\href{https://en.wikipedia.org/wiki/Downsampling_(signal_processing)}{decimating}
by 2 because we have two channels in the FB) of ${\mathbf w}_0$ and
${\mathbf w}_1$ (see the notebook
\href{https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/PRFB.ipynb}{A
  Perfect Reconstruction Filter Bank (PRFB)}).\footnote{Notice that
  this subsampling is possible because the
  \href{https://en.wikipedia.org/wiki/Aliasing}{aliasing} generated in
  the low-pass subband is attenuated by the aliasing generated in the
  high-pass subband. Notice also that the filters are not ideal, the
  bandwidth of the filtered signals ${\mathbf w}_0$ and
  ${\mathbf w}_1$ is bigger than half of the bandwidth of
  ${\mathbf x}$. Therefore, subsampling at a ratio of one of each two
  coefficients, we are generating aliasing. See the
  \href{https://en.wikipedia.org/wiki/Nyquist-Shannon_sampling_theorem}{sampling
    theorem}.} To achieve this, the
\href{https://en.wikipedia.org/wiki/Filter_(signal_processing)}{frequency
  response} of ${\mathbf K}_0$ must be equal to the mirrored frequency
response of ${\mathbf K}_1,$ and obviously both filters must have the
same
\href{https://en.wikipedia.org/wiki/Bandwidth_(signal_processing)}{bandwidth}~\cite{sayood2017introduction}. In
this situation, in which ${\mathbf K}_0$ and ${\mathbf K}_1$ are
mirror filters, we say that they form a
\href{https://en.wikipedia.org/wiki/Quadrature_mirror_filter}{Quadrature
  Mirror Filters (QMF) Bank}.

%}}}

\subsection{Multichannel filter banks and psychoacoustic frequency resolution}
%{{{

% M-channels PRFB and the frequency resolution of the HAS
Using the suitable filters, it is possible to build $M$-channels
PRFBs.\footnote{Notice that our matrix $K$ would have $M$ rows in this
  case, and also $M$ columns, to satisfy that
  ${\mathbf K}^{-1}={\mathbf K}^{\text T}$ if we are implementing an
  orthogonal transform.}  These filters can analyze (and synthesize)
the signal ${\mathbf x}$, decomposing it in
(\href{https://en.wikipedia.org/wiki/Low-pass_filter#Ideal_and_real_filters}{almost
  for sure}) overlaping frequency subbands with different
bandwidth. The question here is to know how many filters should be
used and what
\href{https://en.wikipedia.org/wiki/Band-pass_filter}{pass-band} width
should they have. At this design point, we must also consider that the
accuracy of the
\href{https://en.wikipedia.org/wiki/Psychoacoustics}{human perception
  of the sound} depends on the frequency (as can be
checked\footnote{You need to generate tonal sounds with different
  frequency and amplitudes.} with the notebook
\href{https://github.com/Tecnologias-multimedia/InterCom/blob/master/tools/tonal_generator.ipynb}{Tonal
  Generator}) we are more sensitive to frequency variations when the
frequency of the sound is low\footnote{And also, we are more sensitive
  to low frequencies that to high ones.}. This fact is related to
the way in which the
\href{https://en.wikipedia.org/wiki/Critical_band}{critical bands} are
distributed in \href{https://en.wikipedia.org/wiki/Bark_scale}{the
  Bark Scale}.

%}}}

\subsection{The Discrete Wavelet Transform}
%{{{

% The bark scale and the DWT
As can be seen, the Bark Scale divides the audible spectrum into 24
subbands of (a priori) ``whimsical'' bandwidths. However, it is clear
that a \href{https://en.wikipedia.org/wiki/Octave_band}{dyadic
  partition of the audible spectrum} fits better than
\href{https://en.wikipedia.org/wiki/Wavelet_transform#Principle}{a
  lineal partition}. Considering this reason, from all the families of
transforms designed to date, the most suitable one, from a frequency
partitioning point of view, is the Discrete Wavelet Transform (DWT).

% Features of the DWT
The DWT has also other interesting features:
\begin{enumerate}
\item It is
  \href{https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Time_complexity}{fast}
  ($O(N)$, where $N$ is the number of ``transformed'' samples).
\item It can represent efficienty
  \href{https://en.wikipedia.org/wiki/Transient_(oscillation)}{transient}
  signals, which can occur frequently in audio.
\item Although we are not going to take advantage of the following
  characteristic (for now), one of the most interesting features of
  the DWT is that it can used to find a
  \href{https://en.wikipedia.org/wiki/Multiresolution_analysis}{multiresolution
    representation} of the signal.
\end{enumerate}

%}}}

\subsection{Implementation of the DWT}
%{{{

% Implementation alternatives for the DWT
The DWT can be implemented in different ways:

\begin{enumerate}

\item Defining the transform matrix ${\mathbf K}$ (see these
  \href{https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf}{slides})
  and computing matrix-vector multiplications, which requires a
  calculation time proportional to $O(N^2)$. However, the main problem
  of this type of implementation is generated by the amount of memory
  that ${\mathbf K}$ requires, which is proportional to $N^2$.

\item
  \href{https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Cascading_and_filter_banks}{Cascading
    PRFBs} (see the Figure~\ref{fig:cascade}). Considering that the
  \href{https://en.wikipedia.org/wiki/Convolution}{convolution} is a
  $O(N\log_2N)$ operation (if it is
  \href{https://en.wikipedia.org/wiki/Convolution_theorem}{implemented
    in the frequency domain}), and that the number of levels in the
  cascade is generally small (5, for example), this implementation is
  faster than the based on vector-matrix arithmetic. And most
  importantly, we do not need to store ${\mathbf K}$, but only the coefficients
  of the different filters that are used.\footnote{Notice that in a
    typical cascade, the filters are always the same. Therefore, we
    only need to store in memory only a copy of each different filter.}

\begin{figure}
  \centering
  \myfig{graphics/cascade}{8cm}{800}
  \caption{A dyadic 2-levels cascade of PRFBs.}
  \label{fig:cascade}
\end{figure}

\item Using
  \href{https://en.wikipedia.org/wiki/Lifting_scheme}{lifting}~\cite{sweldens1997building},
  which provides an additional speed-up factor of 2 compared to the FB
  implementation. DWTs implemented with lifting do not need to
  downsample and upsample the subbands, an operation that is wasting
  the calculus of half of the wavelet coefficients at each level of
  the cascade.

\end{enumerate}

%}}}

\subsection{Example of a DWT using the MST filters}
%{{{

% Using the MST filters for building a DWT
In order to clarify the concepts introduced above, let us build a
DWT using the MST filters and lifting.

\begin{enumerate}

\item Lifting is based on the concept of dyadic
  \href{https://en.wikipedia.org/wiki/Multiresolution_analysis}{multiresolution
    analysis}, and also related to the so called
  \href{https://en.wikipedia.org/wiki/Polyphase_matrix}{polyphase
    representation} of signals. To do that, we can rewrite
  the MST filter equations (our ${\mathbf K}_0$ and ${\mathbf K}_1$
  filters in the previous section) as
  \begin{equation}
    \begin{array}{rcl}
      {\mathbf l}^1_i & = & {\mathbf x}_{2i} + {\mathbf x}_{2i+1} \\
      {\mathbf h}^1_i & = & {\mathbf x}_{2i+1} - {\mathbf x}_{2i},
    \end{array}
    \label{eq:1dwt}
  \end{equation}
  where the $l$-th subband
  ${\mathbf w}^l=\{{\mathbf w}_i^l~|~0\le i\le 2^{n-l}\}$, being
  $2^n=N$ the number of samples in ${\mathbf x}$, and where, by
  definition, ${\mathbf l}^0={\mathbf x}$, is the original resolution
  level of the signal. The subbands ${\mathbf l}^1$ and
  ${\mathbf h}^1$ computed by Eq.~\eqref{eq:1dwt} are the same than
  the decimated subbands computed by the corresponding 1-level PRFB,
  and we say, therefore, that Eq.~\eqref{eq:1dwt} computes the
  1-level DWT.

  Based on the 1-level DWT, we define the 2-levels DWT as
  \begin{equation}
    \begin{array}{rcl}
      {\mathbf l}^2_i & = & {\mathbf l}^1_{2i} + {\mathbf l}^1_{2i+1} \\
      {\mathbf h}^2_i & = & {\mathbf l}^1_{2i+1} - {\mathbf l}^1_{2i},
    \end{array}
    \label{eq:2dwt}
  \end{equation}
  that, as we can see, uses as input the output of Eq.~\eqref{eq:1dwt}.

  In general, for a $l$-levels DWT, we get
    \begin{equation}
    \begin{array}{rcl}
      {\mathbf l}^l_i & = & {\mathbf l}^{l-1}_{2i} + {\mathbf l}^{l-1}_{2i+1} \\
      {\mathbf h}^l_i & = & {\mathbf l}^{l-1}_{2i+1} - {\mathbf l}^{l-1}_{2i}.
    \end{array}
    \label{eq:ldwt}
  \end{equation}

  The $l$-levels DWT splits the signal spectrum into $l+1$ subbands. If
  $l=n$, where $N=2^n$, we have the spectrum partition
  \begin{equation*}
        | \mathbf{l}^l_0 | \mathbf{h}^l_0 | \mathbf{h}^{l-1}_0 \mathbf{h}^{l-1}_1 | \mathbf{h}^{l-2}_0 \mathbf{h}^{l-2}_1 \mathbf{h}^{l-2}_2 \mathbf{h}^{l-2}_3 | \cdots | \mathbf{h}^1_0 \mathbf{h}^1_1 \cdots \mathbf{h}^1_{2^{n-1}-1} |,
  \end{equation*}
  holding\footnote{The wavelet coefficient ${\mathbf l}^l_0$ is called the DC
    (Direct Current) coefficient, and the rest of ${\mathbf h}$
    coefficients are called AC (Alternating Current) coefficients.} that
  \begin{equation}
    1+\sum_{j=1}^l 2^{j-1}=2^n,
  \end{equation}
  i.e., the number of DWT coefficients is also $N$.

\item All DWT perform a number of lifting steps, each one with
  2 (sub)steps:
  \begin{enumerate}
  \item A \textbf{predict step}, which computes the ${\mathbf h}$
    subbands as a prediction error (that in general should be
    minimized) between the even samples (usually, the values used to
    predict) and the odd samples (usually, the values predicted). For
    the MST filters, we have that (see Eq.~\eqref{eq:ldwt})
    \begin{equation}
      {\mathbf h}^l_i = {\mathbf l}^{l-1}_{2i+1} - {\mathbf l}^{l-1}_{2i}.
    \end{equation}
    
  \item An \textbf{update step}, which computes the ${\mathbf l}$
    subband considering (only) the even samples and the prediction
    errors. For the MST, we have that (see also Eq.~\eqref{eq:ldwt})
    \begin{equation}
      {\mathbf l}^l_i = 2{\mathbf l}^{l-1}_{2i} + {\mathbf h}^l_i.
    \end{equation}
  \end{enumerate}

  Notice that these steps are invertible:
  \begin{equation}
    \begin{array}{rcl}
      {\mathbf l}^{l-1}_{2i} & = & \frac{1}{2}({\mathbf l}^l_i - {\mathbf h}^l_i)\\
      {\mathbf l}^{l-1}_{2i+1} & = & {\mathbf l}^{l-1}_{2i} + {\mathbf h}^l_i.
    \end{array}
  \end{equation}

\end{enumerate}

%}}}

\subsection{Wavelets and filter banks}
%{{{

In the context of wavelet theory~\cite{burrus2013wavelets}, the
response of the low-pass analysis filter (${\mathbf K}_0$ in MST)
to the
\href{https://en.wikipedia.org/?title=Unit_impulse&redirect=no}{unit
  impulse}\footnote{The response of a filter to the unit impulse
characterize the filter because the output of the filter is the set of
coefficients of the filter.} is known as \emph{scaling function} and is
usually denoted by $\tilde\phi$, the response of the analysis
high-pass filter (${\mathbf K}_1$) is known as the \emph{wavelet
function} and it is usually denoted by $\tilde\psi$, the response of
the low-pass filter synthesis (${\mathbf K}^{-1}_0$) is indicated by
$\phi$ and the synthesis high-pass filter (${\mathbf K}^{-1}_1$) is
represented by $\psi$, which are the dual scaling and wavelet functions.

For the MST it holds that $\tilde\phi\bot\tilde\psi$, the frequency
response of $\tilde\phi$ is equal to the mirror\footnote{In the
  $Z$-domain, it holds that
  ${\mathcal Z}\{\tilde\phi\}(z)={\mathcal Z}\{\phi\}(-z)$.} of $\phi$
and $\tilde\psi$ is equal to the mirror of $\psi$, and this is also
true for all orthogonal DWTs. Another important characteristic of
orthogonal DWTs is that the filters cannot be
\href{https://en.wikipedia.org/wiki/Symmetry}{symmetric}.\footnote{The
  symmetry of the filters is important to produce the same type of
  artifacts in the boundaries of the signal and also to avoid the
  phase-shifting of the coefficients in the wavelet domain.}

%The dilated and translated versions of the wavelet function are
%orthogonal~\cite{sayood2017introduction}.

%}}}

\subsection{Example of a DWT using ``high''-order filters}
%{{{

The previous MST-based DWT is similar to other transforms such as the
\href{https://en.wikipedia.org/wiki/Haar_wavelet}{Haar transform}, in
which we use a 1-order predictor to remove temporal
redundancy. Let us extend the idea of lifting to a prediction of order
two. For that, we define the predict step as
\begin{equation}
  {\mathbf h}^l_i = {\mathbf l}^{l-1}_{2i+1} - \frac{1}{2}({\mathbf l}^{l-1}_{2i} + {\mathbf l}^{l-1}_{2i+2})
  \label{eq:linear_prediction}
\end{equation}
and the update step as
\begin{equation}
  {\mathbf l}^l_i = {\mathbf l}^{l-1}_{2i} + \frac{1}{4}({\mathbf h}^l_{i-1} + {\mathbf h}^l_i),
  \label{eq:linear_update}
\end{equation}
where the factor $1/4$ is used to preserve the
energy~\cite{sweldens1997building}. This transform is known as the
\href{https://en.wikipedia.org/wiki/Biorthogonal_wavelet}{biorthogonal}
(2,2) of Cohen-Daubechies-Feauveau.  Biorthogonal\footnote{All
  transforms express a change of basis. When the basis are not
  orthogonal, the synthesis transform is not the transpose of the
  analysis transform. When the synthesis filters are orthogonal to
  their corresponding ``\emph{dual}'' analysis filters, the transform is
  said biorthogonal.~\cite{vetterli2014foundations}} filters can be
\href{http://wavelets.pybytes.com/}{easely recognized} because they
are always symmetric.\footnote{If Eq.~\eqref{eq:linear_prediction} is used in Eq.\eqref{eq:linear_update}, we can obtain the coefficients of the low-pass filter that computes the low-frequency subband: ${\mathbf l}^l_i=-1/8{\mathbf l}^{l-1}_{2i-2}+1/4{\mathbf l}^{l-1}_{2i-1}+3/4{\mathbf l}^{l-1}_{2i}+1/4{\mathbf l}^{l-1}_{2i+1}-1/8{\mathbf l}^{l-1}_{2i+2}$.} When the PRFB filters are biorthogonal,
they also satisfy $\phi\bot\tilde\phi$ and
$\psi\bot\tilde\psi$.

This linear transform is also invertible by simply reversing the steps:
\begin{equation}
  \begin{array}{rcl}
    {\mathbf l}^{l-1}_{2i} & = & {\mathbf l}^l_i - \frac{1}{4}({\mathbf h}^l_{i-1} + {\mathbf h}^l_i)\\
    {\mathbf l}^{l-1}_{2i+1} & = & {\mathbf h}^l_i + \frac{1}{2}({\mathbf l}^{l-1}_{2i} + {\mathbf l}^{l-1}_{2i+2}).
  \end{array}
\end{equation}

%}}}

\subsection{Quantization of the DWT subbands}

The same theory developed for the quantization of the MST subbands
(see Section~\href{sec:quantization_subbands_spatial} is applicable
here: we should select the different quantization step sizes depending
on the slope generated in the rate/distortion curve (see this
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/contents/transform_coding/DWT_RD.ipynb}{A
  RD-comparison of DWTs}. In the practice, when the dynamic range of
the DWT coefficients depends on the gain of the synthesis filters (as
occurs with PyWavelets), a constant QSS strategy, where
\begin{equation}
  \Delta_0=\Delta_i~\text{for}~i=1,\cdots,l+1
\end{equation}
usually works fine.
\begin{comment}
The QSSs to be used in the different subbands of a (orthogonal)
decomposition should be inversely\footnote{Remember that if the QSS is
  higher, the quantization error is also higher. Therefore, those
  subbands with higher amplification in the inverse transform should
  be quantized less.} proportional the gain of the synthesis
filters. The gain of a filter corresponds to the L$^2$ norm of its
coefficients, and the final gain applied to a subband depends
logically on the number of times that we have applied the filter in
the cascade. Notice that if we do not know the coefficients, we can
use the algorithm described in
Section~\ref{sec:quantization_subbands_spatial} to find the gain of
the subbands. Notice, however, that in most of the implementations,
the coefficients are already multiplied by the gain, and therefore,
using a constant $\Delta$ for all the subbands we are satisfiying such
requirement.\footnote{This is the reason why we need to use more than
  2 bytes for representing the wavelet coefficients that have been
  generated using 2 bytes samples.}

Finally, notice that if the transform is orthonormal, by definition,
the gain of the analysis and synthesis filters is always 1, and this is also the gain of the subbands. In the notebook
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/contents/transform_coding/DWT_RD.ipynb}{A
  RD-comparison of DWTs} there is more information on QSS that
can be used in the quantization process.
\end{comment}
%}}}

%{{{

\section{\href{https://en.wikipedia.org/wiki/Lapped_transform}{Overlapped block transforms} to minimize distortion}
%{{{

Transform Coding implies splitting the signal into blocks of data
(chunks) and computing the transform of each chunk. When the output
coefficients are quantized, it is possible that significant (and
unpleasant) distortions may appear in the border frames of the chunks
(see Fig.~\ref{fig:3_chunks}). This is a consequence of the prediction
step computed by the DWT in the limits of the chunks (where we need
the samples of the adjacent chunks), generating different predictions
at the beginning and the end of the adjacent chunks.

\begin{figure}
  \centering
  \begin{tabular}{cc}
    \svg{3_chunks}{500} & \svg{without}{500} \\
    \svg{extended}{500} & \svg{reconstructed}{500} \\
  \end{tabular}
  \caption{On the top-left, three consecutive chunks of a real mono
    audio sequence. On the top-right, the reconstruction of the chunks
    without overlapping. On the bottom-left, the extended central
    chunk. On the bottom-right, the reconstruction of the extended
    chunk. See the notebook
    \href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/contents/transform_coding/quantization_DWT.ipynb}{Quantization
      in the DWT domain}. Remember that only the orange samples of
    the extended chunk will be used to reconstruct the original
    signal!}
  \label{fig:3_chunks}
\end{figure}

One solution to avoid signal discontinuities between chunks is to
overlap the content of the blocks of data processed by the DWT. Thus,
the current ($i$-th) ``chunk'' uses also the last frames of the
previous ($(i-1)$-th) chunk and the first frames of the next
($(i+1)$-th) chunk to compute the transform of the current extended
($i$-th) chunk (see the Fig.~\ref{fig:subbands}). This has been
described in the following algorithm:

\subsection*{Encoder:}
\begin{enumerate}
\item ${\mathbf C}_{-1}\leftarrow{\mathbf 0}$, a zero chunk.
\item Input ${\mathbf C}_0$.
\item For $i\in\{0,1,\cdots\}$:   
  \begin{enumerate}               
  \item Input ${\mathbf C}_{i+1}$.
  \item Build the extended chunk ${\mathbf E}={\mathbf
    C}_{i-1}[-o:]|{\mathbf C}_i|{\mathbf C}_{i+1}[:o]$, where
    $\cdot|\cdot$ denotes the concatenation of chunks, $o$ is the
    overlapped area size in frames, ${\mathbf C}_{i-1}[-o:]$ the last
    $o$ frames of chunk ${\mathbf C}_{i-1}$, and ${\mathbf
      C}_{i+1}[:o]$ are the first $o$ frames of the chunk ${\mathbf
      C}_{i+1}$.
  \item Compute the decomposition ${\mathbf D}_i \leftarrow
    \text{DWT}^l({\mathbf E})$, where $l$ is the number of levels of
    the DWT ($l=2$ in Fig.~\ref{fig:subbands}).
  \item Output the decomposition ${\mathbf D}_i$.
  \item ${\mathbf C}_{i-1}\leftarrow {\mathbf C}_i$ (we can assign the pointers, not the contents).
  \item ${\mathbf C}_i\leftarrow {\mathbf C}_{i+1}$.
  \end{enumerate}
\end{enumerate}

Notice that we are following the
\href{https://numpy.org/doc/stable/reference/}{NumPy}~\cite{numpy,harris2020array}
\href{https://www.pythoninformer.com/python-libraries/numpy/index-and-slice/}{slicing}
notation.

%Notice that we are sending for each chunk $2o+x$ coefficients
%(stereo-coefficients, in the case of using 2 chanels), where $x$ is
%the number of frames/chunk.

\subsection*{Decoder:}
\begin{enumerate}
\item For $i\in\{0,1,\cdots\}$:
  \begin{enumerate}
  \item Input decomposition ${\mathbf D}_i$.
  \item Compute extended chunk ${\mathbf E}\leftarrow\text{DWT}^{-l}({\mathbf D}_i)$.
  \item Output chunk ${\mathbf C}_i={\mathbf E}[o:-o]$.
  \end{enumerate}
\end{enumerate}

%\begin{figure}
%  \centering
%  \svg{graphics/overlapping2}{800}
%  \caption{Chunks overlapping. Notice that $a$ data is repeated in the
%    extended chunks $C_0$ and $C_1$. Something similar happens with
%    $b$ data.}
%  \label{fig:overlapping2}
%\end{figure}

\begin{figure}
  \centering
  \svg{graphics/subbands}{550}
  \caption{Structure in the DWT domain of an extended chunk for $l=2$
    (upper subfigure, without chunk extension). $o$ is the number of
    overlapped frames between adjacent chunks.
    ${\mathbf C}_{i-1}[-o:]$ represents the last $o$ frames of chunk
    ${\mathbf C}_{i-1}$, and ${\mathbf C}_{i+1}[:o]$ the first $o$
    frames of the chunk ${\mathbf C}_{i+1}$.}
  \label{fig:subbands}
\end{figure}

This idea has been implemented in the notebook
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/contents/transform_coding/overlapped_DWT_I.ipynb}{Overlapped
  DWT}, and the result can be seen in Fig.~\ref{fig:3_chunks}.

%}}}

\section{Reducing the data overhead}
%{{{

\label{sec:reducing}

Unfortunately, the previous algorithm sends twice the DWT coefficients
of the overlapped areas (in Fig.~\ref{fig:subbands}, $\{{\mathbf
  D}_i.{\mathbf l}^2[-o/4:], {\mathbf D}_i.{\mathbf l}^2[:o/4],
{\mathbf D}_i.{\mathbf h}^2[-o/4:], {\mathbf D}_i.{\mathbf
  h}^2[:o/4], {\mathbf D}_i.{\mathbf h}^1[-o/2:], {\mathbf
  D}_i.{\mathbf h}^1[:o/2]\}$). To avoid this waste of bandwidth, we
can reuse the received coefficients of the overlapped areas. This
procedure has been described in Fig.~\ref{fig:overlapping}, and,
as can be seen, the encoding algorithm is identical to the previous
one except that only the central (stereo) coefficients are
sent. The rest of the coefficients that are needed to compute the inverse
transform are extracted from the neighboring chunks (represented in the
DWT domain). Notice that now the number of sent coefficients is
$\text{len}({\mathbf C}_i)$, the number of samples in ${\mathbf C}_i$.

\begin{figure}
  \centering
  \svg{graphics/overlapping}{800}
  \caption{Block overlapping in the DWT domain for $l=2$. Only the
    shadded coefficients are transmitted. Notice that, to be
    reconstructed, each chunk depends on some coefficients of the
    adjacent blocks (only some dependencies have been indicated).}
  \label{fig:overlapping}
\end{figure}

%\subsection*{Encoder:}
%\begin{enumerate}
%\item For $i\in\{0,1,\cdots\}$:
%  \begin{enumerate}
%  \item Input $C_i$ and $C_{i+1}$.
%  \item $D_i \leftarrow \text{DWT}(C_i[o:]|C_{i+1}[:o])$, where
%    $C[o:]$ the last $x-o$ frames of the chunk $C$, and
%    $C_i[o:]|C_{i+1}[:o]$ is the $i$-th right-only extended chunk.
%    \item Send $D_i$.
%  \end{enumerate}
%\end{enumerate}

The codec can now be described by:

\subsection*{Encoder:}
\begin{enumerate}
\item ${\mathbf C}_{-1}\leftarrow{\mathbf 0}$, a zero chunk.
\item Input ${\mathbf C}_0$.
\item For $i\in\{0,1,\cdots\}$:   
  \begin{enumerate}               
  \item Input ${\mathbf C}_{i+1}$.
  \item Build the extended chunk ${\mathbf E} = {\mathbf
    C}_{i-1}[-o:]|{\mathbf C}_i|{\mathbf C}_{i+1}[:o]$.
  \item Compute the decomposition ${\mathbf D}_i \leftarrow
    \text{DWT}^l({\mathbf E})$.
  \item Output the decomposition subset
    $\Big\{{\mathbf D}_i.{\mathbf l}^l[\frac{o}{2^l}:-\frac{o}{2^l}], {\mathbf
      D}_i.{\mathbf h}^l[\frac{o}{2^l}:-\frac{o}{2^l}], {\mathbf D}_i.{\mathbf
      h}^{l-1}[\frac{o}{2^{l-1}}:-\frac{o}{2^{l-1}}], \cdots, {\mathbf D}_i.{\mathbf
      h}^1[\frac{o}{2^1}:-\frac{o}{2^1}]\Big\}$.
  \item ${\mathbf C}_{i-1}\leftarrow {\mathbf C}_i$.
  \item ${\mathbf C}_i\leftarrow {\mathbf C}_{i+1}$.
  \end{enumerate}
\end{enumerate}

%\begin{enumerate}
%\item For $i\in\{0,1,\cdots\}$:   
%  \begin{enumerate}               
%  \item Input chunk $C_i$.
%  \item Compute decomposition $D_i \leftarrow \text{DWT}^l(C_i)$.
%  \item Send $D_i$.
%  \end{enumerate}
%\end{enumerate}

\subsection*{Decoder (ignores overlapping):}
This decoder ignores the adjacent chunks in the DWT domain, but notice that it uses the right coefficients (those computed using overlapping chunks). This should provide reconstructions of the chunks with a higher quality than in the previous decoding algorithm.
\begin{enumerate}
\item For $i\in\{0,1,\cdots\}$:
  \begin{enumerate}
  \item Input the decomposition subset ${\mathbf D}_i$.
  \item Compute the chunk ${\mathbf C}_i\leftarrow\text{DWT}^{-l}({\mathbf D}_i)$.
  \item Output ${\mathbf C}_i$.
  \end{enumerate}
\end{enumerate}

\subsection*{Decoder (uses overlapping):}

Finally, this is the definitive decoder that minimizes the
reconstruction error and avoid the gliches at the borders of the
chunks.

\begin{enumerate}
\item ${\mathbf D}_{-1}\leftarrow{\mathbf 0}$.
\item Input decomposition ${\mathbf D}_0$.
\item For $i\in\{0,1,\cdots\}$:
  \begin{enumerate}
  \item Input decomposition ${\mathbf D}_{i+1}$.
  \item Build the extended decomposition ${\mathbf E}_i =
    {\mathbf D}_{i-1}.{\mathbf l}^l[-\frac{o}{2^l}:]|{\mathbf D}_i.{\mathbf l}^l|{\mathbf D}_{i+1}.{\mathbf l}^l[:\frac{o}{2^l}]|{\mathbf D}_{i-1}.{\mathbf h}^l[-\frac{o}{2^l}:]|{\mathbf D}_i.{\mathbf h}^l|{\mathbf D}_{i+1}.{\mathbf h}^l[:\frac{o}{2^l}]|\cdots|{\mathbf D}_{i-1}.{\mathbf h}^1[-\frac{o}{2^1}:]|{\mathbf D}_i.{\mathbf h}^1|{\mathbf D}_{i+1}.{\mathbf h}^1[:\frac{o}{2^1}].$
  \item Compute the extended chunk ${\mathbf C}_i\leftarrow\text{DWT}^{-l}({\mathbf E}_i)$.
  \item Output ${\mathbf C}_i[o:-o]$.
  \item ${\mathbf D}_{i-1} \leftarrow {\mathbf D}_i$.
  \item ${\mathbf D}_i \leftarrow {\mathbf D}_{i+1}$.
  \end{enumerate}
\end{enumerate}

%Notice that the only that changes between this codec and the previous
%one is that now, the inverse transform of the extended chunks uses the
%last coefficients of the previous extended chunk. This idea has been
%checked in the
%\href{https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/overlapped_DWT_II.ipynb}{notebook}.

%}}}

%}}}

%}}}

\section{Deliverables}

\begin{enumerate}

\item \textbf{Find the following RD curves}:

\begin{enumerate}

\item \textbf{Determine the RD curves for the MST}:
  
%{{{
As we did in the previous milestone, generate the RD curves for a set
of simulated transmission contexts. Use the modules
\texttt{stereo\_MST\_coding\{\_16|\_32\}.py}. As you can see, they
differs in how the transform has been implemented.  Notice that you
can use the \verb|--minimal_quantization_step| parameter to generate
the different points of the RD curves (it is not necessary to use a
bit-rate control algorithm neither \texttt{tc}).

%}}}

\item \textbf{Determine the RD curves for the DWT}:
%{{{

  Rebuild the RD curves considering also the removal of the temporal
  decorrelation. Use \verb|temporal_no_overlapped_DWT_coding.py|. Note
  that the number of levels $l$ of the DWT (computed using
  \href{https://pywavelets.readthedocs.io/en/latest/}{PyWavelets}~\cite{lee2019pywavelets})
  can have a high impact on the amount of energy concentration
  achieved by the DWT, and therefore on the efficiency of the coding
  system. Show such an impact. Experiment also with the wavelet name
  (try to optimize --minimize-- the RD curve). Again, use the
  \verb|--minimal_quantization_step| parameter to generate the
  different points of the RD curves.

%}}}

\item \textbf{Determine the RD curves for the overlapped DWT}:
%{{{

Finally, redo the curves considering now the block overlapping
(\verb|temporal_overlapped_DWT_coding.py|). It is a good idea to put
all the RD curves together (in the same graph), to compare easily.

%}}}

\end{enumerate}

Mark: \textbf{2 points}.

\item \textbf{Answer the questions}:
%{{{

\begin{enumerate}
  
%\item Which has been the gain of the filters used in your experiments?
%  You can plot the gains (as it is shown in
%  \href{https://github.com/Tecnologias-multimedia/InterCom/blob/master/docs/2-hours_seminar.ipynb}{this
%    notebook}), but give some written explanation.

\item Does the computation of the DWT using chunk overlapping increase
  the latency of the whole system? And what about the jitter? In what
  amount? Provide a reason.

\item Which other transform(s) are used in audio encoding systems
  (such as MP3) to exploit temporal redundancy? Enumerate the
  systems and the transform(s) used.

\end{enumerate}

Mark: \textbf{1 point}.

%}}}

\end{enumerate}

\begin{comment}
\subsection{Visualize}
%{{{

Visualize the effects (in the DWT domain) of quantization.
\begin{verbatim}
qjackctl & # Select sampling frequency 44100 Hz 
python temporal_overlapped_DWT_coding.py -i 6 -o 6 --show_stats -q 8192
# Connect the output of temporal_overlapped_DWT_coding.py to the input of dwt5.py
python dwt5.py -d 9
\end{verbatim}

You can also visualize the DWT domain running the commands defined in the notebook \href{https://github.com/Tecnologias-multimedia/InterCom/blob/master/docs/2-hours_seminar.ipynb}{InterCom: a Real-Time Digital Audio Full-Duplex Transmitter/Receiver}.
\end{comment}
%}}}

\section{Resources}

\bibliography{python,maths,data_compression,DWT,audio_coding,signal_processing}
