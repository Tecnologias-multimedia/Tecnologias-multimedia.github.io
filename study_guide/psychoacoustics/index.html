<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Removing psychoacoustical redundancy</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'>Removing psychoacoustical redundancy</h2>
 <div class='author'><a href='https://cms.ual.es/UAL/personas/persona.htm?id=515256515553484875'><span class='ecrm-1200'>Vicente González Ruiz</span></a><br class='newline' /><a href='https://cms.ual.es/UAL/universidad/departamentos/informatica/index.htm'><span class='ecrm-1200'>Depto Informática</span></a> <span class='ecrm-1200'>- </span><a href='https://www.ual.es'><span class='ecrm-1200'>UAL</span></a></div><br />
<div class='date'><span class='ecrm-1200'>September 14, 2022</span></div>
   </div>
   <h3 class='sectionHead'><span class='titlemark'>1   </span> <a id='x1-10001'></a>Description</h3>
<!-- l. 7 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.1   </span> <a id='x1-20001.1'></a>Threshold of Human Hearing (THH)</h4>
<!-- l. 10 --><p class='noindent'>Psychoacoustics (see <a href='https://vicente-gonzalez-ruiz.github.io/the_sound/'>the sound</a>, <a href='https://vicente-gonzalez-ruiz.github.io/human_auditory_system/'>the human auditory system</a>, and <a href='https://vicente-gonzalez-ruiz.github.io/human_sound_perception/'>the human sound
perception</a>) has determined that the HAS (Human Auditory System) has a
sensitivity that depends on the frequency of the sound, the so called THH (<a href='https://en.wikipedia.org/wiki/Absolute_threshold_of_hearing'>Threshold
of Human Hearing</a>). This basically means that some subbands can be quantized with
a larger quantization step than others without a noticeable increase (from a
perfection perspective) of the quantization noise.
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 26 --><p class='noindent'><div style='text-align:center;'> <img src='graphics/ToHH.svg' /> </div>  <a id='x1-2001r1'></a>
<a id='x1-2002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 1: </span><span class='content'>Absolute threshold of human hearing.                          </span></figcaption><!-- tex4ht:label?: x1-2001r1  -->
                                                                  

                                                                  
   </figure>
<!-- l. 31 --><p class='indent'>   A good approximation of the THH (Threshold of Human Hearing) for a 20-years
old person can be obtained with <span class='cite'>[<a href='#Xbosi2003intro'>1</a>]</span> \begin {equation}  T(f)\text {[dB]} = 3.64(f\text {[kHz]})^{-0.8} - 6.5e^{f\text {[kHz]}-3.3)^2} + 10^{-3}(f\text {[kHz]})^4. \label {eq:ToHH}  \end {equation}
This equation has been plotted in the Fig. <a href='#x1-2001r1'>1<!-- tex4ht:ref: fig:ToHH  --></a>.
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.2   </span> <a id='x1-30001.2'></a>DWT subbands and quantization steps</h4>
<!-- l. 43 --><p class='noindent'>The number of DWT subbands \begin {equation}  N_{\text {sb}} = N_{\text {levels}} + 1  \end {equation}
where \(N_{\text {levels}}\) is the number of levels of the DWT. Except for the \({\mathbf l}^{N_{\text {levels}}}\) subband (the lowest-pass
frequency of the decomposition), it holds that \begin {equation}  W({\mathbf h}^s) = \frac {1}{2}W({\mathbf h}^{s-1}),  \end {equation}
being \(W(\cdot )\) the bandwidth of the corresponding subband \(s\). Therefore, considering that the
bandwidth of the audio signal is \(22050\) Hz, the bandwidth \(W({\mathbf h}^1)\) of the \({\mathbf h}^1\) subband is \(11025\) Hz, \(W({\mathbf h} ^2)=22025/4\), and so
on. It also holds that \begin {equation}  W({\mathbf l}^{N_{\text {levels}}}) = W({\mathbf h}^{N_{\text {levels}}}).  \end {equation}
</p><!-- l. 61 --><p class='indent'>   The idea is to determine, knowning the frequencies represented in each DWT
subband and the THH curve, the quantization step that should be applied to each
subband.
</p><!-- l. 67 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>2   </span> <a id='x1-40002'></a>What you have to do?</h3>
<!-- l. 70 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>2.1   </span> <a id='x1-50002.1'></a>Subjective comparison</h4>
<!-- l. 73 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-5002x1'>Using a recording tool such as <a href='http://audacity.sourceforge.net'>Audacity</a> or <a href='http://plugin.org.uk/timemachine/'>JACK Timemachine</a>, record the
     simulated transmission of a piece of audio and create a <span class='ectt-1000'>.wav </span>file, when the
     audio has been transmitted using <span class='ectt-1000'>temporal_overlapped_DWT_coding.py</span>
     and <span class='ectt-1000'>threshold.py</span>, using in both cases the same transmission bit-rate.
     Use the quantization step for controlling the bit-rate.
     </li>
<li class='enumerate' id='x1-5004x2'>Determine which audio sounds better, from a subjective point of view.
     Repeat this step the number of times you consider necessary.</li></ol>
                                                                  

                                                                  
<!-- l. 90 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>3   </span> <a id='x1-60003'></a>Deliverables</h3>
<!-- l. 92 --><p class='noindent'>The results of your experiments.
</p><!-- l. 94 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>4   </span> <a id='x1-70004'></a>Resources</h3>
   <div class='thebibliography'>
   <p class='bibitem'><span class='biblabel'>
 [1]<span class='bibsp'>   </span></span><a id='Xbosi2003intro'></a>M. Bosi and R.E. Goldberd.  <a href='https://last.hit.bme.hu/download/vidtechlab/fcc/literature/audio/audio_coding_standards_book.pdf'><span class='ecti-1000'>Introduction to Digital Audio Coding and
   </span><span class='ecti-1000'>Standards</span></a>. Kluwer Academic Publishers, 2003.
</p>
   </div>
<p><a id='Q1-1-9'></a></p>
    
</body> 
</html>