\input{../definitions}
\title{\TM{} - Study Guide - Milestone 9: Compressing the audio data with \href{https://zlib.net/}{zlib}}

\maketitle

\section{Description}

It's time to reduce bandwidth comsumption in InterCom. The
\verb|pack()| and the \verb|unpack()| methods can compress and
decompress, respectively, the chunks that are processed. To compress
and decompress, we will use a free
\href{https://en.wikipedia.org/wiki/Codec}{codec} named
\href{https://en.wikipedia.org/wiki/DEFLATE}{DEFLATE}, which is based
on
\href{https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Storer%E2%80%93Szymanski}{LZSS}
  and \href{https://en.wikipedia.org/wiki/Huffman_coding}{Huffman
    Coding}~\cite{nelson96datacompression}. See this
  \href{https://github.com/vicente-gonzalez-ruiz/LZ77}{notebook} and
  this
  \href{https://vicente-gonzalez-ruiz.github.io/Huffman_coding/}{notebook}.

The DEFLATE algorithm is implemented in the Python's standard library
\href{https://docs.python.org/3/library/zlib.html}{\texttt{zlib}}. We
have used this facility for compressing and decompressing the chunks
that we are sending and receiving in the methods \verb|pack()| and
\verb|unpack()|, respectively. These methods are implemented in the
modules:

\begin{enumerate}
\item \verb|DEFLATE_raw.py|: Compress the raw chunks with DEFLATE.
\item \verb|DEFLATE_serial.py|: Compress the chunk after concatenating
  the channels (see Fig.~\ref{fig:reordering}). Notice that with this
  shuffling, the samples are not interleaved and the correlation
  between consecutive bytes is slighly increased. This should increase
  the
  \href{https://en.wikipedia.org/wiki/Data_compression_ratio}{(data)
    compression ratio}
\begin{figure}
  \begin{center}
    \myfig{graphics/reordering}{5cm}{500}
  \end{center}
  \caption{Sample reordering to create two independent channels.}
  \label{fig:reordering}
\end{figure}
\item \verb|DEFLATE_serial2.py|: Similar to \verb|compress_serial.py|, but
  reseting DEFLATE at each new chunk-channel. The idea here is to see
  if DEFLATE is exploiting the redundancy between the consecutive
  channels.
\item \verb|DEFLATE_byteplanes2.py|: Similar to
  \verb|compress_serial.py| (channels are concatenated), but 2
  code-streams are generated, one for the LSB (Low Significant Byte)
  plane and another for the MSB (Most Significant Byte) plane, working
  with 16 bits/sample. The idea here is to see if the MSB can be
  compressed more efficiently because it can contain runs of zeros,
  especially when the audio sequence is \emph{quiet}.
\item \verb|DEFLATE_byteplanes3.py|: Similar to
  \verb|DEFLATE_byteplanes2.py| but considering three
  byte-planes. This would enable the compression of
  \emph{coefficients}\footnote{Uses in the future improvements of
    intercom.} that require more than two bytes to be represented.
\item \verb|DEFLATE_byteplanes4.py|: Considers four byte-planes.
\item \verb|DEFLATE_byteplanes2_interlaced.py|: Similar to
  \verb|DEFLATE_byteplanes2.py| but using the raw chunks (without
  concatenating the channels).
\end{enumerate}

Finally, notice that the number of sent UDP packets (that now will be
length-variying) remain constant respect to \verb|buffer.py|.

\section{What you have to do?}

Determine empirically which ordering of the chunk data is the most
efficient from a lossless data compression point of view (the smaller
the bit-rates, the higher the compression). Use the audio sequence you
want. Some samples are stored in the \verb|data| directory of
intercom.

\section{Timming}

Please, finish this milestone at most in one week.

\section{Deliverables}

A report documenting the experiment and the results.

%Create a Python module named compress.py and store it in the
%\href{https://github.com/Tecnologias-multimedia/intercom}{root
%  directory} of your InterCom's repo.

\section{Resources}

\bibliography{text-compression}
