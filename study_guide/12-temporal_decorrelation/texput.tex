\input{../definitions}
\title{\TM{} - Study Guide - Milestone 12: Temporal decorrelation in audio signals}

\maketitle

\section{Description}

\subsection{About temporal redundancy in audio}
After exploiting the spatial (stereo) redundancy in the previous
milestone, the next natural step in the development of InterCom is to
remove the temporal redundancy that can be found inside of each
subband\footnote{Notice that, beacuse the MST and the transform used
  in this milestone are both lineal, the order in which the transforms
  are applied is irrelevant. For this reason, we could also have used
  the temporal transform inside of each channel of samples, and then,
  remove the spatial redundancy.}. As it can be seen in this
\href{https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/audio_viewer.ipynb}{notebook},
most audio signals show ``patterns'' of samples that tends to repeat,
especially locally. Another clear source of temporal redundancy is
that the neighbor audio samples usually show similar amplitude values.

% A decorrelating technique: DPCM
There are several techniques that can be used for removing the
temporal redundancy of a sequence of audio. One of the most
straightforward is
\href{https://en.wikipedia.org/wiki/Differential_pulse-code_modulation}{Differential
  Pulse Code Modulation
  (DPCM)~\cite{sayood2017introduction}}. However, there are more
efficient decorrelation algorithms based on
\href{https://en.wikipedia.org/wiki/Transform_coding}{transform
  coding}, such as the used in the previous milestone and in this one.

% Another decorrelating technique: transform coding
Transform coding is based on the idea that we can decompose (we can
generate a decomposition from) the input signal into a set of
subbands, and if the used filters are the adecuate ones for removing
the temporal redundancy, we can achieve a high transform
\href{https://en.wikipedia.org/wiki/Coding_gain}{coding gain},
accumulating most of the signal energy (and presumably most of the
information) in a small number of subbands. When this happens, the
quantization of the subbands will remove basically the least
significant information (usually
\href{https://en.wikipedia.org/wiki/Noise_(electronics)}{electronic
  noise}), allowing better compression ratios than those in which we
apply the same quantization process to the original
samples.\footnote{Notice that is we dead-zone quantize a decomposition
and most of the coefficients are close to zero, the information
removed from $x$ will be those with a smaller energy.}

\begin{figure}
  \centering
  \myfig{graphics/PRFB}{5cm}{500}
  \caption{A 2-channels PRFB (Perfect Reconstruction Filter Bank).}
  \label{fig:PRFB}
\end{figure}

\subsection{Transform and subband coding}
% Relation between transform coding and subband coding
The name that has been given to the previous process is
\href{https://en.wikipedia.org/wiki/Sub-band_coding}{subband
  coding}. In this context, our analysis transform matrix $K$ (see the
previous milestone) represents the taps of a 2-channels analysis
\href{https://en.wikipedia.org/wiki/Filter_bank}{Filter Bank
  (FB)}~\cite{vetterli1995wavelets}, and the forward transform is in
fact ``descomposing'' $x$ into two subbands $w_0$ and $w_1$ (see the
Figure~\ref{fig:PRFB}, and this
\href{https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/PRFB.ipynb}{notebook}). On
the other hand, the synthesis transform matrix $K^{-1}$ denotes the
taps of the corresponding synthesis FB that allows to recover $x$
(notice that in the figure, $x=l^i$, $w_0=l^{i+1}$, $w_1=h^{i+1}$,
$\tilde\phi=K_0$, $\tilde\psi=K_1$, $\phi=K^{-1}_0$, and
$\psi=K^{-1}_1$).

% An intro to PRFBs
Let's suppose now that the filters (represented by the taps of) $K_0$
and $K_1$ are applied to the input signal $x$ (now a sequence of $N$
samples) using a
\href{https://en.wikipedia.org/wiki/Kernel_(image_processing)}{convolution}
(without splitting $x$ into blocks). Let's also suppose (as happens in
the MST) that $K_0$ is a low-pass filter and $K_1$ is a high-pass
filter, and that the
\href{https://en.wikipedia.org/wiki/Filter_(signal_processing)#The_transfer_function}{transfer
  function}\footnote{The response of the filter to the
  \href{https://en.wikipedia.org/?title=Unit_impulse&redirect=no}{unit
    impulse}.} of both filters
\href{https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks}{are
  one the inverse of the other}. Under these assumptions, the complete
(analysis/synthesis) transform is called a (2-channels)
\href{https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks}{Perfect
  Reconstruction Filter Bank (PRFB)}, and $x$ can be recovered
(perfectly) from a subsampled version (in this case
\href{https://en.wikipedia.org/wiki/Downsampling_(signal_processing)}{decimating}
by 2) of $w_0$ and $w_1$ (see the
\href{https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/PRFB.ipynb}{notebook}). Notice
that this subsampling is possible because the
\href{https://en.wikipedia.org/wiki/Aliasing}{aliasing}\footnote{Because
  the filters are not ideal, the bandwidth of the filtered signals
  $w_0$ and $w_1$ is bigger than half of the bandwidth of
  $x$. Therefore, subsampling at a ratio of one of each two
  coefficients, we are generating aliasing. See the
  \href{https://en.wikipedia.org/wiki/Nyquist-Shannon_sampling_theorem}{sampling
    theorem}.}  generated in the low-pass subband is compensated by
the aliasing generated in the high-pass subband. To achieve this, the
\href{https://en.wikipedia.org/wiki/Filter_(signal_processing)#The_transfer_function}{frequency
  response} of $K_0$ must be equal to the mirror frequency response of
$K_1$, and obviously, both filters must have the same
bandwidth~\cite{sayood2017introduction}. In this situation, in which
$K_1$ and $K_2$ are mirror filters, we say that they form a
\href{https://en.wikipedia.org/wiki/Quadrature_mirror_filter}{Quadrature
  Mirror Filters Bank (QMF)}.

\subsection{Multichannel filter banks and psychoacoustic frequency resolution}
% M-channels PRFB and the frequency resolution of the HAS
Using the suitable filters, it is possible to build $M$-channels
PRFBs.\footnote{Notice that our matrix $K$ would have $M$ rows in this
case, and also $M$ colums, to satisfy that $K^{-1}=K^{\text T}$ if we
are implementing an orthogonal transform.}  These filters can analyze
(and synthesize) the signal $x$, decomposing it in
(\href{https://en.wikipedia.org/wiki/Low-pass_filter#Ideal_and_real_filters}{almost
  for sure}) overlaping frequency subbands with different
bandwidth. The question here is to know how many filters should be
used and what
\href{https://en.wikipedia.org/wiki/Band-pass_filter}{pass-band} width
should they have. At this design point, we must also consider that the
accuracy of the
\href{https://en.wikipedia.org/wiki/Psychoacoustics}{humman perception
  of the sound} depends on the frequency: (as it can be checked in this
\href{https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/frequency_resolution.ipynb}{notebook})
we are more sensitive to frequency variations when the frequency of
the sound is low. This fact is related with the way in which the
\href{https://en.wikipedia.org/wiki/Critical_band}{critical bands} are
distributed in \href{https://en.wikipedia.org/wiki/Bark_scale}{the
  bark scale}.

\subsection{The Discrete Wavelet Transform}
% The bark scale and the DWT
As it can be seen, the bark scale divides the audible spectrum into 24
subband of (a priori) ``whimsical'' bandwidths. However, it's clear
that a \href{https://en.wikipedia.org/wiki/Octave_band}{dyadic
  partition of the spectrum} fits better than
\href{https://en.wikipedia.org/wiki/Wavelet_transform#Principle}{a
  lineal partition}. Considering this reason, from all the families of
transforms designed to date, the most suitable one, from a frequency
partitioning point of view, is the Discrete Wavelet Transform (DWT).

% Features of the DWT
The DWT has also other interesting features:
\begin{enumerate}
\item It is
  \href{https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Time_complexity}{fast}
  ($O(N)$, where $N$ is the number of ``transformed'' samples).
\item It can represent efficienty
  \href{https://en.wikipedia.org/wiki/Transient_(oscillation)}{transient}
  signals, which can happen frequently in audio.
\item Although we are not going to take advantage of the following
  characteristic (for now), one of the most interesting features of
  the DWT is that it can used to find a
  \href{https://en.wikipedia.org/wiki/Multiresolution_analysis}{multiresolution
    representation} of the signal.
\end{enumerate}

\begin{figure}
  \centering
  \myfig{graphics/cascade}{10cm}{1000}
  \caption{A dyadic 2-levels cascade of PRFBs.}
  \label{fig:cascade}
\end{figure}

\subsection{Implementation of the DWT}
% Implementation alternatives for the DWT
The DWT can be implemented in different ways:
\begin{enumerate}
\item Defining the transform matrix $K$ (see these
  \href{https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf}{slides})
  and computing vector-matrix multiplications, which requires a
  calculation time proportional to $O(N^2)$. However, the main problem
  of this type of implementation is generated by the amount of memory
  that $K$ requires, that is proportional to $N^2$.
\item
  \href{https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Cascading_and_filter_banks}{Cascading
    PRFBs} (see the Figure~\ref{fig:cascade}). Considering that the
  \href{https://en.wikipedia.org/wiki/Convolution}{convolution} is a
  $O(N\log_2N)$ operation (if it is
  \href{https://en.wikipedia.org/wiki/Convolution_theorem}{implemented
    in the frequency domain}), and that the number of levels in the
  cascade is generally small (5 for example), this implementation is
  faster than the based in vector-matrix arithmetic. And most
  importantly, we don't need to store $K$, but only the taps of the
  filters that in a software implementation of a cascade can be as
  small as the number of different filters.\footnote{Notice that in a
    typical cascade, the filters are always the same.}
\item Using
  \href{https://en.wikipedia.org/wiki/Lifting_scheme}{lifting}~\cite{sweldens1997building},
  which provides an extra speed-up factor of 2 compared to the FB
  implementation. DWTs implemented with lifting do not need to
  downsample and upsample the subbands, an operation that is wasting
  the calculus of half of the coefficients at each level of the
  cascade.
\end{enumerate}

\subsection{Example of a DWT using the MST filters}
% Using the MST filters for building a DWT
In order to clarify the previously introduced concepts, let's build a
DWT using the MST filters and lifting.

\begin{enumerate}
\item Lifting is based on the concept of dyadic
  \href{https://en.wikipedia.org/wiki/Multiresolution_analysis}{multiresolution
    analysis}, and also with the so called
  \href{https://en.wikipedia.org/wiki/Polyphase_matrix}{polyphase
    representation} of signals. In order to do that, we can rewrite
  the MST filter equations (our $K_0$ and $-K_1$ filters in the
  previous milestone) as
  \begin{equation}
    \begin{array}{rcl}
      l^1_i & = & x_{2i} + x_{2i+1} \\
      h^1_i & = & x_{2i+1} - x_{2i},
    \end{array}
    \label{eq:1dwt}
  \end{equation}
  where the $s$-th subband $z^s=\{z_i^s~|~0\le i\le 2^{n-s}\}$, being
  $2^n=N$ the number of samples in $x$, and where, by definition, $l^0=x$,
  the original resolution level of the signal. The subbands $l^1$ and
  $h^1$ computed by Eq.~\ref{eq:1dwt} are the same than the decimated
  subbands computed by a 1-levels PRFB (based on that filters), and we
  say, therefore, that Eq.~\ref{eq:1dwt} computes the 1-levels DWT.

  Based on the 1-levels DWT, we define the 2-levels DWT as
  \begin{equation}
    \begin{array}{rcl}
      l^2_i & = & l^1_{2i} + l^1_{2i+1} \\
      h^2_i & = & l^1_{2i+1} - l^1_{2i},
    \end{array}
    \label{eq:2dwt}
  \end{equation}
  that, as we can see, uses as input the output of Eq.~\ref{eq:1dwt}.

  In general, for a $s$-levels DWT, we get
    \begin{equation}
    \begin{array}{rcl}
      l^s_i & = & l^{s-1}_{2i} + l^{s-1}_{2i+1} \\
      h^s_i & = & l^{s-1}_{2i+1} - l^{s-1}_{2i}.
    \end{array}
    \label{eq:2dwt}
  \end{equation}

  The $s$-levels DWT splits the signal spectrum in $s+1$ subbands. If
  $s=n$, we have the spectrum partition
  \begin{equation*}
    | l^s_0 | h^s_0 | h^{s-1}_0 h^{s-1}_1 | h^{s-2}_0 h^{s-2}_1 h^{s-2}_2 h^{s-2}_3 | \cdots | h^1_0 h^1_1 \cdots h^1_{2^{n-1}-1} |,
  \end{equation*}
  where\footnote{The coefficient $l^s_0$ is called the DC (Direct
    Current) coefficient, and the rest of $h$ coefficients are called
    AC (Alternating Current) coefficients.} it holds that
  \begin{equation}
    1+\sum_{j=1}^s 2^{j-1}=2^n.
  \end{equation}

\item DWT performs a number of lifting steps, each one with
  2 (sub)steps:
  \begin{enumerate}
  \item A \textbf{predict step}, that computes the $h$ subbands as a
    prediction error (that should be minimized) between the even
    samples (usually, the values used to predict) and the odd samples
    (usually, the values predicted). For the MST filters, we have that
    \begin{equation}
      h^s_i = l^{s-1}_{2i+1} - l^{s-1}_{2i}.
    \end{equation}
    
  \item An \textbf{update step}, which computes the $l$ subbands
    considering (only) the even samples and the prediction errors. For
    the MST, we have that
    \begin{equation}
      l^s_i = 2l^{s-1}_{2i} + h^s_i.
    \end{equation}
  \end{enumerate}

  Notice that these steps are invertible:
  \begin{equation}
    \begin{array}{rcl}
      l^{s-1}_{2i} & = & \frac{1}{2}(l^s_i - h^s_i)\\
      l^{s-1}_{2i+1} & = & l^{s-1}_{2i} + h^s_i.
    \end{array}
  \end{equation}

\end{enumerate}

\subsection{Wavelets and filter banks}
In the context of the wavelet theory~\cite{burrus2013wavelets}, the
response of the analysis low-pass filter ($K_0$ in the MST) to the
\href{https://en.wikipedia.org/?title=Unit_impulse&redirect=no}{unit
  impulse}\footnote{The response of a filter to the unit impulse
  characterize the filter because the output of the filter is the set
  of taps of the filter.} is known as the scaling function and is
usually denoted by $\tilde\phi$, the response of the analysis high-pass
filter ($K_1$) is known as the wavelet function and it is usually
denoted by $\tilde\psi$, the response of the synthesis low-pass filter
($K^{-1}_0$) is denoted by $\phi$ and the synthesis high-pass
filter ($K^{-1}_1$) is represented by $\psi$.

For the MST it holds that $\tilde\phi\bot\tilde\psi$, that
$\tilde\phi=\psi$ and that $\tilde\psi=\phi$, and this is also true
for all orthogonal DWTs. Another important characteristic of
orthogonal DWTs is that the filters cannot be
\href{https://en.wikipedia.org/wiki/Symmetry}{symmetric}.\footnote{The
  symmetry of the filters is important to produce the same type of
  artifacts in the boundaries of the signal.}

%The dilated and translated versions of the wavelet function are
%orthogonal~\cite{sayood2017introduction}.

\subsection{Example of a DWT using high-order filters}
The previous MST-based DWT is similar to other transforms such as the
\href{https://en.wikipedia.org/wiki/Haar_wavelet}{Haar transform}, in
which we are using an 1-order predictor for removing the temporal
redundancy. Let's extend the idea of lifting to a prediction of order
two. For that, we define the predict step as
\begin{equation}
  h^s_i = l^{s-1}_{2i+1} - \frac{1}{2}(l^{s-1}_{2i} + l^{s-1}_{2i+2})
\end{equation}
and the update step as
\begin{equation}
  l^s_i = l^{s-1}_{2i} + \frac{1}{4}(h^s_{i-1} + h^s_i),
\end{equation}
where the factor 1/4 is used to preserve the
energy~\cite{sweldens1997building}. This transform is known as the
\href{https://en.wikipedia.org/wiki/Biorthogonal_wavelet}{biorthogonal}
(2,2) of Cohen-Daubechies-Feauveau, and also as the linear transform.
Biorthogonal\footnote{All transforms express a change of basis. When
  the basis are not orthogonal, the synthesis transform is not the
  transpose of the analysis transform. When the synthesis filters are
  orthogonal to their corresponding \emph{dual} analysis filters, the
  transform is said biorthogonal.~\cite{vetterli2014foundations}}
filters can be \href{http://wavelets.pybytes.com/}{easely recognized}
because they are always symmetric. When the filters of the PRFB are
biorthogonal, they also satisfy that $\psi\bot\tilde\phi$ and
$\phi\bot\tilde\psi$.

The linear transform is also invertible by simply reversing the steps:
\begin{equation}
  \begin{array}{rcl}
    l^{s-1}_{2i} & = & l^s_i - \frac{1}{4}(h^s_{i-1} + h^s_i)\\
    l^{s-1}_{2i+1} & = & h^s_i + \frac{1}{2}(l^{s-1}_{2i} + l^{s-1}_{2i+2}).
  \end{array}
\end{equation}

\subsection{\href{https://en.wikipedia.org/wiki/Lapped_transform}{Lapped transforms} for minimizing the distortion}
A final (and important) consideration about transform coding and
quantization. Transform coding implies splitting the signal into
chunks, and computing the transform of each chunk. When the
coefficients are quantized, it is possible that significative (and
unpleasant) distortions may appear between the border samples of the
chunks (see this
\href{https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/quantization_DWT.ipynb}{notebook}). One
simple solution is to use the last samples of the $i-1$-th chunk and
the first samples of the $i+1$-chunk for computing the transform of
the $i$-th chunk (notice that this
\href{https://en.wikipedia.org/wiki/Lapped_transform}{overlaping} does
not imply to generate more transform coefficients, but only to avoid
using an artificial
\href{https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html}{signal
  extension} at the limits of the chunks). The number of overlaped
samples depends on the length of the filters and the number of levels
$s$ of the DWT. This last parameter (the number of levels of the DWT)
has also a high impact on the decorrelation process, but take into
consideration that, depending on the signal, usually happens that it
is not worth decomposing the signal into the maximum number of
subbands because the increase in the coding gain can be negligible
beyond a number of levels (typically, $5$).
  
\section{What you have to do?}

\begin{enumerate}
\item In a module named temporal\_decorrelate.py, inherit the class
  Stereo\_decorrelation and create a class named Temporal\_decorrelation.
\item Select a suitable\footnote{Take into consideration the subband
    gains and the shape of the wavelet functions in your wavelet
    selection.} DWT from
  \href{https://pywavelets.readthedocs.io/en/latest/}{PyWavelets} and
  transform the MST subbands. Take also into consideration that the
  signal should be processed using overlaped chunks in order to
  minimize the discontinuities of the reconstructed signal at the
  chunk boundaries, when the DWT coefficients are
  quantized. Obviously, implement also the inverse stuff for
  recovering the audio signal.
\item Compare the RD (Rate/Distortion) curves generated by the modules
  br\_control.py, stereo\_decorrelate.py and temporal\_decorrelate.py.
\end{enumerate}

\section{Timming}

This is the final milestone. Present your results in the exam time.

\section{Deliverables}

The module temporal.py. Store it at the
\href{https://github.com/Tecnologias-multimedia/intercom}{root
  directory} of your InterCom's repo.

\section{Resources}

\bibliography{maths,data-compression,DWT,audio-coding}

\begin{comment}

  The Figure~\ref{fig:transform_coding} shows the stages that are
  tipycally involved in a transform-based signal compression system.

\begin{figure}
  \begin{center}
\begin{verbatim}
   s   +---+   w    +---+   k    +---+    c
 ----->| T |------->| Q |------->| E |-----------+
  (s)  +---+  (s)   +---+  (~s)  +---+   (~s)    |
samples   coefficients   indexes      code-words ~
                                                 :
                                                 ~
   ~s  +---+    w   +---+   k    +---+           |
 <-----| t |<-------| q |<-------| D |<----------+
  (~s) +---+  (~s)  +---+  (~s)  +---+
approx.    quantized     indexes
samples   coefficients
\end{verbatim}                
  \end{center}
  \caption{Common data-flow used un Transform Coding. $s$ represents
    the signal to compress, $\tilde{s}$ the lossy version of the
    reconstructed signal, $T$ the (forward) transform (which takes blocks of
    samples) producing blocks of coefficients $w$, $Q$ the scalar
    quantization stage (which takes single coefficients) producing
    quantization indexes $k$, $E$ the entropy encoder (which in our
    case (DEFLATE) works with blocks of coefficients) producing
    code-words $c$, $D$ the entropy decoder, $q$ the decuantization
    stage, and $t$ the inverse (or backward) transform. PCM stands for Puse Code
    Modulation and DEFLATE is the technique used to find a compact
    representation of the quantized coefficients.}
  \label{fig:transform_coding}
\end{figure}
\end{comment}

