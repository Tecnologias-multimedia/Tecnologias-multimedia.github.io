\input{../definitions}
\title{\TM{} - Study Guide - Milestone 10: Bit-rate control through quantization}

\maketitle

\section{Description}

\subsection{Quantization}
This discussion is reffered only to the
\href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)}{quantization}
of digital signals. Quantizers can be also applied to analog signals.

At the hardware level, the samples of audio are usually represented
using \href{https://en.wikipedia.org/wiki/Pulse-code_modulation}{PCM
  (Pulse Code Modulation)}. In a PCM sample, the number of levels that
the signal can take depends on the
\href{https://en.wikipedia.org/wiki/Audio_bit_depth}{number of
  bits/sample} (16 bits in our case).

Another key aspect to consider is that the processing that the
\href{https://en.wikipedia.org/wiki/Auditory_system}{Human Auditory
  System (HAS)} performs to understand audio signals has several
\href{https://en.wikipedia.org/wiki/Psychoacoustics}{\emph{sources} of
  perceptual redundancy}. One of these sources is the
\href{https://en.wikipedia.org/wiki/Equal-loudness_contour}{finite
  number of different volumen levels that a human being can
  recognize}~\cite{bosi2003intro}. In this milestone we will profit of
that fact to decrease the transmission bit-rate by sacrificing
quality.  In most lossy compression systems, quantization is the only
source of distortion~\cite{taubman2002jpeg2000}.

\href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)}{Scalar
  Quantization} (SQ) is the process of decreasing the number of
discrete levels that a signal can
take~\cite{sayood2017introduction}. \href{https://en.wikipedia.org/wiki/Vector_quantization}{Vector
Quantization} (VQ) is similar, but is applied to tuples of samples at
the same time~\cite{vetterli2014foundations}. SQ is used when the
samples are decorrelated or althought are correlated, the decorrelation
will be exploited in
a \href{https://en.wikipedia.org/wiki/Entropy_encoding}{entropy
coding} stage (which in our case is DEFLATE), because the
\href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)#Rate%E2%80%93distortion_optimization}{coding
  efficiency} provided by VQ is marginal in this
context~\cite{vetterli2014foundations}.

Quantizers can also be classified into
\href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)#Mid-riser_and_mid-tread_uniform_quantizers}{uniform}
and
\href{https://nptel.ac.in/content/storage2/courses/117104069/chapter_5/5_5.html}{non-uniform}~\cite{sayood2017introduction,vetterli2014foundations}. An
uniform quantizer distributes the available representation levels
uniformely over the range of input values. Non-uniform quantizers use
higher density of representation levels (more output levels per input
different values) to those intervals of input values that occur more
often. Non-uniform quantizers can also be classified into static and
\href{https://en.wikipedia.org/wiki/Adaptive_differential_pulse-code_modulation}{adaptive
  quantizers}. In the first case, the
\href{https://en.wikipedia.org/wiki/Probability_distribution}{distribution}
of the representation levels remains constant during the quantization
stage, and in the second case, the quantizer parameters are adapted
dinamically to the characteristics of the input signal. In this
milestone we will use an
\href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)#Dead-zone_quantizers}{uniform
  dead-zone scalar static quantizer}, which can be implemented
efficiently for digital signals. Moreover, dead-zone quantiders tend
to produce more quantization indices equal to 0 (which increases
compression rates) at the cost of generating more quantization noise
for values of the input signal close to 0, or what is the same,
decreasing the \href{https://en.wikipedia.org/wiki/Signal-to-noise_ratio}{SNR} for small signal values. This may seem like a
problem, but in reality it is not because precisely when the amplitude
of the signal is small and the noise is independent of its amplitude
(which usually happens with electronic noise), the SNR of the input
signal has its lowest value precisely for those values close to
0. Therefore, the quantizer basically is going to change the
electronic noise for quantization noise. See
\href{https://github.com/vicente-gonzalez-ruiz/quantization/blob/master/digital_quantization.ipynb}{this
  Jupyter notebook} for more information.\footnote{It is necessary to
download the notebook and run it, because at GitHub it is empy.}

\subsection{Rate-control and distortion}
The number of representation levels used by a quantizer depends
basically on the so called quantization step (size), typically denoted by
$\Delta$. The higher the $\Delta$, the smaller the number of
representation levels, and therefore, the higher the distortion
generated by the quantization error (see
\href{https://github.com/vicente-gonzalez-ruiz/quantization/blob/master/digital_quantization.ipynb}{the
  notebook}), and lileky (depending finally on the entropy encoder),
the smaller the output bit-rate. This generates a \href{https://en.wikipedia.org/wiki/Rate%E2%80%93distortion_theory}{rate/distortion} trade-off that is descriptive of all lossy compressors.

The control of the bit-rate through the $\Delta$ values is a technique
that can be used in real-time transmission systems to minimize the
jitter and the loss of packets when
\href{https://en.wikipedia.org/wiki/Network_congestion}{congestion}
occurs. However, notice that depending of the entropy coding stage and
the characteristics of the signal (variance, entropy) may not exist a
clear relationship between the $\Delta$ and the output bit-rate. This
happens using DEFLATE.

Notice that any rate-control algorithm based on quantization has a
characteristic RD (Rate/Distortion) curve, in which the X axis
represents the (in the case of InterCom, received) bit-rate and the Y
axis the distortion in the reconstruction (in the case of InterCom,
the played audio sequence) obtained after the quantization. Some
examples can be found
in \href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/10-br_control/audio_quantization.ipynb}{this
notebook}.

\subsection{The current implementation(s)}

Bit-Rate (BR) control through quantization has been implemented in the
class \verb|BR_Control*| of the modules
\texttt{BR\_control*.py}. This class overrides the inherited
methods \verb|Compression.pack()| and \verb|Compression.unpack()|,
performing:

\begin{lstlisting}[language=Python]
  def pack(chunk_number, chunk):
    quantized_chunk = quantize(chunk)  # (1)
    packed_chunk = Buffering.pack(chunk_number, quantized_chunk)  # (2)
    return packed_chunk  # (3)
\end{lstlisting}

\begin{lstlisting}[language=Python]
  def unpack(packed_chunk):
    (chunk_number, quantized_chunk) = Buffering.unpack(packed_chunk)  # (1)
    chunk = dequantize(quantized_chunk)  # (2)
    return (chunk_number, chunk)  # (3)
\end{lstlisting}

Notice that you will find four implementations related to this milestone:
\begin{enumerate}
\item \verb|BR_control_no.py|: Uses a constant
  $\Delta>0$.\footnote{$\Delta$ must be always bigger than $0$, by
definition, and this does not depend on the bit-rate control.} There
  is not BR control.
\item \verb|BR_control_add_lost.py|: Every second runs:
  \begin{equation}
    \Delta = \Delta + L - 1
  \end{equation}
  where $L$ is the number of lost (received) chunks in the previous
  second. Notice that this heuristic supposes that the interlocutor is
  lossing (on average) the same number of chunks.
\item \verb|BR_control_lost.py|: Every second runs:
  \begin{equation}
    \Delta = L - 1.
  \end{equation}
\item \verb|BR_control_conservative.py|: Every second runs:
  \begin{equation}
    \left\{
    \begin{array}{ll}
      \Delta = 2\Delta & \quad\text{if}~L>1 \\
      \Delta = \frac{1}{2}\Delta & \quad\text{otherwise}.
    \end{array}
    \right.
  \end{equation}
\end{enumerate}

\section{What you have to do?}

Considering the
\href{https://en.wikipedia.org/wiki/Root-mean-square_deviation}{RMSE
  (Root Mean Square Error)} as distortion measure between the sent and
the received audio signal, generate the RD curve considering a set of
different simulated transmission environments (use
\href{https://man7.org/linux/man-pages/man8/tc.8.html}{tc}) of one
audio sequence (remember that you can use one of the samples found in
the \verb|data| directory of the intercom's repo), for the four
implementations. Notice that you can use the
\verb|--minimal_quantization_step| parameter to generate the different
points of the RD curves.

\section{Timming}

Please, finish this milestone at most in one week.

\section{Deliverables}

A report with the RD curves and the data necessary to redo the curves.

\section{Resources}

\bibliography{JPEG2000,audio-coding,data-compression,signal-processing}
