\input{../definitions}
\title{\TM - Study Guide - Milestone 6: Impact of the Jitter}

\maketitle

\section{Description}

\href{https://en.wikipedia.org/wiki/Latency_(engineering)#Communication_latency}{Communication
  latency} (also called
\href{https://en.wikipedia.org/wiki/Network_delay}{network delay} and
\href{https://en.wikipedia.org/wiki/End-to-end_delay}{end-to-end
  delay}) is the time that a piece of data (a
\href{https://en.wikipedia.org/wiki/Network_packet}{packed} in the
case of the Internet) takes to travel from one point of the network to
another. This time is relevant for an intercom because the total latency $t_u$ that an user is going to experiment is
\begin{equation}
  t_u = t_l + t_i,
  \label{eq:user_latency}
\end{equation}
where $t_l$ is the (tele-communication)
\href{https://en.wikipedia.org/wiki/Telecommunications_link}{link}
latency and $t_i$ is the latency generated by the intercom.

Due to the current design of the Internet (where the available
\href{https://en.wikipedia.org/wiki/Bandwidth_(computing)}{bandwidth}
is shared on demand by the users of the network) $t_l$ is
time-variying, and cannot be controlled without using
\href{https://en.wikipedia.org/wiki/Quality_of_service}{Quality of
  Service (QoS)}, something that is not accesible to normal network
users~\cite{dordal2020intro}. On the contrary, $t_i$ is constant for a
given intercom's configuration/implementation.

In this milestone we are going to measure the
\href{https://en.wikipedia.org/wiki/Quality_of_experience}{Quality of
  Experience (QoE)} provided by our minimal intercom when the network
latency varies \href{https://en.wikipedia.org/wiki/Randomness}{at
  random}. At this point, we have basically two alternatives:
\begin{enumerate}
\item Run two instances of InterCom in two different hosts separated
  by a shared link.
\item Run one instance of Intercom and simulate the network latency.
\end{enumerate}
Each option has pros and cons, from which we can highlight that:
\begin{enumerate}
\item (Pro) The use of real latency is going to show the definitive
  behaviour of InterCom between the used hosts, which is quite
  impredictable (depend basically of the
  \href{https://en.wikipedia.org/wiki/Network_congestion}{network
    congestion}). (Con) To run InterCom in two different hosts we will
  need to establish a direct communication between them and it is very
  likely that we will have to redirect ports in the corresponding
  \href{https://en.wikipedia.org/wiki/Network_address_translation}{NAT}
  devices~\cite{srisuresh1999nat}.
\item (Pro) The simulation of the link latency is much more
  straightforward than the opening ports in our routers and (pro) will
  allow us to run InterCom in situations that are difficult to achieve
  in a real network. (Con) The running environment must provide a way
  of controlling the latency between
  \href{https://en.wikipedia.org/wiki/Process_(computing)}{processes}. Fortunately,
  in Linux we can control the latency (and the
  \href{https://en.wikipedia.org/wiki/Bit_rate}{bit-rate}) of the
  outgoing (packets) traffic using the command
  \href{https://man7.org/linux/man-pages/man8/tc.8.html}{\testtt{tc}}
  \cite{bert2012lartc}.
\end{enumerate}

\section{What you have to do?}

\subsection{Characterize the latency in different scenarios}

\subsubsection{In your host}

In most cases we will test InterCom in your host. Therefore, it can be
useful to have an idea of how the latencies are distributed, at least
from a statistical point of view.

\begin{enumerate}
\item Ping \texttt{localhost}:
   \begin{lstlisting}{language=bash}
    ping localhost -c 100 > /tmp/ping.dat
  \end{lstlisting}
Compute the expected (considering that the
  \href{https://en.wikipedia.org/wiki/Round-trip_delay}{RTT} should
  double the) latency to the host of your interlocutor:\\
\texttt{~~~~grep from < /tmp/ping.dat | cut -f 4 -d "=" | cut -f 1 -d " " | awk
  \textquotesingle\{print \$1/2\}\textquotesingle > /tmp/localhost\_latencies.dat}

\item Find the histogram of the expected latencies:
  \begin{lstlisting}{language=python}
    cat << EOF | python -
    import numpy as np
    from scipy import stats
    latencies = np.loadtxt("/tmp/localhost_latencies.dat")
    average_latency = np.average(latencies)
    print("average latency =", average_latency)
    max_latency = np.max(latencies)
    min_latency = np.min(latencies)
    maximum_absolute_deviation = max(max_latency - average_latency, average_latency - min_latency)
    print("maximum absolute deviation (jitter)=", maximum_absolute_deviation)
    print("Pearson correlation coefficient =", stats.pearsonr(latencies, np.roll(latencies, 1)[0])
    histogram = np.histogram(latencies)
    np.savetxt("/tmp/localhost_histogram.dat", histogram[0])
    EOF
  \end{lstlisting}

\item Plot the histogram:
  \begin{lstlisting}{language=bash}
    gnuplot plot "/tmp/localhost_histogram.dat" with histogram
  \end{lstlisting}
  
\item Characterize statistically the latency: which statistical
  distribution is more close to your experimental data?
\end{enumerate}

\subsubsection{In the Internet}

This scenario can be useful to test InterCom in your host but
simulating a real connection between hosts in different home
networks. For doing that:

\begin{enumerate}
  
\item Repeat the previous experiment (the characterization of the
  latencies returned by the \texttt{ping} tool) but using your
  interlocutor's \texttt{<router\_public\_IP\_address>} instead of
  \texttt{localhost}. Call the generated file as
  \texttt{/tmp/<router\_public\_IP\_address>.dat}.
  
\item Request to your interlocutor to ping its router from his/her private
  network, and to send this data to you. Save this info in
  \texttt{/tmp/<router\_private\_IP\_address>.dat} and characterize it.

\item Supposing that the latencies are symmetric (the direction of the
  packes does not affect to the latency) and that the overall network
  latency of the link between you a your interlocutor is the sum of
  the latency from your host to the router of your interlocutor and
  the latency from your interlocutor's host to that router, find a
  characterization for the full link:
  \href{https://en.wikipedia.org/wiki/Average}{average} (arithmetic
  mean) latency, \href{https://en.wikipedia.org/wiki/Jitter}{jitter},
  \href{https://en.wikipedia.org/wiki/Pearson_correlation_coefficient}{Pearson
    correlation coefficient}, and
  \href{https://en.wikipedia.org/wiki/List_of_probability_distributions}{probability
    distribution}.

\end{enumerate}

\subsection{Quantification of the QoE without packed loss}

Let's measure the QoE using the following classification:
\begin{itemize}
\item Perfect: no loss or delay can be distinguish.
\item Good: if you detect some minimal distortion in the rendering
  of the sound.
\item Acceptable: when the effects of the latency are apreciable, but
  you can communicate with your interlocutor.
\item Bad: you are able to recognize only small parts of the
  received audio.
\item No way: when most of the time only silence is heard.
\end{itemize}

\subsubsection{In your host}

You don't need to control the network traffic in this scenario because
it is already shapped when InterCom uses the loopback network
device. Therefore, simply quantify your QoE when you run InterCom in
your host.

\subsubsection{In the Internet}

\begin{enumerate}
  
\item Using the characterization of the Internet link previously
  obtained, use the command
  \href{https://man7.org/linux/man-pages/man8/tc.8.html}{\texttt{tc}}
  to simulate this link locally using
  \href{https://man7.org/linux/man-pages/man8/tc-netem.8.html}{netem}:

  \begin{lstlisting}{language=bash}
    sudo tc qdisc add dev lo root netem delay <average_dalay_in_miliseconds> <maximum_average_deviation_in_miliseconds> <Pearson_correlation_coefficient_expressed_as_a_percentage> distribution <uniform|normal|pareto|paretonormal>
  \end{lstlisting}
  where:
  \begin{description}
  \item [\texttt{qdisc}:] Use the default
    \href{https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)}{FIFO}
    \href{https://wiki.debian.org/TrafficControl}{Queueing DISCipline}
    for the outgoing traffic.
  \item [\texttt{add}:] Add a new traffic control rule.
  \item [\texttt{dev lo}:] The device affected by the
    rule. \texttt{lo} means \texttt{loopback}.
  \item [\texttt{root}:] The rule will be applied to all the outbound
    traffic (it's the root rule of the possible tree of rules).
  \item [\texttt{netem}:] Use the
    \href{https://wiki.linuxfoundation.org/networking/netem}{network
      emulator} to emulate a WAN property.
  \end{description}

\item Measure the QoE.

\item Remove the \texttt{tc} rule with.
  
  \begin{lstlisting}{language=bash}
    sudo tc qdisc delete dev lo root netem delay <average_dalay_in_miliseconds> <maximum_average_deviation_in_miliseconds> <Pearson_correlation_coefficient_expressed_as_a_percentage> distribution <uniform|normal|pareto|paretonormal>
  \end{lstlisting}

\item (Optional) You can see the current rules with:

  \begin{lstlisting}{language=bash}
    tc qdisc show
  \end{lstlisting}

\item (Optional) It's possible to change a working rule with:

  \begin{lstlisting}{language=bash}
    sudo tc qdisc change dev lo root netem delay <average_dalay_in_miliseconds> <maximum_average_deviation_in_miliseconds> <Pearson_correlation_coefficient_expressed_as_a_percentage> distribution <uniform|normal|pareto|paretonormal>
  \end{lstlisting}
  
\end{enumerate}

\subsection{(Optional) QoE considering the packet loss}

For our application, InterCom, a chunk is lost when it arrives too
late or it never arrives. Therefore, the results of a packet loss or a
packet delay are almost indistinguishable, except by the average
latency experimented by the user (the higher the network latency, the
higher the perceived latency).

For example, the packet loss ratio of $10\%$ can be controlled with
\texttt{tc} by running:

  \begin{lstlisting}{language=bash}
    sudo tc qdisc add dev lo root netem loss 10%
  \end{lstlisting}

\section{Timming}

Please, finish this milestone in one week.

\section{Deliverables}

A report showing your results.

\section{Resources}

\bibliography{networking,nat}
