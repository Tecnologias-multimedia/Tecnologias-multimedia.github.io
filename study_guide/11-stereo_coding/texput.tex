\input{../definitions}
\title{\TM{} - Study Guide - Milestone 11: Spatial decorrelation in stereo audio signals}

\maketitle

\section{Description}

\subsection{An analysis transform}
InterCom transmits a
\href{https://en.wikipedia.org/wiki/Stereophonic_sound}{stereo} (two
channels)
\href{https://en.wikipedia.org/wiki/Pulse-code_modulation}{PCM
  signal}. In most cases, the channels are
\href{https://en.wikipedia.org/wiki/Binaural_recording}{highly
  correlated} (especially when the microphone is mono because both
channels are identical), which means that we can find a more efficient
representation. To perform this inter-channel
\href{https://en.wikipedia.org/wiki/Decorrelation}{decorrelation}~\cite{thinkstats}
we can use the \href{https://en.wikipedia.org/wiki/Linear_map}{linear
  transform}~\cite{strang4linear}
\begin{equation}
  {\mathbf w} = {\mathbf K}{\mathbf x} =
\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}
{\mathbf x},
  \label{eq:forward_transform_matrix_form}
\end{equation}
that can be also written as
\begin{equation}
  \begin{bmatrix}
    {\mathbf w}_0 \\
    {\mathbf w}_1
  \end{bmatrix}
  = 
  \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}
  \begin{bmatrix}
    {\mathbf x}_0 \\
    {\mathbf x}_1
  \end{bmatrix},
  \label{eq:forward_transform_matrix_form2}
\end{equation}
where ${\mathbf x}\in\mathbb{Z}^2$ is a stereo frame, ${\mathbf K}$ is
the (forward or analysis) transform matrix, and ${\mathbf
  w}=\begin{bmatrix} {\mathbf w}_0 & {\mathbf w}_1\end{bmatrix}^{\text
  T}$ is the corresponding
\href{https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Example_in_image_processing}{decomposition}. In
this particular transform, the decomposition has two
\href{https://en.wikipedia.org/wiki/Sub-band_coding}{subbands}
${\mathbf w}_0$ and ${\mathbf w}_1$, and each subband has only one
\href{https://web.stanford.edu/class/ee398a/handouts/lectures/07-TransformCoding.pdf}{coefficient}. Notice
that ${\mathbf x}\in\mathbb{Z}^2$ is a vector space\footnote{Adding
two vectors in the plane produces a third one also in the plane;
multiplying a vector by a real scalar produces a second vector also in
the plane. These two ingrained facts make the real plane be a vector
space.~\cite{vetterli2014foundations}}.

The proposed matrix ${\mathbf K}$ corresponds to the transform used in
\href{https://en.wikipedia.org/wiki/Joint_encoding#M/S_stereo_coding}{Mid/Side
  (M/S) stereo coding}~\cite{bosi2003intro} that we will call MST
(Mid/Side Transform). This is similar to the $2\times 2$ KLT
\href{http://fourier.eng.hmc.edu/e161/lectures/klt/node3.html}{(Karhunen-Lo\`eve
  Transform)}, the
\href{http://wavelets.pybytes.com/wavelet/haar/}{Haar
  Transform}~\cite{vetterli1995wavelets} and the $2\times 2$
\href{https://en.wikipedia.org/wiki/Hadamard_transform}{Discrete
  Walsh-Hadamard Transform}~\cite{sayood2017introduction}.

In general (for all the linear transforms),
Eqs.~\ref{eq:forward_transform_matrix_form} and
\ref{eq:forward_transform_matrix_form2} can be also expressed as
\begin{equation}
  {\mathbf w}_u = \sum_i {\mathbf K}_{u,i}{\mathbf x}_i,
  \label{eq:forward_transform_linear_combination_form}
\end{equation}
where ${\mathbf K}_{u,i}$ denotes $i$-th element of the $u$-th row of
the matrix ${\mathbf K}$.

A major difference between the transformed data ${\mathbf w}$ and the
original data ${\mathbf x}$ is that the characteristics of the
elements of ${\mathbf w}$ are determined by their position within the
decomposition ${\mathbf w}$~\cite{sayood2017introduction}. Thus, as a
consequence of how the matrix has been defined, the subband ${\mathbf
  w}_0$ represents (very roughly) the low frequencies of ${\mathbf
  x}$, and ${\mathbf w}_1$ the high frequencies. Therefore, the values
of ${\mathbf K}_0$ (the row 0 of ${\mathbf K}$) describe a
\href{https://en.wikipedia.org/wiki/Low-pass_filter}{low-pass filter},
the values of ${\mathbf K}_1$ describe a
\href{https://en.wikipedia.org/wiki/High-pass_filter}{high-pass
  filter}, and ${\mathbf K}$ represents the
\href{https://en.wikipedia.org/wiki/Digital_filter}{filters} of a
\href{https://en.wikipedia.org/wiki/Filter_bank}{filter bank} with two
filters. This can be also seen in this
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/11-stereo_coding/stereo_transforms_RD.ipynb}{notebook}.

\subsection{The synthesis transform}
The inverse (or synthesis) transform
\begin{equation}
  {\mathbf x} = {\mathbf K}^{-1}{\mathbf w}
  \label{eq:inverse_transform}
\end{equation}
can be found from Eq. \ref{eq:forward_transform_matrix_form}, where we
get that
\begin{equation}
  \begin{array}{rcl}
  {\mathbf w}_0 & = & {\mathbf x}_0 + {\mathbf x}_1\\
  {\mathbf w}_1 & = & {\mathbf x}_0 - {\mathbf x}_1.
  \end{array}
\end{equation}
By solving ${\mathbf x}_0$ (adding) and ${\mathbf x}_1$ (substracting) in
these equations, we obtain that
\begin{equation}
  \begin{array}{rcl}
  {\mathbf x}_0 & = & \frac{1}{2}({\mathbf w}_0 + {\mathbf w}_1)\\
  {\mathbf x}_1 & = & \frac{1}{2}({\mathbf w}_0 - {\mathbf w}_1),
  \end{array}
\end{equation}
that in matrix form becomes
\begin{equation}
  \begin{bmatrix}
    {\mathbf x}_0 \\
    {\mathbf x}_1
  \end{bmatrix}
  = \frac{1}{2}
  \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}
  \begin{bmatrix}
    {\mathbf w}_0 \\
    {\mathbf w}_1
  \end{bmatrix}.
\end{equation}
Therefore,
\begin{equation}
  {\mathbf x} = {\mathbf K}^{-1}{\mathbf w} = \frac{1}{2}{\mathbf K}^{\text T}{\mathbf w} = \frac{1}{2}{\mathbf K}{\mathbf w} = \frac{1}{2}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}{\mathbf w}.
  \label{eq:inverse_transform_matrix_form}
\end{equation}

\subsection{Orthogonality of the transform}
As can be seen (previously ignoring the $\frac{1}{2}$ scale factor)
the inverse transform is the transpose of the forward transform
(${\mathbf K}^{-1}={\mathbf K}^{\text T}$). This is a characteristic
of all
\href{https://en.wikipedia.org/wiki/Orthogonal_transformation}{orthogonal
  transforms}~\cite{sayood2017introduction}. For the MST,
specifically, it also holds that ${\mathbf K}^{\text T}={\mathbf K}$
because ${\mathbf K}$ is
\href{https://en.wikipedia.org/wiki/Symmetric_matrix}{symmetric}.

Apart from checking that ${\mathbf K}^{-1}={\mathbf K}^{\text T}$,
${\mathbf K}$ is orthogonal if the
\href{https://en.wikipedia.org/wiki/Inner_product_space}{inner
  product}\footnote{The inner product between two vectors is in some
sense a measure of how ``similar'' they are
\cite{sayood2017introduction}. In fact, the dot product computes the
norm (a measure of the distance between
vectors).~\cite{vetterli2014foundations} Notice also, that the inner
product is
\href{https://math.stackexchange.com/questions/476738/difference-between-dot-product-and-inner-product}{also
  called} the \href{https://en.wikipedia.org/wiki/Dot_product}{dot
  product} and the scalar product when we work with
\href{https://en.wikipedia.org/wiki/Real_number}{real}
signals.~\cite{vetterli2014foundations}} of the filters\footnote{When
we are working with discrete signals, we usually talk about vectors
instead of functions. These vectors are sampled versions of the
corresponding functions, or as happen in our case, the
\href{https://en.wikipedia.org/wiki/Finite_impulse_response}{taps} of
the filters, each one representing a
\href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis
  vectors}.} of ${\mathbf K}$ is $0$ between the different
filters\footnote{If a set of vectors are linearly independent, then
the set is called a basis for the subspace generated by linear
combinations of this set. The basis set contains the smallest number
of linearly independent vectors required to represent each element of
the vector (sub)space. The number of basis vectors required to
generate the space is called the dimension of the vector
space~\cite{sayood2017introduction}. In our case, for the MST, we have
two basis vectors.}. In our case ${\mathbf K}_0=\begin{bmatrix}1 &
1\end{bmatrix}$~ and ${\mathbf K}_1=\begin{bmatrix} 1 &
-1\end{bmatrix}$~, and as we can see
\begin{equation}
  \langle {\mathbf K}_0,{\mathbf K}_1 \rangle =
  \langle \begin{bmatrix}
    1 & 1
  \end{bmatrix}
  ,
  \begin{bmatrix}
    1 & -1
  \end{bmatrix}
  \rangle =
  \begin{bmatrix}
    1 & 1
  \end{bmatrix}
  \cdot
  \begin{bmatrix}
    1 & -1
  \end{bmatrix}
   = 1\times 1 + 1\times -1 = 0,
\end{equation}
which means that the filters ${\mathbf K}_0$ and ${\mathbf K}_1$ are linearly
independent\footnote{In terms of orthogonality, this means that we
  cannot derive one from the other using the operations that define a
  vector space, and therefore the basis vectors can be a part a basis
  (set)~\cite{strang4linear}.}.

Notice also that
\begin{equation}
  {\mathbf w}_i = \langle {\mathbf x}, {\mathbf K}_i\rangle,
\end{equation}
which basically means\footnote{Remember that for the MST a subband has
  only one coefficient. For other transforms, ${\mathbf w}_i$ can be
  made up of more than one coefficient and therefore, we would be
  speaking of the coefficients of the subband, instead of only one
  coefficient.} that ${\mathbf w}_i$ is proportional to the similarity
between the input signal ${\mathbf x}$ and the
\href{https://en.wikipedia.org/wiki/Finite_impulse_response}{taps} of
the filter ${\mathbf K}_i$. These
\href{https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf}{slides}
can help you with this key idea.

Orthogonality is important in compression applications because the
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlation}
between subbands is 0, and therefore, the contributions of the
subbands to the reconstruction of the original signal are
independent\footnote{The total
  \href{https://en.wikipedia.org/wiki/Distortion}{distortion} is the
  sum of the distortion contribution of each
  subband~\cite{sayood2017introduction}.}. Another interesting
property satisfied by a lot of famous transforms (such as the
\href{https://en.wikipedia.org/wiki/Fourier_transform}{Fourier
  Transform}) is
\href{https://en.wikipedia.org/wiki/Orthonormality}{orthonormality},
which means that the transform is
\href{https://en.wikipedia.org/wiki/Energy_(signal_processing)}{energy}
preserving~\cite{sayood2017introduction} (or that the
\href{https://en.wikipedia.org/wiki/Parseval%27s_theorem}{Parseval's theorem}
  is satisfied, in both, the analysis and the synthesis transform).

The MST analysis is not orthonormal, because
\begin{equation}
  \sum_i {{\mathbf w}_i}^2 =
  ({\mathbf x}_0 + {\mathbf x}_1)^2 + ({\mathbf x}_0 - {\mathbf x}_1)^2 =
  ({\mathbf x}_0^2 + 2{\mathbf x}_0{\mathbf x}_1+{\mathbf x}_1^2) + ({\mathbf x}_0^2-{\mathbf 2}x_0{\mathbf x}_1+{\mathbf x}_1^2) =
  2({\mathbf x}_0^2+{\mathbf x}_1^2) =
  2\sum_i {{\mathbf x}_i}^2.
  \label{eq:No_Parseval}
\end{equation}
For this reason, we must divide the synthesized samples by $2$ (see
Eq.~\ref{eq:inverse_transform_matrix_form}). On the contrary, we would
get $2{\mathbf x}$ as the reconstructed signal instead of ${\mathbf x}$.

% About quantizing the subbands
\subsection{Quantization of the subbands}
Ideally, the quantization step $\Delta_i$ used for a subband ${\mathbf w}_i$
must operate in the RD curve $f_i$ with the same
slope~\cite{vetterli2014foundations,sayood2017introduction} (this is
the same to say that we must satisfy that $f'_0(x)=f'_1(x)$, where
$f'$ denotes the derivative of $f$). The main drawback of this
approach is that the finding of $f_i$ is computationally intensive (we
must analyze, quantize, compress, decompress, dequantize, synthesize
and compute the distortion of the data for a enoughly high number of
quantization steps), and usually we cannot do that in real-time
applications.\footnote{Notice, however, that this would solve the
problem of controlling the bit-rate because using the RD curves we
know how many bits will require each subband.}

An approximation to this could be to suppose that the RD curves of the
subbands resulting from the analysis of our current piece of data
(remember, two samples of a stereo frame in our case) are similar to
the curves of previous pieces, that has already been compressed and
transmitted, and therefore, we can compute also the distortion. Using
this information, we can estimate a RD curve for the current piece,
and find the quantization steps. This procedure is much faster than
the described in the previou paragraph, but it may still be
time-consuming.

For this reason, in the previous
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/11-stereo_coding/stereo_transforms_RD.ipynb}{notebook}
we explore a different solution based on the idea of that the
contribution (in terms of energy) of the subbands to the
reconstruction of the signal ${\mathbf x}$ is proportional to the
\href{https://en.wikipedia.org/wiki/Filter_(signal_processing)}{gain}
of each analysis filter of ${\mathbf K}$ (remember that we are working
with orthogonal transforms and therefore, the contribution of the
subbands are independent), or what is the same, proportional to the gain of each
column of the syntesis matrix\footnote{Notice that the quantization
error is generated in the transform domain and perceived in the signal
domain after appliying the inverse transform.}. Thus, if the filters
had different gains, the quantization steps should consider this
fact.\footnote{Notice that the important here is the relative gain of
each subband. For example, if the gain of ${\mathbf K}_0$ were $2$ and
the gain of ${\mathbf K}_1$ were $1$, and the dynamic range of
${\mathbf w}_0$ and ${\mathbf w}_1$ is the same, we could use
$\Delta_1=2\Delta_0$ and expect to minimize the distortion.}

By definition, the gain of the subband ${\mathbf w}_i$ is the
\href{https://en.wikipedia.org/wiki/Lp_space}{L$_2$
  norm}\footnote{L$_2(f)$ (where $f$ is a function) is the set of all
functions with finite energy and constitues a vector
space~\cite{sayood2017introduction}. $L_2({\mathbb R})$ of simply
$L_2$ is the space of all functions $f(t)$ with a well defined
integral of the square of the modulus of the function. The $L$
signifies a Lebesque integral, the ``2'' denotes the integral of the
square of the modulus of the function, and ${\mathbb R}$ states that
the independent variable of integration is a number over the whole
real line. For a function $g(t)$ to be a member of that space is
denoted: $g\in L_2({\mathbb R})$ or simply $g\in
L_2$~\cite{burrus2013wavelets}. The computation of the L$_2$ form is
equivalent to compute the
\href{https://en.wikipedia.org/wiki/Euclidean_distance}{Euclidean
  distance} in $N$-dimensional (in our case, $N=2$)
\href{https://en.wikipedia.org/wiki/Vector_space}{spaces}.} of the
filter ${\mathbf K}_i$ (remember that for the MST, the rows of the
analysis matrix are equal to the columns of the synthesis
matrix). Thus

\begin{equation}
  \begin{array}{l}
    \left\| {\mathbf K}_0 \right\|_2 := \sqrt{\langle \begin{bmatrix}1 & 1\end{bmatrix}, \begin{bmatrix}1 & 1\end{bmatrix} \rangle} = \sqrt{\begin{bmatrix}1 & 1\end{bmatrix} \cdot \begin{bmatrix}1 & 1\end{bmatrix}} = \sqrt{2},\\
    \left\| {\mathbf K}_1 \right\|_2 := \sqrt{\langle \begin{bmatrix}1 & -1\end{bmatrix}, \begin{bmatrix}1 & -1\end{bmatrix} \rangle} = \sqrt{\begin{bmatrix}1 & -1\end{bmatrix}\cdot \begin{bmatrix}1 & -1\end{bmatrix}} = \sqrt{2},
  \end{array}
\end{equation}
resulting that both subbands ${\mathbf w}_1$ and ${\mathbf w}_2$ have
the same gain ($\sqrt{2}$). This result tell us that both subbands
could use the same quantization step ($\Delta_0=\Delta_1$). In the
\href{https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/11-stereo_coding/stereo_transforms_RD.ipynb}{notebook}
there are some evidences of this.

Unfortunately, most of the transform are not implemented using
matrix-vector operations, but using
\href{https://en.wikipedia.org/wiki/Fast_Fourier_transform}{faster
  algorithms} based on a lattice of
\href{https://en.wikipedia.org/wiki/Butterfly_diagram}{computational
  bufferflies} or filter
\href{https://en.wikipedia.org/wiki/Filter_(signal_processing)}{convolutions}
(and therefore, we don't know ${\mathbf K}$). In general, we can
determine ${\mathbf K}_i$ simply by computing the inverse transform of
the decomposition
$\begin{bmatrix} 0 & \cdots & 0 & 1 & 0 & \cdots &
  0 \end{bmatrix}^{\text T}$, where the $1$ value is in the position
$i$ (only the subband ${\mathbf w}_i=1$, the rest are
``zeroed'')).\footnote{Notice that this operation will ``extract'' the
  $i$-th column from ${\mathbf K}^{-1}$ that is equivalent to say that
  will ``extract'' the $i$-th row of ${\mathbf K}$, ${\mathbf K}_i$
  (remember that for orthogonal transforms,
  ${\mathbf K}^{-1}={\mathbf K}^{\text T}$).} In our example, we get
that

\begin{equation}
  \begin{array}{l}
    {\mathbf K}_0 =
    \begin{bmatrix}
      1 & 1 \\
      1 & -1
    \end{bmatrix}
          \begin{bmatrix}
            1 \\
            0
          \end{bmatrix}
    =
    \begin{bmatrix}
      1 & 1
    \end{bmatrix},
    \\
    {\mathbf K}_1 = 
    \begin{bmatrix}
      1 & 1 \\
      1 & -1
    \end{bmatrix}
          \begin{bmatrix}
            0 \\
            1
          \end{bmatrix}
    =
    \begin{bmatrix}
      1 & -1
    \end{bmatrix},
  \end{array}
\end{equation}
that as you can see, correspond to the columns of the inverse
transform matrix ${\mathbf K}^{-1}$. Notice that this is true for all
the orthogonal transforms whose analysis and synthesis matrices are
simmetrical.% because in that case ${\mathbf K}^{-1}={\mathbf K}^{\text T}$.

\begin{comment}
Unfortunately, this
estatement is only true if the
\href{https://en.wikipedia.org/wiki/Entropy_encoding}{entropy coding}
stage generates the same number of bits for both subbands, something
that rarely happens because we are compressing the coefficients of the
subbands considering the complete chunk (remember that we are
exploiting the
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{statistical
  correlation} between the sequence of coefficients generated by all
the frames of a chunk). In general, the amount of information provided
by each subband $w_i$ is different, and therefore, the discrete
\href{https://en.wikipedia.org/wiki/Rate%E2%80%93distortion_theory}{Rate
  Distortion} (RD) curve\footnote{A discrete RD curve is defined by
the
\href{https://en.wikipedia.org/wiki/Multi-objective_optimization}{Pareto
  front} form by the RD points.} generated by each subband is distint.

The standard solution for this problem is to select a $\Delta_i$ value
for each $w_i$ that select RD points with the same RD
\href{https://en.wikipedia.org/wiki/Slope}{slope}~\cite{vetterli2014foundations,sayood2017introduction}.
A RD point is defined as a pair or $(r,d)$ values where $r$ represents
a bit-rate (typically expressed in bits/sample) and $d$ represents a
distortion (that uses to be the
\href{https://en.wikipedia.org/wiki/Root-mean-square_deviation}{RMSE}
when we use the L$_2$ norm to measure distances). Therefore, to find
the two RD curves for the current chunk, we should apply the stereo
transform, use a set of quantization steps to each subband, and
compress the resulting quantization indexes for each quantization
step. This would find the $r$ values of our RD curve. Then,
decompress, dequantize and find the distortion for the chunk. This
would find the $d$ values. Finally, with this RD curve, we should
select the $\Delta_i$ values that provides the same slope for both
subbands.

Obviously, we can not use the previous algoritm for computing the RD
curves in a real-time application such as InterCom.\footnote{The
amount of computational resources would increase significatively.} We
need to make some assumptions in order to reduce the computational
cost of finding the RD curves. The first of our assumptions is that
between (temporally) adjacent chunks the RD curves are going to be
similar. Therefore, we can build the RD curve for the current chunk by
using the RD points generated\footnote{Each chunk is quantized and
compressed, so, we only need to compute the distortion to have the RD
point used for the chunk.} by the compression of previously processed
chunks. The second assumption is that we can estimate the average
slope of the complete RD curve by using only 2 RD points. Using this
information, we will try to use, for the current chunk, a pair of
$\Delta_i$ quantization steps that produce two RD curves (one curve
per subband) with the same average slope.
\end{comment}

\section{What you have to do?}

As we did in the previous milestone, generate the RD curves for a set
of simulated transmission contexts. Use the modules
\texttt{stereo\_MST\_coding\{|\_16|\_32\}.py}. As you can see, they
differs in how the transform has been implemented.

\begin{comment}
\begin{enumerate}
\item In a module named stereo\_coding.py, inherit the class
  Quantization and create a class named Stereo\_Coding.
\item Override the methods pack() and unpack(). In pack() perform the
  analysis transform previously described, and in unpack() the
  synthesis transform. These procedures should be applied to all the
  frames of a chunk using
  \href{https://www.oreilly.com/library/view/python-for-data/9781449323592/ch04.html}{vectorized
    operations}.
\item Has the
  \href{https://en.wikipedia.org/wiki/Data_compression_ratio}{compression
    ratio} been improved (on
  \href{https://en.wikipedia.org/wiki/Average}{average})? How much?
\end{enumerate}
\end{comment}

\section{Timming}

You should reach this milestone at most one week.

\section{Deliverables}

The RD curves and the required information to redo them.

\section{Resources}

\bibliography{maths,data-compression,DWT,audio-coding,signal-processing}
