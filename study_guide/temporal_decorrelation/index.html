<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>TecnologÃ&#x014B;as Multimedia - Study Guide - Milestone 12: Temporal decorrelation in
audio signals</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (https://tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (https://tug.org/tex4ht/)"> 
<!-- html --> 
<meta name="src" content="index.tex"> 
<link rel="stylesheet" type="text/css" href="index.css"> 
</head><body 
>
   <div class="maketitle">
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class="titleHead"><a 
href="https://www.ual.es/estudios/grados/presentacion/plandeestudios/asignatura/4015/40154321?idioma=zh_CN" >Tecnologías Multimedia</a> - Study Guide -
Milestone 12: Temporal decorrelation in audio
signals</h2>
 <div class="author" ><a 
href="https://cms.ual.es/UAL/personas/persona.htm?id=515256515553484875" ><span 
class="ecrm-1200">Vicente Gonz</span><span 
class="ecrm-1200">ález Ruiz</span></a> <span 
class="ecrm-1200">- </span><a 
href="https://cms.ual.es/UAL/universidad/departamentos/informatica/index.htm" ><span 
class="ecrm-1200">Depto Inform</span><span 
class="ecrm-1200">ática</span></a> <span 
class="ecrm-1200">- </span><a 
href="https://www.ual.es" ><span 
class="ecrm-1200">UAL</span></a></div><br />
<div class="date" ><span 
class="ecrm-1200">January 2, 2021</span></div>
   </div>
   <h3 class="sectionHead"><span class="titlemark">1   </span> <a 
 id="x1-10001"></a>Description</h3>
<!--l. 8--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">1.1   </span> <a 
 id="x1-20001.1"></a>About temporal redundancy in audio</h4>
<!--l. 9--><p class="noindent" >After exploiting the spatial (stereo) redundancy in the previous
milestone, the next natural step in the development of InterCom is
to remove the temporal redundancy that can be found inside of each
subband<span class="footnote-mark"><a 
href="index2.html#fn1x0"><sup class="textsuperscript">1</sup></a></span><a 
 id="x1-2001f1"></a> .
As it can be seen in this <a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/audio_viewer.ipynb" >notebook</a>, most audio signals show &#8220;patterns&#8221; of samples
that tends to repeat, especially locally. Another clear source of temporal
redundancy is that the neighbor audio samples usually show similar amplitude
values.
<!--l. 23--><p class="indent" >   There are several techniques that can be used for removing the temporal
redundancy of a sequence of audio. One of the most straightforward is <a 
href="https://en.wikipedia.org/wiki/Differential_pulse-code_modulation" >Differential
Pulse Code Modulation (DPCM)&#x00A0;<span class="cite">[<a 
href="#Xsayood2017introduction">2</a>]</span></a>. However, there are more efficient decorrelation
algorithms based on <a 
href="https://en.wikipedia.org/wiki/Transform_coding" >transform coding</a>, such as the used in the previous milestone and
in this one.
                                                                  

                                                                  
<!--l. 34--><p class="indent" >   Transform coding is based on the idea that we can decompose (we can generate a
decomposition from) the input signal into a set of subbands, and if the used filters
are the adecuate ones for removing the temporal redundancy, we can achieve a high
transform <a 
href="https://en.wikipedia.org/wiki/Coding_gain" >coding gain</a>, accumulating most of the signal energy (and presumably most
of the information) in a small number of subbands. When this happens,
the quantization of the subbands will remove basically the least significant
information (usually <a 
href="https://en.wikipedia.org/wiki/Noise_(electronics)" >electronic noise</a>), allowing better compression ratios
than those in which we apply the same quantization process to the original
samples.<span class="footnote-mark"><a 
href="index3.html#fn2x0"><sup class="textsuperscript">2</sup></a></span><a 
 id="x1-2002f2"></a> 
<!--l. 50--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
                                                                  

                                                                  
<!--l. 52--><p class="noindent" ><div style="text-align:center;"> <img width=500 src="graphics/PRFB.svg" /> </div>  <a 
 id="x1-2003r1"></a>
<a 
 id="x1-2004"></a>
<br />                                                                  <div class="caption" 
><span class="id">
Figure&#x00A0;1: </span><span  
class="content">A 2-channels PRFB (Perfect Reconstruction Filter Bank).         </span></div><!--tex4ht:label?: x1-2003r1 -->
                                                                  

                                                                  
<!--l. 55--><p class="indent" >   </div><hr class="endfigure">
   <h4 class="subsectionHead"><span class="titlemark">1.2   </span> <a 
 id="x1-30001.2"></a>Transform and subband coding</h4>
<!--l. 59--><p class="noindent" >The name that has been given to the previous process is <a 
href="https://en.wikipedia.org/wiki/Sub-band_coding" >subband coding</a>. In this
context, our analysis transform matrix <span 
class="cmmi-10">K </span>(see the previous milestone) represents the
taps of a 2-channels analysis <a 
href="https://en.wikipedia.org/wiki/Filter_bank" >Filter Bank (FB)</a>&#x00A0;<span class="cite">[<a 
href="#Xvetterli1995wavelets">4</a>]</span>, and the forward transform is in
fact &#8220;descomposing&#8221; <span 
class="cmmi-10">x </span>into two subbands <span 
class="cmmi-10">w</span><sub><span 
class="cmr-7">0</span></sub> and <span 
class="cmmi-10">w</span><sub><span 
class="cmr-7">1</span></sub> (see the Figure&#x00A0;<a 
href="#x1-2003r1">1<!--tex4ht:ref: fig:PRFB --></a>, and this
<a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/PRFB.ipynb" >notebook</a>). On the other hand, the synthesis transform matrix <span 
class="cmmi-10">K</span><sup><span 
class="cmsy-7">-</span><span 
class="cmr-7">1</span></sup> denotes the taps
of the corresponding synthesis FB that allows to recover <span 
class="cmmi-10">x </span>(notice that in
the figure, <span 
class="cmmi-10">x </span><span 
class="cmr-10">= </span><span 
class="cmmi-10">l</span><sup><span 
class="cmmi-7">i</span></sup>, <span 
class="cmmi-10">w</span><sub><span 
class="cmr-7">0</span></sub> <span 
class="cmr-10">= </span><span 
class="cmmi-10">l</span><sup><span 
class="cmmi-7">i</span><span 
class="cmr-7">+1</span></sup>, <span 
class="cmmi-10">w</span><sub><span 
class="cmr-7">1</span></sub> <span 
class="cmr-10">= </span><span 
class="cmmi-10">h</span><sup><span 
class="cmmi-7">i</span><span 
class="cmr-7">+1</span></sup>, <span 
class="cmmi-10">&#x03D5; </span><span 
class="cmr-10">= </span><span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">0</span></sub>, <span 
class="cmmi-10">&#x03C8; </span><span 
class="cmr-10">= </span><span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">1</span></sub>, <img 
src="index0x.png" alt="&#x02DC;
&#x03D5;"  class="tilde" > <span 
class="cmr-10">= </span><span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">0</span></sub><sup><span 
class="cmsy-7">-</span><span 
class="cmr-7">1</span></sup>, and
<img 
src="index1x.png" alt=" &#x02DC;
&#x03C8;"  class="tilde" > <span 
class="cmr-10">= </span><span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">1</span></sub><sup><span 
class="cmsy-7">-</span><span 
class="cmr-7">1</span></sup>).
<!--l. 75--><p class="indent" >   Let&#8217;s suppose now that the filters (represented by the taps of) <span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">0</span></sub> and <span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">1</span></sub> are
applied to the input signal <span 
class="cmmi-10">x </span>(now a sequence of <span 
class="cmmi-10">N </span>samples) using a <a 
href="https://en.wikipedia.org/wiki/Kernel_(image_processing)" >convolution</a>
(without splitting <span 
class="cmmi-10">x </span>into blocks). Let&#8217;s also suppose (as happens in the MST) that
<span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">0</span></sub> is a low-pass filter and <span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">1</span></sub> is a high-pass filter, and that the <a 
href="https://en.wikipedia.org/wiki/Filter_(signal_processing)#The_transfer_function" >transfer
function</a><span class="footnote-mark"><a 
href="index4.html#fn3x0"><sup class="textsuperscript">3</sup></a></span><a 
 id="x1-3001f3"></a> 
of both filters <a 
href="https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks" >are one the inverse of the other</a>. Under these assumptions,
the complete (analysis/synthesis) transform is called a (2-channels) <a 
href="https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks" >Perfect
Reconstruction Filter Bank (PRFB)</a>, and <span 
class="cmmi-10">x </span>can be recovered (perfectly)
from a subsampled version (in this case <a 
href="https://en.wikipedia.org/wiki/Downsampling_(signal_processing)" >decimating</a> by 2) of <span 
class="cmmi-10">w</span><sub><span 
class="cmr-7">0</span></sub> and <span 
class="cmmi-10">w</span><sub><span 
class="cmr-7">1</span></sub>
(see the <a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/PRFB.ipynb" >notebook</a>). Notice that this subsampling is possible because the
<a 
href="https://en.wikipedia.org/wiki/Aliasing" >aliasing</a><span class="footnote-mark"><a 
href="index5.html#fn4x0"><sup class="textsuperscript">4</sup></a></span><a 
 id="x1-3002f4"></a> 
generated in the low-pass subband is compensated by the aliasing generated in the
high-pass subband. To achieve this, the <a 
href="https://en.wikipedia.org/wiki/Filter_(signal_processing)#The_transfer_function" >frequency response</a> of <span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">0</span></sub> must be
equal to the mirror frequency response of <span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">1</span></sub>, and obviously, both filters
must have the same bandwidth&#x00A0;<span class="cite">[<a 
href="#Xsayood2017introduction">2</a>]</span>. In this situation, in which <span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">1</span></sub> and <span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">2</span></sub>
are mirror filters, we say that they form a <a 
href="https://en.wikipedia.org/wiki/Quadrature_mirror_filter" >Quadrature Mirror Filters Bank
(QMF)</a>.
   <h4 class="subsectionHead"><span class="titlemark">1.3   </span> <a 
 id="x1-40001.3"></a>Multichannel filter banks and psychoacoustic frequency resolution</h4>
<!--l. 114--><p class="noindent" >Using the suitable filters, it is possible to build <span 
class="cmmi-10">M</span>-channels
PRFBs.<span class="footnote-mark"><a 
href="index6.html#fn5x0"><sup class="textsuperscript">5</sup></a></span><a 
 id="x1-4001f5"></a> 
These filters can analyze (and synthesize) the signal <span 
class="cmmi-10">x</span>, decomposing it in
(<a 
href="https://en.wikipedia.org/wiki/Low-pass_filter#Ideal_and_real_filters" >almost for sure</a>) overlaping frequency subbands with different bandwidth.
                                                                  

                                                                  
The question here is to know how many filters should be used and what
<a 
href="https://en.wikipedia.org/wiki/Band-pass_filter" >pass-band</a> width should they have. At this design point, we must also consider
that the accuracy of the <a 
href="https://en.wikipedia.org/wiki/Psychoacoustics" >humman perception of the sound</a> depends on the
frequency: (as it can be checked in this <a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/frequency_resolution.ipynb" >notebook</a>) we are more sensitive to
frequency variations when the frequency of the sound is low. This fact is
related with the way in which the <a 
href="https://en.wikipedia.org/wiki/Critical_band" >critical bands</a> are distributed in <a 
href="https://en.wikipedia.org/wiki/Bark_scale" >the bark
scale</a>.
   <h4 class="subsectionHead"><span class="titlemark">1.4   </span> <a 
 id="x1-50001.4"></a>The Discrete Wavelet Transform</h4>
<!--l. 137--><p class="noindent" >As it can be seen, the bark scale divides the audible spectrum into 24 subband of (a
priori) &#8220;whimsical&#8221; bandwidths. However, it&#8217;s clear that a <a 
href="https://en.wikipedia.org/wiki/Octave_band" >dyadic partition of the
spectrum</a> fits better than <a 
href="https://en.wikipedia.org/wiki/Wavelet_transform#Principle" >a lineal partition</a>. Considering this reason, from all
the families of transforms designed to date, the most suitable one, from a
frequency partitioning point of view, is the Discrete Wavelet Transform
(DWT).
<!--l. 147--><p class="indent" >   The DWT has also other interesting features:
     <ol  class="enumerate1" >
     <li 
  class="enumerate" id="x1-5002x1">It is <a 
href="https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Time_complexity" >fast</a> (<span 
class="cmmi-10">O</span><span 
class="cmr-10">(</span><span 
class="cmmi-10">N</span><span 
class="cmr-10">)</span>, where <span 
class="cmmi-10">N </span>is the number of &#8220;transformed&#8221; samples).
     </li>
     <li 
  class="enumerate" id="x1-5004x2">It can represent efficienty <a 
href="https://en.wikipedia.org/wiki/Transient_(oscillation)" >transient</a> signals, which can happen frequently
     in audio.
     </li>
     <li 
  class="enumerate" id="x1-5006x3">Although we are not going to take advantage of the following characteristic
     (for now), one of the most interesting features of the DWT is that it can
     used to find a <a 
href="https://en.wikipedia.org/wiki/Multiresolution_analysis" >multiresolution representation</a> of the signal.</li></ol>
<!--l. 162--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
                                                                  

                                                                  
<!--l. 164--><p class="noindent" ><div style="text-align:center;"> <img width=1000 src="graphics/cascade.svg" /> </div>  <a 
 id="x1-5007r2"></a>
<a 
 id="x1-5008"></a>
<br />                                                                  <div class="caption" 
><span class="id">
Figure&#x00A0;2: </span><span  
class="content">A dyadic 2-levels cascade of PRFBs.                           </span></div><!--tex4ht:label?: x1-5007r1 -->
                                                                  

                                                                  
<!--l. 167--><p class="indent" >   </div><hr class="endfigure">
   <h4 class="subsectionHead"><span class="titlemark">1.5   </span> <a 
 id="x1-60001.5"></a>Implementation of the DWT</h4>
<!--l. 171--><p class="noindent" >The DWT can be implemented in different ways:
     <ol  class="enumerate1" >
     <li 
  class="enumerate" id="x1-6002x1">Defining  the  transform  matrix  <span 
class="cmmi-10">K  </span>(see  these  <a 
href="https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf" >slides</a>)  and  computing
     vector-matrix   multiplications,   which   requires   a   calculation   time
     proportional  to  <span 
class="cmmi-10">O</span><span 
class="cmr-10">(</span><span 
class="cmmi-10">N</span><sup><span 
class="cmr-7">2</span></sup><span 
class="cmr-10">)</span>.  However,  the  main  problem  of  this  type  of
     implementation is generated by the amount of memory that <span 
class="cmmi-10">K </span>requires,
     that is proportional to <span 
class="cmmi-10">N</span><sup><span 
class="cmr-7">2</span></sup>.
     </li>
     <li 
  class="enumerate" id="x1-6004x2"><a 
href="https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Cascading_and_filter_banks" >Cascading PRFBs</a> (see the Figure&#x00A0;<a 
href="#x1-5007r2">2<!--tex4ht:ref: fig:cascade --></a>). Considering that the <a 
href="https://en.wikipedia.org/wiki/Convolution" >convolution</a> is
     a <span 
class="cmmi-10">O</span><span 
class="cmr-10">(</span><span 
class="cmmi-10">N</span> <span 
class="cmr-10">log</span> <sub><span 
class="cmr-7">2</span></sub><span 
class="cmmi-10">N</span><span 
class="cmr-10">) </span>operation (if it is <a 
href="https://en.wikipedia.org/wiki/Convolution_theorem" >implemented in the frequency domain</a>),
     and that the number of levels in the cascade is generally small (5 for
     example), this implementation is faster than the based in vector-matrix
     arithmetic. And most importantly, we don&#8217;t need to store <span 
class="cmmi-10">K</span>, but only the
     taps of the filters that in a software implementation of a cascade can be as
     small as the number of different filters.<span class="footnote-mark"><a 
href="index7.html#fn6x0"><sup class="textsuperscript">6</sup></a></span><a 
 id="x1-6005f6"></a> 
     </li>
     <li 
  class="enumerate" id="x1-6007x3">Using <a 
href="https://en.wikipedia.org/wiki/Lifting_scheme" >lifting</a>&#x00A0;<span class="cite">[<a 
href="#Xsweldens1997building">3</a>]</span>, which provides an extra speed-up factor of 2 compared
     to the FB implementation. DWTs implemented with lifting do not need
     to downsample and upsample the subbands, an operation that is wasting
     the calculus of half of the coefficients at each level of the cascade.</li></ol>
<!--l. 201--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">1.6   </span> <a 
 id="x1-70001.6"></a>Example of a DWT using the MST filters</h4>
<!--l. 203--><p class="noindent" >In order to clarify the previously introduced concepts, let&#8217;s build a DWT using the
MST filters and lifting.
<!--l. 206--><p class="indent" >
     <ol  class="enumerate1" >
     <li 
  class="enumerate" id="x1-7002x1">Lifting is based on the concept of dyadic <a 
href="https://en.wikipedia.org/wiki/Multiresolution_analysis" >multiresolution analysis</a>, and also with
     the so called <a 
href="https://en.wikipedia.org/wiki/Polyphase_matrix" >polyphase representation</a> of signals. In order to do that, we can
     rewrite the MST filter equations (our <span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">0</span></sub> and <span 
class="cmsy-10">-</span><span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">1</span></sub> filters in the previous
     milestone) as
     <table 
class="equation"><tr><td><a 
 id="x1-7003r1"></a>
                                                                  

                                                                  
<div class="math-display" >
<img 
src="index2x.png" alt=" l1i  =  x2i + x2i+1
h1i  =  x2i+1 - x2i,
" class="math-display" ></div>
     </td><td class="equation-label">(1)</td></tr></table>
     <!--l. 220--><p class="nopar" >
     where the <span 
class="cmmi-10">s</span>-th subband <span 
class="cmmi-10">z</span><sup><span 
class="cmmi-7">s</span></sup> <span 
class="cmr-10">= </span><span 
class="cmsy-10">{</span><span 
class="cmmi-10">z</span><sub><span 
class="cmmi-7">i</span></sub><sup><span 
class="cmmi-7">s</span></sup><span 
class="cmmi-10">&#x00A0;</span><span 
class="cmsy-10">|</span><span 
class="cmmi-10">&#x00A0;</span><span 
class="cmr-10">0 </span><span 
class="cmsy-10">&#x2264; </span><span 
class="cmmi-10">i </span><span 
class="cmsy-10">&#x2264; </span><span 
class="cmr-10">2</span><sup><span 
class="cmmi-7">n</span><span 
class="cmsy-7">-</span><span 
class="cmmi-7">s</span></sup><span 
class="cmsy-10">}</span>, being <span 
class="cmr-10">2</span><sup><span 
class="cmmi-7">n</span></sup> <span 
class="cmr-10">= </span><span 
class="cmmi-10">N </span>the number
     of samples in <span 
class="cmmi-10">x</span>, and where, by definition, <span 
class="cmmi-10">l</span><sup><span 
class="cmr-7">0</span></sup> <span 
class="cmr-10">= </span><span 
class="cmmi-10">x</span>, the original resolution level of
     the signal. The subbands <span 
class="cmmi-10">l</span><sup><span 
class="cmr-7">1</span></sup> and <span 
class="cmmi-10">h</span><sup><span 
class="cmr-7">1</span></sup> computed by Eq.&#x00A0;<a 
href="#x1-7003r1">1<!--tex4ht:ref: eq:1dwt --></a> are the same
     than the decimated subbands computed by a 1-levels PRFB (based on
     that filters), and we say, therefore, that Eq.&#x00A0;<a 
href="#x1-7003r1">1<!--tex4ht:ref: eq:1dwt --></a> computes the 1-levels
     DWT.
     <!--l. 228--><p class="noindent" >Based on the 1-levels DWT, we define the 2-levels DWT as
     <table 
class="equation"><tr><td><a 
 id="x1-7004r2"></a>
<div class="math-display" >
<img 
src="index3x.png" alt="l2i  =  l21i + l12i+1
h2i  =  l21i+1 - l12i,
" class="math-display" ></div>
     </td><td class="equation-label">(2)</td></tr></table>
     <!--l. 235--><p class="nopar" >
     that, as we can see, uses as input the output of Eq.&#x00A0;<a 
href="#x1-7003r1">1<!--tex4ht:ref: eq:1dwt --></a>.
     <!--l. 238--><p class="noindent" >In general, for a <span 
class="cmmi-10">s</span>-levels DWT, we get
     <table 
class="equation"><tr><td><a 
 id="x1-7005r3"></a>
<div class="math-display" >
                                                                  

                                                                  
<img 
src="index4x.png" alt="lsi  =  ls2-i1+ ls2-i1+1
hsi  =  ls2-i+11 - ls2-i1.
" class="math-display" ></div>
     </td><td class="equation-label">(3)</td></tr></table>
     <!--l. 245--><p class="nopar" >
     <!--l. 247--><p class="noindent" >The <span 
class="cmmi-10">s</span>-levels DWT splits the signal spectrum in <span 
class="cmmi-10">s </span><span 
class="cmr-10">+ 1 </span>subbands. If <span 
class="cmmi-10">s </span><span 
class="cmr-10">= </span><span 
class="cmmi-10">n</span>, we
     have the spectrum partition
     <table 
class="equation-star"><tr><td>
<div class="math-display" >
<img 
src="index5x.png" alt="|ls|hs|hs-1hs-1|hs-2hs-2hs-2hs-2|&#x22C5;&#x22C5;&#x22C5;|h1h1&#x22C5;&#x22C5;&#x22C5;h1n-1  |,
 0  0 0   1   0   1   2   3       0 1    2  -1
" class="math-display" ></div>
     </td></tr></table>
     <!--l. 251--><p class="nopar" >
     where<span class="footnote-mark"><a 
href="index8.html#fn7x0"><sup class="textsuperscript">7</sup></a></span><a 
 id="x1-7006f7"></a> 
     it holds that
     <table 
class="equation"><tr><td><a 
 id="x1-7007r4"></a>
<div class="math-display" >
<img 
src="index6x.png" alt="   &#x2211;s
1+    2j-1 = 2n.
   j=1
" class="math-display" ></div>
     </td><td class="equation-label">(4)</td></tr></table>
                                                                  

                                                                  
     <!--l. 257--><p class="nopar" >
     </li>
     <li 
  class="enumerate" id="x1-7009x2">DWT performs a number of lifting steps, each one with 2 (sub)steps:
         <ol  class="enumerate2" >
         <li 
  class="enumerate" id="x1-7011x1">A <span 
class="ecbx-1000">predict step</span>, that computes the <span 
class="cmmi-10">h </span>subbands as a prediction error (that
         should be minimized) between the even samples (usually, the values used
         to predict) and the odd samples (usually, the values predicted). For the
         MST filters, we have that
         <table 
class="equation"><tr><td><a 
 id="x1-7012r5"></a>
<div class="math-display" >
<img 
src="index7x.png" alt="     s-1    s- 1
hsi = l2i+1 - l2i .
" class="math-display" ></div>
         </td><td class="equation-label">(5)</td></tr></table>
         <!--l. 268--><p class="nopar" >
         </li>
         <li 
  class="enumerate" id="x1-7014x2">An <span 
class="ecbx-1000">update step</span>, which computes the <span 
class="cmmi-10">l </span>subbands considering (only) the
         even samples and the prediction errors. For the MST, we have
         that
         <table 
class="equation"><tr><td><a 
 id="x1-7015r6"></a>
<div class="math-display" >
<img 
src="index8x.png" alt="lsi = 2ls-2i 1+ hsi.
" class="math-display" ></div>
         </td><td class="equation-label">(6)</td></tr></table>
         <!--l. 275--><p class="nopar" >
         </li></ol>
                                                                  

                                                                  
     <!--l. 278--><p class="noindent" >Notice that these steps are invertible:
     <table 
class="equation"><tr><td><a 
 id="x1-7016r7"></a>
<div class="math-display" >
<img 
src="index9x.png" alt=" s-1     1  s   s
ls2-i1   =  2(s-li1 - his)
l2i+1  =  l2i  + hi.
" class="math-display" ></div>
     </td><td class="equation-label">(7)</td></tr></table>
     <!--l. 284--><p class="nopar" >
     </li></ol>
<!--l. 288--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">1.7   </span> <a 
 id="x1-80001.7"></a>Wavelets and filter banks</h4>
<!--l. 289--><p class="noindent" >In the context of the wavelet theory&#x00A0;<span class="cite">[<a 
href="#Xburrus2013wavelets">1</a>]</span>, the response of the analysis low-pass filter (<span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">0</span></sub> in the MST)
to the <a 
href="https://en.wikipedia.org/?title=Unit_impulse&redirect=no" >unit impulse</a><span class="footnote-mark"><a 
href="index9.html#fn8x0"><sup class="textsuperscript">8</sup></a></span><a 
 id="x1-8001f8"></a> 
is known as the scaling function and is usually denoted by <span 
class="cmmi-10">&#x03D5;</span>, the response of the
analysis high-pass filter (<span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">1</span></sub>) is known as the wavelet function and it is
usually denoted by <span 
class="cmmi-10">&#x03C8;</span>, the response of the synthesis low-pass filter (<span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">0</span></sub><sup><span 
class="cmsy-7">-</span><span 
class="cmr-7">1</span></sup>) is
denoted by <img 
src="index10x.png" alt="&#x02DC;&#x03D5;"  class="tilde" > and the synthesis high-pass filter (<span 
class="cmmi-10">K</span><sub><span 
class="cmr-7">1</span></sub><sup><span 
class="cmsy-7">-</span><span 
class="cmr-7">1</span></sup>) is represented by
<img 
src="index11x.png" alt="&#x03C8;&#x02DC;"  class="tilde" >.
<!--l. 301--><p class="indent" >   For the MST it holds that <span 
class="cmmi-10">&#x03D5;</span><span 
class="cmsy-10">&#x22A5;</span><span 
class="cmmi-10">&#x03C8;</span>, that <span 
class="cmmi-10">&#x03D5; </span><span 
class="cmr-10">=</span> <img 
src="index12x.png" alt="&#x02DC;&#x03C8;"  class="tilde" > and that <span 
class="cmmi-10">&#x03C8; </span><span 
class="cmr-10">=</span> <img 
src="index13x.png" alt="&#x02DC;&#x03D5;"  class="tilde" > ,
and this is also true for all orthogonal DWTs. Another important
characteristic of orthogonal DWTs is that the filters cannot be
<a 
href="https://en.wikipedia.org/wiki/Symmetry" >symmetric</a>.<span class="footnote-mark"><a 
href="index10.html#fn9x0"><sup class="textsuperscript">9</sup></a></span><a 
 id="x1-8002f9"></a> 
                                                                  

                                                                  
   <h4 class="subsectionHead"><span class="titlemark">1.8   </span> <a 
 id="x1-90001.8"></a>Example of a DWT using high-order filters</h4>
<!--l. 313--><p class="noindent" >The previous MST-based DWT is similar to other transforms such as the <a 
href="https://en.wikipedia.org/wiki/Haar_wavelet" >Haar
transform</a>, in which we are using an 1-order predictor for removing the temporal
redundancy. Let&#8217;s extend the idea of lifting to a prediction of order two. For that, we
define the predict step as
   <table 
class="equation"><tr><td><a 
 id="x1-9001r8"></a>
   <div class="math-display" >
<img 
src="index14x.png" alt="hs = ls-1 - 1(ls-1 + ls-1)
 i   2i+1   2 2i    2i+2
" class="math-display" ></div>
   </td><td class="equation-label">(8)</td></tr></table>
<!--l. 320--><p class="nopar" >
and the update step as
   <table 
class="equation"><tr><td><a 
 id="x1-9002r9"></a>
   <div class="math-display" >
<img 
src="index15x.png" alt=" s   s- 1  1  s     s
li = l2i + 4(hi-1 + hi),
" class="math-display" ></div>
   </td><td class="equation-label">(9)</td></tr></table>
<!--l. 324--><p class="nopar" >
where the factor 1/4 is used to preserve the energy&#x00A0;<span class="cite">[<a 
href="#Xsweldens1997building">3</a>]</span>. This transform is known as the
<a 
href="https://en.wikipedia.org/wiki/Biorthogonal_wavelet" >biorthogonal</a> (2,2) of Cohen-Daubechies-Feauveau, and also as the linear transform.
Biorthogonal<span class="footnote-mark"><a 
href="index11.html#fn10x0"><sup class="textsuperscript">10</sup></a></span><a 
 id="x1-9003f10"></a> 
filters can be <a 
href="http://wavelets.pybytes.com/" >easely recognized</a> because they are always symmetric and because the
analysis filters are different to the synthesis filters (<span 
class="cmmi-10">&#x03D5;</span><span 
class="cmmi-10">&#x2260;</span><img 
src="index16x.png" alt="&#x03D5;&#x02DC;"  class="tilde" > and <span 
class="cmmi-10">&#x03C8;</span><span 
class="cmmi-10">&#x2260;</span><img 
src="index17x.png" alt="&#x03C8;&#x02DC;"  class="tilde" > ).
                                                                  

                                                                  
<!--l. 339--><p class="indent" >   The linear transform is also invertible by simply reversing the steps:
   <table 
class="equation"><tr><td><a 
 id="x1-9004r10"></a>
   <div class="math-display" >
<img 
src="index18x.png" alt="ls-2i 1 =   lsi - 14(hsi-1 +hsi)
ls2-i+11  =   hsi + 12(l2s-i1 + ls2-i+12).
" class="math-display" ></div>
   </td><td class="equation-label">(10)</td></tr></table>
<!--l. 345--><p class="nopar" >
   <h4 class="subsectionHead"><span class="titlemark">1.9   </span> <a 
 id="x1-100001.9"></a><a 
href="https://en.wikipedia.org/wiki/Lapped_transform" >Lapped transforms</a> for minimizing the distortion</h4>
<!--l. 348--><p class="noindent" >A final (and important) consideration about transform coding and quantization.
Transform coding implies splitting the signal into chunks, and computing the
transform of each chunk. When the coefficients are quantized, it is possible that
significative (and unpleasant) distortions may appear between the border
samples of the chunks (see this <a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/quantization_DWT.ipynb" >notebook</a>). One simple solution is to use the
last samples of the <span 
class="cmmi-10">i </span><span 
class="cmsy-10">- </span><span 
class="cmr-10">1</span>-th chunk and the first samples of the <span 
class="cmmi-10">i </span><span 
class="cmr-10">+ 1</span>-chunk
for computing the transform of the <span 
class="cmmi-10">i</span>-th chunk (notice that this <a 
href="https://en.wikipedia.org/wiki/Lapped_transform" >overlaping</a>
does not imply to generate more transform coefficients, but only to avoid
using an artificial <a 
href="https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html" >signal extension</a> at the limits of the chunks). The number
of overlaped samples depends on the length of the filters and the number
of levels <span 
class="cmmi-10">s </span>of the DWT. This last parameter (the number of levels of the
DWT) has also a high impact on the decorrelation process, but take into
consideration that, depending on the signal, usually happens that it is not worth
decomposing the signal into the maximum number of subbands because the increase
in the coding gain can be negligible beyond a number of levels (typically,
<span 
class="cmr-10">5</span>).
<!--l. 371--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">2   </span> <a 
 id="x1-110002"></a>What you have to do?</h3>
<!--l. 373--><p class="noindent" >
     <ol  class="enumerate1" >
     <li 
  class="enumerate" id="x1-11002x1">In   a   module   named   temporal_decorrelate.py,   inherit   the   class
     Stereo_decorrelation and create a class named Temporal_decorrelation.
                                                                  

                                                                  
     </li>
     <li 
  class="enumerate" id="x1-11004x2">Select a suitable<span class="footnote-mark"><a 
href="index12.html#fn11x0"><sup class="textsuperscript">11</sup></a></span><a 
 id="x1-11005f11"></a> 
     DWT from <a 
href="https://pywavelets.readthedocs.io/en/latest/" >PyWavelets</a> and transform the MST subbands. Take also into
     consideration that the signal should be processed using overlaped chunks
     in order to minimize the discontinuities of the reconstructed signal at the
     chunk boundaries, when the DWT coefficients are quantized. Obviously,
     implement also the inverse stuff for recovering the audio signal.
     </li>
     <li 
  class="enumerate" id="x1-11007x3">Compare  the  RD  (Rate/Distortion)  curves  generated  by  the  modules
     br_control.py, stereo_decorrelate.py and temporal_decorrelate.py.</li></ol>
<!--l. 390--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">3   </span> <a 
 id="x1-120003"></a>Timming</h3>
<!--l. 392--><p class="noindent" >This is the final milestone. Present your results in the exam time.
<!--l. 394--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">4   </span> <a 
 id="x1-130004"></a>Deliverables</h3>
<!--l. 396--><p class="noindent" >The module temporal.py. Store it at the <a 
href="https://github.com/Tecnologias-multimedia/intercom" >root directory</a> of your InterCom&#8217;s
repo.
<!--l. 400--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">5   </span> <a 
 id="x1-140005"></a>Resources</h3>
   <div class="thebibliography">
   <p class="bibitem" ><span class="biblabel">
 [1]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a 
 id="Xburrus2013wavelets"></a>C.S.  Burrus,  R.&#x00A0;Gopinath,  and  H.&#x00A0;Guo.     <a 
href="https://cnx.org/contents/EQurkhlI@6.9:ZcNjPhDo@15/Preface" ><span 
class="ecti-1000">Wavelets  and  Wavelet</span>
   <span 
class="ecti-1000">Transforms</span></a>. Rice University, 2013.
   </p>
   <p class="bibitem" ><span class="biblabel">
 [2]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a 
 id="Xsayood2017introduction"></a>K.&#x00A0;Sayood. <a 
href="http://rahilshaikh.weebly.com/uploads/1/1/6/3/11635894/data_compression.pdf" ><span 
class="ecti-1000">Introduction to data compression</span></a>. Morgan Kaufmann, 2017.
   </p>
   <p class="bibitem" ><span class="biblabel">
 [3]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a 
 id="Xsweldens1997building"></a>W.&#x00A0;Sweldens and P.&#x00A0;Schröder. <a 
href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.5600&rep=rep1&type=pdf" >Building Your Own Wavelets at Home</a>.
   <span 
class="ecti-1000">Wavelets in Computer Graphics</span>, 1997.
                                                                  

                                                                  
   </p>
   <p class="bibitem" ><span class="biblabel">
 [4]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a 
 id="Xvetterli1995wavelets"></a>M.&#x00A0;Vetterli   and   J.&#x00A0;Kovacevic.      <a 
href="http://waveletsandsubbandcoding.org/Repository/VetterliKovacevic95_Manuscript.pdf" ><span 
class="ecti-1000">Wavelets  and  Subband  Coding</span></a>.
   Prentice-hall, 1995.
</p>
   </div>
<a 
 id="Q1-1-15"></a>
    
</body></html> 

                                                                  


