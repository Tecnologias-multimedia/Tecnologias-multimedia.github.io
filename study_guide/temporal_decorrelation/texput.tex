\title{\href{https://www.ual.es/estudios/grados/presentacion/plandeestudios/asignatura/4015/40154321?idioma=zh_CN}{Tecnolog√≠as Multimedia} - Study Guide - Milestone 12: Temporal decorrelation in audio signals}

\maketitle

\section{Description}

% About the redundancy
After removing the spatial (stereo) redundancy in the previous
milestone, the next natural step in its development is the removal of
the temporal redundancy that can be found inside of each
subband\footnote{Notice that, beacuse the MST and the transform used
in this milestone are both lineal, the order in which the transforms
are applied is irrelevant. For this reason, we could also have used
the temporal transform inside of each channel of samples, and then,
remove the spatial redundancy.}. As it can be seen in this
\href{}{notebook}, most audio signals show ``patterns'' of samples
that tends to repeat, especially locally. Another clear source of
temporal redundancy is that the neighbor audio samples usually show
similar amplitude values.

% A decorrelating technique: DPCM
There are several techniques that can be used for removing the
temporal redundancy from a sequence of audio. One of the most
straightforward is
\href{https://en.wikipedia.org/wiki/Differential_pulse-code_modulation}{Differential
  Pulse Code Modulation
  (DPCM)~\cite{sayood2017introduction}}. However, there are more
efficient decorrelation algorithms based on
\href{https://en.wikipedia.org/wiki/Transform_coding}{transform
  coding}, such the used in the previous milestone and in this one.

% Another decorrelating technique: transform coding
Transform coding is based on the idea that we can decompose (we can
generate a decomposition from) the input signal into a set of
subbands, and if the used filters\footnote{In a more pure mathematical
  context, the
  \href{https://en.wikipedia.org/wiki/Digital_filter}{filters} are
  representing the basis vectors of a lineal transform.} are the
adecuate for removing the temporal redundancy, we can achieve a high
transform \href{https://en.wikipedia.org/wiki/Coding_gain}{coding
  gain}, accumulating most of the signal energy (and presumably most
of the information) in a small number of subbands. When this happens,
the quantization of the coefficients of the subbands will remove
basically the least significant information, allowing better
compression ratios than those in which we apply the same quantization
process to the original samples.\footnote{Notice that if we use, for
  example, a dead-zone quantizer and most of the coefficients are
  close to zero, the quantizer will generate a high number of zero
  quantization indexes and therefore, a high number of dequantized
  coefficients will be equal to zero.}

% Relation between transform coding and subband coding
The name that has been given to the previous process is
\href{https://en.wikipedia.org/wiki/Sub-band_coding}{subband
  coding}. In this context, our analysis transform matrix $K$ (see the
previous milestone) represents the coefficients (or
\href{https://en.wikipedia.org/wiki/Finite_impulse_response}{taps}) of
a 2-channels analysis
\href{https://en.wikipedia.org/wiki/Filter_bank}{Filter Bank
  (FB)}~\cite{vetterli1995wavelets}, and the forward transform is in
fact ``descomposing'' $x$ into two subbands $w_0$ and $w_1$ (see the
Figure~\ref{fig:PRFB}, and this \href{}{notebook}). On the other hand,
the synthesis transform matrix $K^{-1}$ denotes the taps of a
synthesis FB.

% An intro to PRFBs
Let's suppose now that the filters (represented by the taps of) $K_0$
and $K_1$ are applied to the input signal $x$.\footnote{Remember,
  however, that in the context of this milestone, $x$ is a sequence of
  MST coefficients that show some degree of temporal correlation, not
  a simple pair of samples (a frame).} Let's also suppose (as happens
in the MST) that $K_0$ is a low-pass filter and $K_1$ is a high-pass
filter, and that the
\href{https://en.wikipedia.org/wiki/Filter_(signal_processing)#The_transfer_function}{transfer
  function}\footnote{The response of the filter to the
  \href{https://en.wikipedia.org/?title=Unit_impulse&redirect=no}{unit
    impulse}.} of both filters
\href{https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks}{are
  the inverse of each other}. Under these assumptions, the complete
(analysis/synthesis) system is called a (2-channels)
\href{https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks}{Perfect
  Reconstruction Filter Bank (PRFB)}, and $x$ can be recoverd from a
subsampled version (in this case
\href{https://en.wikipedia.org/wiki/Downsampling_(signal_processing)}{decimating}
by 2) of $w_0$ and $w_1$ (see the notebook). Notice that this
subsampling is possible because the
\href{https://en.wikipedia.org/wiki/Aliasing}{aliasing} generated in
the low-pass subband is compensated by the aliasing generated in the
high-pass subband.

% M-channels PRFB and the frequency resolution of the HAS
Using the suitable filters, it is possible to build $M$-channels
PRFBs.\footnote{Notice that our matrix $K$ would have $M$ rows in this
  case.} These filters can analyze (and synthesize) the signal $x$,
decomposing it in
(\href{https://en.wikipedia.org/wiki/Low-pass_filter#Ideal_and_real_filters}{almost
  for sure}) overlaping frequency subbands with different
bandwidth. The question here is how many filters should be used and
what bandwidth should they have. At this design point, we must
consider also that the accuracy of the humman perception of the sound
depends on the frequency: (as it can be seen in this notebook) we are
more sensitive to frequency variations when the frequency of the sound
is low. This fact is related with the existence of
\href{https://en.wikipedia.org/wiki/Bark_scale}{the bark scale} and
\href{https://en.wikipedia.org/wiki/Critical_band}{critical bands}.

% The bark scale and the DWT
The bark scale divides the audible spectrum into 24 subband of (a
priori) ``whimsical'' bandwidths. However, it's clear that a
\href{https://en.wikipedia.org/wiki/Octave_band}{dyadic partition of
  the spectrum} fits better than
\href{https://en.wikipedia.org/wiki/Wavelet_transform#Principle}{a
  lineal partition}. Considering this reason, from all the transforms
designed to date, the most suitable one from a strict frequency if the
Discrete Wavelet Transform (DWT).

% Features of the DWT
The DWT has also other interesting features:
\begin{enumerate}
\item It is
  \href{https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Time_complexity}{fast
    ($O(N)$, where $N$ is the number of ``transformed'' elements)}.
\item Can represent efficienty
  \href{https://en.wikipedia.org/wiki/Transient_(oscillation)}{transient}
  signals, which can happen frequencly in audio.
\item Although we are not going to take advantage of the following
  characteristic (for now), one of the most interesting features of
  the DWT is that it can used to find easely a
  \href{https://en.wikipedia.org/wiki/Multiresolution_analysis}{multiresolution
    representation} of the signal.
\end{enumerate}

% Implementation alternatives for the DWT
The DWT can be implemented in different ways:
\begin{enumerate}
\item Defining $K$ and computing vector-matrix multiplications, which
  requires a calculation time proportional to $O(N^2)$. However, the
  main problem of this type of implementation is generated by the
  memory that $K$ can require, that is proportional to $N^2$.
\item
  \href{https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Cascading_and_filter_banks}{Cascading
    PRFBs}. Considering that the convolution is a $O(N\log_2N)$
  operation, and that the number the number of levels in the cascade
  is generally small (5 for example), this implementation is faster
  than the based in vector-matrix arithmetic. And most importantly, we
  don't need to store $K$, but only the taps of the filters.
\item Using
  \href{https://en.wikipedia.org/wiki/Lifting_scheme}{lifting}~\cite{sweldens1997building},
  which provides a speed-up factor of 2 compared to the FB
  implementation. DWTs implemented with lifting do not need to
  downsample and upsample the subbands, an operation that is wasting
  the calculus of half of the coefficients at each level of the
  cascade.
\end{enumerate}

% Using the MST filters for building a DWT
In order to clarify the introduced concepts, let's build a DWT using
the MST filters and lifting.

\begin{enumerate}
\item Lifting is based on the concept of dyadic
  \href{https://en.wikipedia.org/wiki/Multiresolution_analysis}{multiresolution
    analysis} of the signals. Using it, we can rewrite the MST filter
  equations ($K_0$ and $K_1$) as
  \begin{equation}
    \begin{array}{rcl}
      l^1_i & = & x_{2i} + x_{2i+1} \\
      h^1_i & = & x_{2i+1} - x_{2i},
    \end{array}
    \label{eq:1dwt}
  \end{equation}
  where a subband $z^s=\{z_i^s|0\le i\le 2^{n-r}\}$, $2^n=N$ is the
  number of samples in $x$, and by definition, $l^0=x$, the original
  resolution level of the signal. The subbands $l^1$ and $h^1$
  computed by Eq.~\ref{rq:1dwt} are the same than the decimated
  subbands computed by a 1-levels PRFB (based on that filters), and we
  say, therefore, that Eq.~\ref{eq:1dwt} computes the 1-levels DWT.

  We define the 2-levels DWT as
  \begin{equation}
    \begin{array}{rcl}
      l^2_i & = & l^1_{2i} + l^1_{2i+1} \\
      h^2_i & = & l^1_{2i+1} - l^1_{2i},
    \end{array}
    \label{eq:2dwt}
  \end{equation}
  that, as we can see, uses as input the output of Eq.~\ref{eq:1dwt}.

  In general, for a $s$-levels DWT, we get
    \begin{equation}
    \begin{array}{rcl}
      l^s_i & = & l^{s-1}_{2i} + l^{s-1}_{2i+1} \\
      h^s_i & = & l^{s-1}_{2i+1} - l^{s-1}_{2i}.
    \end{array}
    \label{eq:2dwt}
  \end{equation}

  The $s$-levels DWT splits the signal spectrum in $s$ subbands. If
  $s=n$, we have the spectrum partition
  \begin{equation*}
    | l^s_0 | h^s_0 | h^{s-1}_0 h^{s-1}_1 | h^{s-2}_0 h^{s-2}_1 h^{s-2}_2 h^{s-2}_3 | \cdots | h^1_0 h^1_1 \cdots h^1_{2^{n-1}-1} |,
  \end{equation*}
  where\footnote{The coefficient $l^s_0$ is called the DC (Direct
    Current) coefficient, and the rest of $h$ coefficients are called
    AC (Alternating Current) coefficients.} it holds that
  \begin{equation}
    1+\sum_{j=1}^s 2^{j-1}=2^n.
  \end{equation}

\item Perform a number of lifting steps, each one with 2 (sub)steps:
  \begin{enumerate}
  \item Predict step: compute the $h$ subbands as a prediction error,
    that should be minimized, between the even samples (the values to
    predict) and the odd samples (the values used to predict). For the
    MST filters, we have that
    \begin{equation}
      h^s_i = l^{s-1}_{2i+1} - l^{s-1}_{2i}.
    \end{equation}
    
  \item Update step: compute the $l$ subbands considering (only) the even
    samples and the prediction errors. For the MST, we have
    \begin{equation}
      l^s_i = 2l^{s-1}_{2i} + h^s_i.
    \end{equation}
  \end{enumerate}
\end{enumerate}

Notice that these steps are invertible:
\begin{equation}
  \begin{array}{rcl}
    l^{s-1}_{2i} & = & \frac{1}{2}(l^s_i - h^s_i)\\
    l^{s-1}_{2i+1} & = & l^{s-1}_{2i} + h^s_i.
  \end{array}
\end{equation}

In the context of the wavelet theory~\cite{burrus2013wavelets}, the
response of the analysis low-pass filter to the
\href{https://en.wikipedia.org/?title=Unit_impulse&redirect=no}{unit
  impulse}\footnote{The response of a filter to the unit impulse
  characterize the filter because the output of the filter is the set
  of taps of the filter.} is known as the scaling function and is
usually denoted by $\phi$, the response of the analysis high-pass is
known as the wavelet function and it is usually denoted by $\psi$, the
response of the synthesis low-pass filter is denoted by $\tilde\phi$
and the synthesis high-pass filter is represented by $\tilde\psi$.

For the MST it holds that $\phi\bot\psi$, that $\phi=\tilde\psi$ and
that $\psi=\tilde\phi$. This is true for all orthogonal DWTs. Another
important characteristic of orthogonal DWTs is that the filters cannot
be symmetric.

%The dilated and translated versions of the wavelet function are
%orthogonal~\cite{sayood2017introduction}.

The previous MST-based DWT is similar to other transforms such as the
Haar transform, in which we are using a 1-order predictor for removing
the temporal redundancy. Let's extend the lifting idea to a predictor
of order two. For that, we define the predict step as
\begin{equation}
  h^s_i = l^{s-1}_{2i+1} - \frac{1}{2}(l^{s-1}_{2i} + l^{s-1}_{2i+2})
\end{equation}
and the update step as
\begin{equation}
  l^s_i = l^{s-1}_{2i} + \frac{1}{4}(h^s_{i-1} + h^s_i),
\end{equation}
where the factor 1/4 is used to preserve the
energy~\cite{sweldens1997building}. This transform is known as the
\href{https://en.wikipedia.org/wiki/Biorthogonal_wavelet}{biorthogonal}
(2,2) of Cohen-Daubechies-Feauveau, and also as the linear transform.
Biorthogonal filters can be \href{http://wavelets.pybytes.com/}{easely
  recognized} because they are always symmetric and because the
analysis filters are different to the synthesis filters.

Again, the linear transform in invertible by simply reversing the
steps:
\begin{equation}
  \begin{array}{rcl}
    l^{s-1}_{2i} & = & l^s_i - \frac{1}{4}(h^s_{i-1} + h^s_i)\\
    l^{s-1}_{2i+1} & = & h^s_i + \frac{1}{2}(l^{s-1}_{2i} + l^{s-1}_{2i+2}).
  \end{array}
\end{equation}

A final (and important) consideration about transform coding and
quantization. Transform coding implies splitting the signal into
chunks, and compute the transform of each chunk. When the coefficients
are quantized, it is possible that large (and umpleasant) differences
may appear between the border samples of the chunks (see this
notebook). One simple solution is to use the last samples of the
$i-1$-th chunk and the first samples of the $i+1$-chunk for computing
the transform of the $i$-th chunk. The number of overlaped samples
depends on the length of the filters and the number of levels of the
DWT. This last parameter (the number of levels of the DWT) has also a
high impact on the decorrelation process, but take into consideration
that, depending on the signal, usually happens that it is not worth
decomposing the signal into the maximum number subbands because the
increments in the coding gain can be negligible beyond a number of
levels.
  
\section{What you have to do?}

\begin{enumerate}
\item In a module named temporal.py, inherit the class
  Spatial\_decorrelation and create a class named Temporal\_decorrelation.
\item Override the methods pack() and unpack(). In pack() perform a
  DWT decomposition of each channel, and in unpack() perform the
  inverse transform. Use a suitable\footnote{Take into consideration
    the subband gains and the shape of the wavelet functions in your
    wavelet selection.} wavelet from
  \href{https://pywavelets.readthedocs.io/en/latest/}{PyWavelets}. Take
  also into consideration that the signal should be processed using
  overlaped chunks in order to minimize the discontinuities of the
  signal at the chunk boundaries, when the DWT coefficients are
  quantized.
\item Has been the
  \href{https://en.wikipedia.org/wiki/Data_compression_ratio}{compression
    ratio} improved (on
  \href{https://en.wikipedia.org/wiki/Average}{average})? How much?
\end{enumerate}

\section{Timming}

This is the final milestone. Present your results in the exam time.

\section{Deliverables}

The module temporal.py. Store it at the
\href{https://github.com/Tecnologias-multimedia/intercom}{root
  directory} of your InterCom's repo.

\section{Resources}

\bibliography{maths,data-compression,DWT,audio-coding}

\begin{comment}

  The Figure~\ref{fig:transform_coding} shows the stages that are
  tipycally involved in a transform-based signal compression system.

\begin{figure}
  \begin{center}
\begin{verbatim}
   s   +---+   w    +---+   k    +---+    c
 ----->| T |------->| Q |------->| E |-----------+
  (s)  +---+  (s)   +---+  (~s)  +---+   (~s)    |
samples   coefficients   indexes      code-words ~
                                                 :
                                                 ~
   ~s  +---+    w   +---+   k    +---+           |
 <-----| t |<-------| q |<-------| D |<----------+
  (~s) +---+  (~s)  +---+  (~s)  +---+
approx.    quantized     indexes
samples   coefficients
\end{verbatim}                
  \end{center}
  \caption{Common data-flow used un Transform Coding. $s$ represents
    the signal to compress, $\tilde{s}$ the lossy version of the
    reconstructed signal, $T$ the (forward) transform (which takes blocks of
    samples) producing blocks of coefficients $w$, $Q$ the scalar
    quantization stage (which takes single coefficients) producing
    quantization indexes $k$, $E$ the entropy encoder (which in our
    case (DEFLATE) works with blocks of coefficients) producing
    code-words $c$, $D$ the entropy decoder, $q$ the decuantization
    stage, and $t$ the inverse (or backward) transform. PCM stands for Puse Code
    Modulation and DEFLATE is the technique used to find a compact
    representation of the quantized coefficients.}
  \label{fig:transform_coding}
\end{figure}
\end{comment}

