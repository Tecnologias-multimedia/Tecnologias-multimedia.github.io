\title{\href{https://www.ual.es/estudios/grados/presentacion/plandeestudios/asignatura/4015/40154321?idioma=zh_CN}{Tecnolog√≠as Multimedia} - Study Guide - Milestone 6: Buffering chunks}

\maketitle

\section{Description}
-------------------

After analyzing these steps, we can see that only $\mathtt{pack(chunk)}$ and $\mathtt{unpack(packet)}$ deserve to be parallelized.

Now is a good moment to think about the computing resources that can
be available: in general, more than one PU (Processing Unit) or core is available.

Using non-blocking I/O 
  
Notice that the execution of these steps, in this order, in two
different InterCom instances has at least two problems:
\begin{enumerate}
\item If a packet is lost, a deadlock is generated, because the
  $\mathtt{receive()}$ never returns.
\item If the time required by $\mathtt{pack(chunk)}$ and
  $\mathtt{unpack(packet)}$ is largest than the chunk-time, a glich
  will be generated.
\end{enumerate}

The Sequential Model is straightforward. However, we cannot control
the chunk size without generating a blocking in the record and play
steps. This can produce
\href{https://en.wikipedia.org/wiki/Glitch_(music)}{gliches}.

\subsection{Concurrent model}

The \href{https://en.wikipedia.org/wiki/Parallel_computing}{parallel}
model supposes that there is at least two Processing Units (or PUs,
typically
\href{https://en.wikipedia.org/wiki/Multi-core_processor}{cores}),
that are able to work in parallel. Thus, the sequential model is
divided into two
\href{https://en.wikipedia.org/wiki/Concurrency_(computer_science)}{concurrent}
tasks that should run in parallel.

\begin{pseudocode}{Concurrent\_InterCom}{~}
  \PROCEDURE{Record\_Pack\_and\_Send}{~}
  \BEGIN
    \mathtt{chunk} \GETS \mathtt{record()}\\
    \mathtt{packet} \GETS \mathtt{pack(chunk)}\\
    \mathtt{send(packet)}
  \END
  \ENDPROCEDURE
  \PROCEDURE{Receive\_Unpack\_and\_Play}{~}
  \BEGIN
    \mathtt{packet} \GETS \mathtt{receive()}\\
    \mathtt{chunk} \GETS \mathtt{unpack(packet)}\\
    \mathtt{play(chunk)}
  \END
  \ENDPROCEDURE
\end{pseudocode}

In this case, the loss of a chunk does not generates a deadlock
between the concurrent tasks, because even if the
$\mathrm{Receive\_Unpack\_Play}$ is blocked waiting for a block in the
$\mathtt{receive()}$, the $\mathtt{Record\_Pack\_and\_Send}$ task will
continue sendind chunks.

Unfortunatelly, gliches can still happen in this model if the packets
are lost or delayed, or if $\mathtt{pack(chunk)}$ or if
$\mathtt{unpack(packet)}$ needs more than a chunk-time to be
completed.

Most of the socket APIs offeer a version of 


\section{What you have to do?}

\begin{enumerate}

\item Implement a timer-based InterCom. Use as reference \href{https://github.com/Tecnologias-multimedia/intercom/blob/master/test/sounddevice/wire.py}{wire.py}.
  
\end{enumerate}

\section{Timming}

You should reach this milestone at most in one week.

\section{Deliverables}

\section{Resources}

\bibliography{python}
