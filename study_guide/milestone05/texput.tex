\title{\href{https://www.ual.es/estudios/grados/presentacion/plandeestudios/asignatura/4015/40154321?idioma=zh_CN}{TecnologÃ­as Multimedia} - Study Guide - Milestone 5: Minimal InterCom}

\maketitle

\section{Description}

\subsection{Sequential model}

InterCom can be divided roughtky in 6 steps:

\begin{pseudocode}{Sequential\_InterCom}{~}
  \BEGIN
    \mathtt{recorded\_chunk} \GETS \mathtt{record()}\\
    \mathtt{outgoing\_packet} \GETS \mathtt{pack(recorded\_chunk)}\\
    \mathtt{send(outgoing\_packet)}\\
    \mathtt{incoming\_packet} \GETS \mathtt{receive()}\\
    \mathtt{chunk\_to\_play} \GETS \mathtt{unpack(incoming\_packet)}\\
    \mathtt{play(chunk\_to\_play)}
  \END
\end{pseudocode}

Where:

\begin{enumerate}
\item $\mathtt{record()}$ captures a chunk of frames. In general, this
  is a \href{https://en.wikipedia.org/wiki/I/O_bound}{I/O-bound}
  \href{https://python-sounddevice.readthedocs.io/en/0.4.0/api/streams.html#sounddevice.Stream.read}{blocking
    operation}, depending on the availability of frames in the ADC's
  buffer. This can be checked in
  \href{https://raw.githubusercontent.com/Tecnologias-multimedia/intercom/master/test/sounddevice/wire4.py}{wire4.py},
  \begin{lstlisting}[language=Bash]
    curl https://raw.githubusercontent.com/Tecnologias-multimedia/intercom/master/test/sounddevice/wire4.py > wire4.py
  \end{lstlisting}  
  where the $\mathtt{read()}$ method always returns inmediately
  because only the available frames are returned in each call (the
  chunk-size depends on the instant of time in which this method is
  called).
\item $\mathtt{pack(chunk)}$ process the chunk to create a
  \href{https://en.wikipedia.org/wiki/Network_packet}{packet} (or a
  sequence of packets), a structure that can be transmitted through
  the Internet using the
  \href{https://en.wikipedia.org/wiki/Datagram}{Datagram} Model. In
  general, this is a
  (\href{https://en.wikipedia.org/wiki/CPU-bound}{CPU-bounded}
  (CPU-intensive) operation, and therefore, reduces the number of
  cycles/second that the main thread can reach.
\item $\mathtt{send(packet)}$, sends the packet to the interlocutor's
  InterCom. When datagrams are used, this step is non-blocking neither
  CPU-bounding (the CPU usage is very low), if the number of
  packets/second is small and the size of the payloads is also small,
  as it is expected in the InterCom.
\item $\mathtt{receive()}$, waits (blocking) for a incoming packet,
  and therefore, this operation is IO-bound. However, most socket APIs
  offeer a
  \href{https://docs.python.org/3.8/library/socket.html#socket.socket.setblocking}{non-blocking
    option} where when a packet is not available in the kernel's
  buffer associanted to the corresponding socket, some kind of
  exception is generated and, in this case, it is resposabability of
  the programmer to generate a ``alternative'' chunk (in our case, for
  example, a chunk filled with zeros will not produce any sound).
\item $\mathtt{unpack(packet)}$ is (as $\mathtt{pack(chunk)}$) a
  CPU-intensive step that transforms a packet (or several packets)
  into a chunk of audio.
\item $\mathtt{play(chunk)}$ renders the chunk. In general, this is an
  I/O-bound
  \href{https://python-sounddevice.readthedocs.io/en/0.4.0/api/streams.html#sounddevice.Stream.write}{blocking}
  action. However, if $\mathtt{play()}$ is called at the same pace
  than $\mathtt{record()}$ and the record and play parameters are
  exactely the same (as happens in our model), the playing of the
  chunk will return inmediately because the time that the
  $\mathtt{play()}$ method needs to complete would exactly match the
  time that the $\mathtt{record()}$ method requires.
\end{enumerate}

This model works fine if the chunk size is controlled by PortAudio and
also, the run-time required by $\mathtt{pack(chunk)}$ and
$\mathtt{unpack(packet)}$ operations is smaller than the
chunk-time. The first issue is complicates slightly the implementation
because we need to work with chunks of constantly changing lenghts
(that as you can see, most of the time are 0). This also complicates
the control of the latency (the chunk size is variable). However, the
real problem appears when our computer is not able to satisfy the
second requirement. This only can be addressed through optimizing and
parallelizing the code.

\subsection{Timer-based model}

In this model, the task dedicated to record and play the chunks of
audio is called periodically (probably, using some timer provided by
the sound hardware). This procedure guarantees a gliches-free audio-IO
when constant chunk sizes are used because the timer interruption
coincides exactly with the instant of time in which the
$\mathtt{record()}$ and the $\mathtt{play()}$ methods need to be run
to guarantee that we are going to handle a chunk of audio of a known
size without blocking.

\begin{pseudocode}{Timer-based\_InterCom}{~}
  \PROCEDURE{Record\_IO\_and\_Play}{\mathtt{chunk\_size}}
  \BEGIN
    \mathtt{recorded\_chunk} \GETS \mathtt{record(chunk\_size)}\\
    \mathtt{send(outgoing\_packet)} \GETS \mathtt{pack(recorded\_chunk)}\\
    \mathtt{send(outgoing\_packet)}\\
    \mathtt{incoming\_packet} \GETS \mathtt{receive()}\\
    \mathtt{chunk\_to\_play} \GETS \mathtt{unpack(incoming\_packet)}\\
    \mathtt{play(chunk\_to\_play)}
  \END
  \ENDPROCEDURE
\end{pseudocode}

where:
\begin{enumerate}
\item $\mathtt{indata}$ points to the last chunk of audio recorded.
\item $\mathtt{outdata}$ points to the chunk of audio that is going to be played.
\item $\mathtt{chunk\_size}$ is the number of frames processed in each iteration of the callback.
\end{enumerate}

The advantage of this alternative compared to the Concurrent Model is
that we can control the size of the buffers, which in the end controls the latency.


-------------------

After analyzing these steps, we can see that only $\mathtt{pack(chunk)}$ and $\mathtt{unpack(packet)}$ deserve to be parallelized.

Now is a good moment to think about the computing resources that can
be available: in general, more than one PU (Processing Unit) or core is available.

Using non-blocking I/O 
  
Notice that the execution of these steps, in this order, in two
different InterCom instances has at least two problems:
\begin{enumerate}
\item If a packet is lost, a deadlock is generated, because the
  $\mathtt{receive()}$ never returns.
\item If the time required by $\mathtt{pack(chunk)}$ and
  $\mathtt{unpack(packet)}$ is largest than the chunk-time, a glich
  will be generated.
\end{enumerate}

The Sequential Model is straightforward. However, we cannot control
the chunk size without generating a blocking in the record and play
steps. This can produce
\href{https://en.wikipedia.org/wiki/Glitch_(music)}{gliches}.

\subsection{Concurrent model}

The \href{https://en.wikipedia.org/wiki/Parallel_computing}{parallel}
model supposes that there is at least two Processing Units (or PUs,
typically
\href{https://en.wikipedia.org/wiki/Multi-core_processor}{cores}),
that are able to work in parallel. Thus, the sequential model is
divided into two
\href{https://en.wikipedia.org/wiki/Concurrency_(computer_science)}{concurrent}
tasks that should run in parallel.

\begin{pseudocode}{Concurrent\_InterCom}{~}
  \PROCEDURE{Record\_Pack\_and\_Send}{~}
  \BEGIN
    \mathtt{chunk} \GETS \mathtt{record()}\\
    \mathtt{packet} \GETS \mathtt{pack(chunk)}\\
    \mathtt{send(packet)}
  \END
  \ENDPROCEDURE
  \PROCEDURE{Receive\_Unpack\_and\_Play}{~}
  \BEGIN
    \mathtt{packet} \GETS \mathtt{receive()}\\
    \mathtt{chunk} \GETS \mathtt{unpack(packet)}\\
    \mathtt{play(chunk)}
  \END
  \ENDPROCEDURE
\end{pseudocode}

In this case, the loss of a chunk does not generates a deadlock
between the concurrent tasks, because even if the
$\mathrm{Receive\_Unpack\_Play}$ is blocked waiting for a block in the
$\mathtt{receive()}$, the $\mathtt{Record\_Pack\_and\_Send}$ task will
continue sendind chunks.

Unfortunatelly, gliches can still happen in this model if the packets
are lost or delayed, or if $\mathtt{pack(chunk)}$ or if
$\mathtt{unpack(packet)}$ needs more than a chunk-time to be
completed.

Most of the socket APIs offeer a version of 


\section{What you have to do?}

\begin{enumerate}

\item Implement a timer-based InterCom. Use as reference \href{https://github.com/Tecnologias-multimedia/intercom/blob/master/test/sounddevice/wire.py}{wire.py}.
  
\end{enumerate}

\section{Timming}

You should reach this milestone at most in one week.

\section{Deliverables}

\section{Resources}

\bibliography{python}
