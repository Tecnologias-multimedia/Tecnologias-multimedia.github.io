\title{\TM - Study Guide - Milestone 5: Impact of the Communication Latency}

\maketitle

\section{Description}

\href{https://en.wikipedia.org/wiki/Latency_(engineering)#Communication_latency}{Communication
  latency} (also called
\href{https://en.wikipedia.org/wiki/Network_delay}{network delay} and
\href{https://en.wikipedia.org/wiki/End-to-end_delay}{end-to-end
  delay}) is the time that a piece of data (a
\href{https://en.wikipedia.org/wiki/Network_packet}{packed} in the
case of the Internet) takes to travel from one point of the network to
another. This time is relevant for an intercom because the total latency $t_u$ that an user is going to experiment is
\begin{equation}
  t_u = t_l + t_i,
  \label{eq:user_latency}
\end{equation}
where $t_l$ is the (tele-communication)
\href{https://en.wikipedia.org/wiki/Telecommunications_link}{link}
latency and $t_i$ is the latency generated by the intercom.

Due to the current design of the Internet (where the available
\href{https://en.wikipedia.org/wiki/Bandwidth_(computing)}{bandwidth}
is shared on demand by the users of the network) $t_l$ is
time-variying, and cannot be controlled without using
\href{https://en.wikipedia.org/wiki/Quality_of_service}{Quality of
  Service (QoS)}, something that is not accesible to normal network
users. On the contrary, $t_i$ is constant for a given intercom's
configuration/implementation.

In this milestone we are going to measure the
\href{https://en.wikipedia.org/wiki/Quality_of_experience}{Quality of
  Experience (QoE)} provided by our minimal intercom when the network
latency varies \href{https://en.wikipedia.org/wiki/Randomness}{at
  random}. At this point, we have basically two alternatives:
\begin{enumerate}
\item Run two instances of InterCom in two different hosts separated
  by a shared link.
\item Run one instance of Intercom and simulate the network latency.
\end{enumerate}
Each option has pros and cons, from which we can highlight that:
\begin{enumerate}
\item (Pro) The use of real latency is going to show the definitive
  behaviour of InterCom between the used hosts, which is quite
  impredictable (depend basically of the
  \href{https://en.wikipedia.org/wiki/Network_congestion}{network
    congestion}). (Con) To run InterCom in two different hosts we will
  need to establish a direct communication between them and it is very
  likely that we will have to redirect ports in the corresponding
  \href{https://en.wikipedia.org/wiki/Network_address_translation}{NAT}
  devices~\cite{}.
\item (Pro) The simulation of the link latency is much more
  straightforward than the opening ports in our routers and (pro) will
  allow us to run InterCom in situations that are difficult to achieve
  in a real network. (Con) The running environment must provide a way
  of controlling the latency between
  \href{https://en.wikipedia.org/wiki/Process_(computing)}{processes}. Fortunately,
  in Linux we can control the latency (and the
  \href{https://en.wikipedia.org/wiki/Bit_rate}{bit-rate}) of the
  outgoing (packets) traffic using the command
  \href{https://man7.org/linux/man-pages/man8/tc.8.html}{$\mathtt{tc}$}.
\end{enumerate}

\section{What you have to do?}

\subsection{Characterize the latency in different scenarios}

\subsubsection{In your host}

In most cases we will test InterCom in your host. Therefore, it can be
useful to have an idea of how the latencies are distributed, at least
from a statistical point of view.

\begin{enumerate}
\item Ping \texttt{localhost}:
   \begin{lstlisting}{language=bash}
    ping localhost -c 100 > /tmp/ping.dat
  \end{lstlisting}
Compute the expected (considering that the
  \href{https://en.wikipedia.org/wiki/Round-trip_delay}{RTT} should
  double the) latency to the host of your interlocutor:
  \begin{lstlisting}{language=bash}
    grep from < /tmp/ping.dat | cut -f 4 -d "=" | cut -f 1 -d " " | awk '{print $1/2}' > /tmp/localhost_latencies.dat
  \end{lstlisting}

\item Find the histogram of the expected latencies:
  \begin{lstlisting}{language=python}
    cat << EOF | python -
    import numpy as np
    latencies = np.loadtxt("/tmp/localhost_latencies.dat")
    histogram = np.histogram(latencies)
    np.savetxt("/tmp/localhost_histogram.dat", histogram[0])
    EOF
  \end{lstlisting}

\item Plot the histogram:
  \begin{lstlisting}{language=bash}
    gnuplot plot "/tmp/localhost_histogram.dat" with histogram
  \end{lstlisting}
  
\item Characterize statistically the latency:
\end{enumerate}

\subsubsection{In the Internet}

This scenario can be useful to test InterCom in your host but
simulating a real connection between hosts in different home
networks. For doing that:

\begin{enumerate}
\item Repeat the previous experiment (the characterization of the
  latencies returned by the \texttt{ping} tool) but using your
  interlocutor's \texttt{<router\_public\_IP\_address>} instead of
  \texttt{localhost}. Call the generated file
  \texttt{/tmp/<router\_public\_IP\_address>}.
\item Request to your interlocutor to ping its router from the private
  network and send this data to you. Save this info in
  \texttt{/tmp/<router\_private\_IP\_address>}.

\end{enumerate}

\subsection{Quantification of the QoE}

Let's measure the QoE using the following classification:
\begin{itemize}
\item [Perfect]: no loss or delay can be distinguish.
\item [Good]: if you detect some minimal distortion in the rendering
  of the sound.
\item [Acceptable]: when the effects of the latency are apreciable, but
  you can communicate with your interlocutor.
\item [Bad]: you are able to recognize only small parts of the
  received audio.
\item [No way]: when most of the time only silence is heard.
\end{itemize}

\subsubsection{In your host}

You don't need to control the network traffic in your host because it
is already shapped when InterCom uses the loopback network
device. Therefore, simply quantify your QoE in this scenario that
should be always Perfect.

\subsubsection{In the Internet}

\begin{enumerate}
  
\item 

\end{enumerate}

\subsubsection{In your home network}

\section{Timming}

There is not time limit for finishing this milestone. Develop it at
your own pace.

\section{Deliverables}

None.

\section{Resources}

\bibliography{python,intercom}
