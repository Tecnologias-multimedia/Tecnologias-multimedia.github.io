% Emacs, this is -*-latex-*-

\title{Hidding the network jitter}

\maketitle

\section{Description}

\subsection{Latencies}
\href{https://en.wikipedia.org/wiki/Latency_(engineering)#Communication_latency}{Communication
  latency} (also called
\href{https://en.wikipedia.org/wiki/Network_delay}{network delay} and
\href{https://en.wikipedia.org/wiki/End-to-end_delay}{end-to-end
  delay}) is the time that a chunk of data (encapsulated
in a \href{https://en.wikipedia.org/wiki/Internet_Protocol}{IP}
\href{https://en.wikipedia.org/wiki/Network_packet}{packet} in the
case of the Internet) takes to travel from one point of the network to
another. This time is relevant for an intercom because the total
latency $t_u$ that an user experiments can be approximated by
\begin{equation}
  t_u = t_p + t_i,
  \label{eq:user_latency}
\end{equation}
where $t_p$ is the \emph{propagation time} (or propagation latency) of
the \href{https://en.wikipedia.org/wiki/Telecommunications_link}{link}
and $t_i$ is the \emph{latency} generated by the intercom.

Due to the current design of the Internet~\cite{Tanenbaum,Stallings}
(where the available
\href{https://en.wikipedia.org/wiki/Bandwidth_(computing)}{bandwidth}
is shared on demand by the users of the network) $t_p$ is
time-variying, and cannot be controlled without using
\href{https://en.wikipedia.org/wiki/Quality_of_service}{Quality of
  Service (QoS)}\footnote{Something that is not available to normal
  network users.}~\cite{dordal2020intro}. On the contrary, $t_i$ is
constant for a given intercom's configuration/implementation.

In this milestone we are going to measure the
\href{https://en.wikipedia.org/wiki/Quality_of_experience}{Quality of
  Experience (QoE)} provided by our minimal intercom when the network
latency varies \href{https://en.wikipedia.org/wiki/Randomness}{at
  random}. In this point, we have basically two alternatives:
\begin{enumerate}
\item Run two instances of InterCom in two different
  \href{https://en.wikipedia.org/wiki/Host_(network)}{host}s separated
  by a shared link.
\item Run one instance of InterCom and simulate the network latency.
\end{enumerate}
Each option has pros and cons, from which we can highlight that:
\begin{enumerate}
\item \textbf{Using a real link:} (Pro) The use of real latency is
  going to show the true behaviour of InterCom between the used hosts,
  which is quite impredictable (depend basically on the
  \href{https://en.wikipedia.org/wiki/Network_congestion}{network
    congestion}). (Con) To run InterCom in two different hosts we will
  need to establish a direct communication between them and it is very
  likely that we will have to redirect ports in the corresponding
  \href{https://en.wikipedia.org/wiki/Network_address_translation}{NAT}
  devices~\cite{srisuresh1999nat}.
\item \textbf{Using a simulated link:} (Pro) The simulation of the
  link latency is much more straightforward than opening ports in our
  NATs and (pro) will allow us to run InterCom in situations that
  are difficult to achieve in a real network. (Con) The running
  environment must provide a way of controlling the latency between
  \href{https://en.wikipedia.org/wiki/Process_(computing)}{processes}. Fortunately,
  in Linux we can control the latency (and the
  \href{https://en.wikipedia.org/wiki/Bit_rate}{bit-rate}) of the
  outgoing (packets) traffic using the command
  \href{https://man7.org/linux/man-pages/man8/tc.8.html}{\texttt{tc}}
  \cite{bert2012lartc}.
\end{enumerate}

\subsection{Measurement}
In most cases we will test InterCom only in our host. Therefore, it
can be useful to have an idea of how the latencies are distributed, at
least, from a statistical point of view.

To mesasure latencies, we will use
\href{https://github.com/torvalds/linux/blob/master/net/ipv4/ping.c}{\texttt{ping}}~\cite{Kurose-Ross,Forouzan},
a tool that
\href{https://en.wikipedia.org/wiki/Ping_(networking_utility)}{sends}
(one or more)
\href{https://en.wikipedia.org/wiki/Internet_Control_Message_Protocol}{ICMP}
Echo Request messages to an IP address and waits for receiving (one or
more) ICMP Echo Reply messages generated by the
(\href{https://en.wikipedia.org/wiki/Operating_system}{OS} of that)
host, measuring the so called
\href{https://en.wikipedia.org/wiki/Round-trip_delay}{RTT} (Round-Trip
Time). For example, in the Figure~\ref{fig:ping_timeline} are
described the different time components in which a RTT can be
decomposed. In this figure, $t_t$ stands for \emph{transmission time},
and $t_p$ (again) for \emph{propagation time}. A simple link (a cable,
for example) using
\href{https://en.wikipedia.org/wiki/Time-division_multiple_access}{TDM}
(Time-Domain Multiplexing) has been supposed. For this reason, the
propagation and transmission times are identical in both
directions. Notice that if the payload of the \verb|ping| message has
only 64 bytes (the default value in most \verb|ping| implementations)
and the bit-rate of the link is high, then $t_p\gg t_t.$ For this type
of link (a simple wire), it also holds that
\begin{equation}
  \text{RTT} = 2t_p + 2t_t.
  \label{eq:RTT}
\end{equation}
  
\begin{figure}
  \begin{center}
    \myfig{graphics/ping_timeline}{8cm}{500}
    % \svgfig{graphics/ping_timeline}{8cm}{1800}
  \end{center}
  \caption{Timeline of a ping interaction between two hosts A and B,
    interconnected by simple communication link.}
  \label{fig:ping_timeline}
\end{figure}

\section{What you have to do?}
\label{sec:homework}

\subsection{Characterize the latency in different scenarios}

\subsubsection{In your host}

Please, do the following steps:

\begin{enumerate}
\item Ping \verb|localhost|:
   \begin{lstlisting}{language=bash}
ping localhost -c 100 -s <payload_length_in_bytes> > /tmp/ping.txt
  \end{lstlisting}
  Use a payload size similar to the chunk size that you expect to use
  in your InterCom experiments.
\item Compute the expected (considering that the RTT should
  double the) latency to the host of your interlocutor:\\\\
  \verb|export LC\_NUMERIC=en\_US.UTF-8 # Use "." instead of "," for the decimal separator|\\
\texttt{grep from < /tmp/ping.txt | cut -f 4 -d "=" | cut -f 1 -d " " | awk
  \textquotesingle\{print \$1/2\}\textquotesingle~> /tmp/localhost\_latencies.txt}\\\\

\item Find the histogram of the expected latencies:
  
  \begin{lstlisting}{language=bash}
cat << EOF | python -
import numpy as np
from scipy import stats
latencies = np.loadtxt("/tmp/localhost_latencies.txt")
average_latency = np.average(latencies)
print("\naverage latency =", average_latency)
max_latency = np.max(latencies)
min_latency = np.min(latencies)
maximum_absolute_deviation = max(max_latency - average_latency, average_latency - min_latency)
print("maximum absolute deviation (jitter) =", maximum_absolute_deviation)
correlation_coefficient = stats.pearsonr(latencies, np.roll(latencies, 1))[0]
print("Pearson correlation coefficient =", correlation_coefficient)
if correlation_coefficient < 0:
  print("Correlation coefficient < 0: use 0 (no correlation between RTT samples) in your experiments")
histogram = np.histogram(latencies)
np.savetxt("/tmp/localhost_histogram.txt", histogram[0])
EOF
  \end{lstlisting}

\item Plot the histogram:
  \begin{lstlisting}{language=bash}
gnuplot
plot "/tmp/localhost_histogram.txt" with histogram
  \end{lstlisting}
  
\item Characterize statistically the latency: which statistical
  distribution is more close to your experimental results?
\end{enumerate}

\subsubsection{In the Internet}

This scenario can be useful to test InterCom in your host but
simulating a real connection between hosts in different local
networks\footnote{If you are unable to use two different local
  networks, try to run InterCom in two hosts connected to the same
  router.}. For doing that:

\begin{enumerate}
  
\item Repeat\footnote{Remember that the data files must be processed
    to extract the latencies.} the previous experiment (the
  characterization of the latencies returned by the \verb|ping| tool)
  but using your interlocutor's \verb|<router_public_IP_address>|
  instead of \verb|localhost|. Call the generated file as
  \verb|/tmp/<router_public_IP_address>_latencies.txt|. The IPv4
  address of your router can be determined with:
  
  \begin{lstlisting}{language=bash}
curl ipecho.net/plain
  \end{lstlisting}  
  
\item Request to your interlocutor to ping its router from his/her
  private network, for example, using\footnote{Notice that the private
    IP addres of your router could be different.}:
  
  \begin{lstlisting}{language=bash}
ping -s <chunk_length_in_bytes> 192.168.1.1
  \end{lstlisting}
  
  and to send this data to you. Save this info in
  \verb|/tmp/<router_private_IP_address>_latencies.txt|.

\item Supposing that the latencies are symmetric (the direction of the
  packes does not affect to the latency) and that the overall network
  latency of the link between you a your interlocutor is the sum of
  the latency from your host to the router of your interlocutor added
  to the latency from your interlocutor's host to that router
  (remember to edit the next line to use the right namefiles!):\\\\

\texttt{paste /tmp/<router\_public\_IP\_address>\_latencies.txt /tmp/<router\_private\_IP\_address>\_latencies.txt | awk
  \textquotesingle\{print \$1+\$2\}\textquotesingle~> /tmp/add.txt}\\

%\begin{lstlisting}{language=bash}
% | awk '{print \$1+\$2}' > /tmp/add.txt
%  \end{lstlisting}

  and as in the previous experiment, find a
  characterization for the full link from the data in \verb|/tmp/add.txt|:
  \href{https://en.wikipedia.org/wiki/Average}{average} (arithmetic
  mean) latency, \href{https://en.wikipedia.org/wiki/Jitter}{jitter},
  \href{https://en.wikipedia.org/wiki/Pearson_correlation_coefficient}{Pearson
    correlation coefficient}, and
  \href{https://en.wikipedia.org/wiki/List_of_probability_distributions}{probability
    distribution}.

\end{enumerate}

\subsection{Quantification of the QoE}

Let's measure the QoE using the following classification:
\begin{itemize}
\item \textbf{Perfect}: no loss or delay can be perceived.
\item \textbf{Good}: if you detect some minimal distortion in the
  rendering of the sound.
\item \textbf{Acceptable}: when the effects of the latency are
  noticeable, but you can communicate with your interlocutor.
\item \textbf{Bad}: you are able to recognize only small parts of the
  received audio.
\item \textbf{No way}: when most of the time only silence is heard.
\end{itemize}

\subsubsection{In your host}

Simply quantify your QoE when you run InterCom in your host without
any traffic control.

\subsubsection{In the Internet}

Quantify your QoE when you run InterCom in two different hosts that
are connected to different\footnote{If you are unable to use two
  different local networks, try to run InterCom in two hosts connected
  to the same router.} local networks, without any traffic control.

\subsubsection{In your host, but simulating the Internet}

\begin{enumerate}

\item Check the current configuration:
  
  \begin{lstlisting}{language=bash}
tc qdisc show dev lo
  \end{lstlisting}
  
  The output should be something like:
  
  \begin{lstlisting}{language=bash}
qdisc noqueue 0: root refcnt 2
  \end{lstlisting}
  
\item Using the characterization of the Internet link previously
  obtained, use the command
  \href{https://man7.org/linux/man-pages/man8/tc.8.html}{\texttt{tc}}
  to simulate this link locally using
  \href{https://man7.org/linux/man-pages/man8/tc-netem.8.html}{netem}:

  \begin{lstlisting}{language=bash}
sudo tc qdisc add dev lo root netem delay <average_delay_in_miliseconds>ms <maximum_average_deviation_in_miliseconds>ms <Pearson_correlation_coefficient_expressed_as_a_percentage>% distribution <uniform|normal|pareto|paretonormal>
  \end{lstlisting}
  where:
  \begin{description}
  \item [\texttt{qdisc}:] Use the default
    \href{https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)}{FIFO}
    \href{https://wiki.debian.org/TrafficControl}{Queueing DISCipline}
    for the outgoing traffic.
  \item [\texttt{add}:] Add a new traffic control rule.
  \item [\texttt{dev lo}:] The device affected by the
    rule. \verb|lo| means \verb|loopback|.
  \item [\texttt{root}:] The rule will be applied to all the outbound
    traffic (it's the root rule of the possible tree of rules).
  \item [\texttt{netem}:] Use the
    \href{https://wiki.linuxfoundation.org/networking/netem}{network
      emulator} to emulate a
    \href{https://en.wikipedia.org/wiki/Wide_area_network}{WAN}.
  \end{description}

  Example:

  \begin{enumerate}
  \item Add the rule:
    
    \begin{lstlisting}{language=bash}
sudo tc qdisc add dev lo root netem delay 100ms 10ms 25% distribution normal
    \end{lstlisting}
    
  \item Check that the rule has been installed with the command:
    
    \begin{lstlisting}{language=bash}
tc qdisc show dev lo
    \end{lstlisting}
    
    that should output (or something very similar):
    
    \begin{lstlisting}{language=bash}
qdisc netem 8009: root refcnt 2 limit 1000 delay 100ms  10ms 25%
    \end{lstlisting}
  \end{enumerate}

\item Measure the QoE.

\item Delete the \verb|tc| rule with:
  
  \begin{lstlisting}{language=bash}
sudo tc qdisc delete dev lo root netem delay <average_dalay_in_miliseconds>ms <maximum_average_deviation_in_miliseconds>ms <Pearson_correlation_coefficient_expressed_as_a_percentage>% distribution <uniform|normal|pareto|paretonormal>
  \end{lstlisting}

\item (Optional) It's possible to change a working rule with:

  \begin{lstlisting}{language=bash}
sudo tc qdisc change dev lo root netem delay <average_dalay_in_miliseconds>ms <maximum_average_deviation_in_miliseconds>ms <Pearson_correlation_coefficient_expressed_as_a_percentage>% distribution <uniform|normal|pareto|paretonormal>
  \end{lstlisting}
  
\end{enumerate}

\subsection{(Optional) QoE considering the packet loss}

For our application, InterCom, a chunk is lost when it arrives too
late or it never arrives. Therefore, the results of a packet loss or a
packet delay are almost indistinguishable\footnote{Except by the
  average latency experimented by the user (the higher the network
  latency, the higher the perceived latency).}. For example, a packet
loss ratio of $10\%$ can be configured with \verb|tc| by running:

  \begin{lstlisting}{language=bash}
sudo tc qdisc add dev lo root netem loss 10%
  \end{lstlisting}

\section{Using a buffer to hidden the jitter}

As explained before, we can consider that the QoE provided by InterCom
is inversely proportional to the network jitter (see
Fig.~\ref{fig:timelines}-a). One solution (see
Fig.~\ref{fig:timelines}-b) is the use of a
\href{https://en.wikipedia.org/wiki/Random_access}{random access}
\href{https://en.wikipedia.org/wiki/Data_buffer}{buffer} at the
receiver side, where the chunks are stored for a time large enough to
hidde the jitter to the user~\cite{Kurose-Ross}.

\begin{figure}
  \begin{center}
    \myfig{graphics/timelines}{10cm}{1000}
  \end{center}
  \caption{Timelines of two InterCom interactions. On the left, the
    playback is defective because some chunks are lost. On the right,
    the audio rendering is correct because the playback has been
    delayed 2 chunk times (enough for this example).}
  \label{fig:timelines}
\end{figure}

\href{https://en.wikipedia.org/wiki/Jitter#Jitter_buffers}{\emph{Dejitterizing}
  buffers}\footnote{Usually implemented with random access buffers.}
are typically implemented like a circular buffer structure (see
Fig.~\ref{fig:circular_buffer}). In an ideal situation (as the
depicted in the figure), the number of pending-to-be-played chunks
available in the buffer is half of the number of slots in the buffer,
and the chunks have arrived on time. In this example, the receiver
(where the chunks are buffered) waits for 3 chunks before to start
playing the chunk number 0.\footnote{Implementation tip: in a system
where for each recorded chunk a chunk must be also played, a delay in
the playback can be generated by sending zero-chunks to the DAC and
then, after the delay, start sending the received chunk of audio, in
the right order.} Notice that the number of slots in the buffer $2N$
must double the number of the chunks buffered during the buffering
time proportional to $N$, in order to hide a $N$ chunk-times
jitter. Notice also that this technique introduces also a $N$
chunk-times delay in the playback.

\begin{figure}
  \begin{tabular}{ccc}
    \vbox{\myfig{graphics/circular_buffer1}{2cm}{200}} & \vbox{\myfig{graphics/circular_buffer2}{2cm}{200}} & \vbox{\myfig{graphics/circular_buffer3}{2cm}{200}} \\
    (a) & (b) & (c)
  \end{tabular}
  \caption{A circular buffer with 6 slots (space for 6 chunks). Up to
    the half of the buffer is occupied (slots in gray) because the
    buffering time is 3 chunk times and 3 chunks (with chunk number 0,
    1 and 2 in the beginning, subfigure (a)) have been received. The
    first chunk to be played is chunk 0 (subfigure (b)). Then, a new
    chunk (chunk number 3) is received and buffered (subfigure (c)).}
  \label{fig:circular_buffer}
\end{figure}

For this new improved InterCom, a new parameter called \emph{buffering
  time} must be provided by the users. This value (typically expressed
in miliseconds) should be large enough to hide the network jitter, but
small enough to keep limited the end-to-end (user) latency.

The following guidelines have been used to implement the
\emph{buffered} version of InterCom:

\begin{enumerate}
\item The class Minimal has been
  \href{https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)}{inherited}
  (extended) to implement a new class Buffering.
\item In the payload of each UDP packet a chunk number (a counter that
  goes from the maximun value to 0) has been included in order to
  provide to the receiver the information to determine where to store
  the corresponding chunk in the circular buffer. Specifically, an
  unsigned integer of 16 bits has been used for representing the chunk
  numbers.
\item It has been taken into consideration that the critical part of
  InterCom (the method \verb|record_send_and_play()|) is a method that
  runs as an
  \href{https://en.wikipedia.org/wiki/Interrupt_handler}{interrup
    handler} that is called each time a new chunk is available
  in the ADC (see the previuous milestone). More precisely:
  \begin{enumerate}
  \item In order to minimize the latency, the recorded chunks are sent
    to the interlocutor as soon as possible.
  \item The playback of the chunks extracted from the buffer is
    \href{https://en.wikipedia.org/wiki/Gapless_playback}{\emph{gapless}}
    (without the ocurrence of silences) as long as the chunks have
    been received on time.
  \item As always, the lost\footnote{Those chunks that have not been
  received on time or never have been received.} chunks are replaced
    by zero-chunks in the playback.
  \end{enumerate}
\item A method \verb|receive_and_buffer()| is run now in a different
  execution
  \href{https://en.wikipedia.org/wiki/Thread_(computing)}{thread},
  decoupled from the \verb|record_send_and_play()| method. But notice
  that this can be achived without using the
  \href{https://docs.python.org/3/library/threading.html}{threading}
  or
  \href{https://docs.python.org/3/library/multiprocessing.html}{multiprocessing}
  packages because the interruption handler (the so called
  \emph{callback}() function in sounddevice) already runs in parallel
  with the main thread.
\end{enumerate}

This is an overview of the implementation:

\begin{lstlisting}[language=Python]
  # Interruption handler
  def record_send_and_play():
    chunk = record()  # (1)
    packed_chunk = pack(chunk)  # (2)
    send(packed_chunk)  # (3)
    chunk = unbuffer_next_chunk()  # (4)
    play(chunk)  # (5)

  # Main (not a new) thread
  def receive_and_buffer():
    packed_chunk = receive()  # (1)
    chunk_number, chunk = unpack(packed_chunk)  # (2)
    buffer(chunk_number, chunk)  # (3)
\end{lstlisting}

Notice that the Step (4) of the method \verb|record_send_and_play()|
extractcs from the buffer an unpacked\footnote{Chunks will be
compressed in a posterior milestone, and uncompressing is performed in
this step.} chunk. The chunks are buffered in the Step (3) of the
method \verb|receive_and_buffer()|. Notice also that the Step (1) of
\verb|receive_and_buffer()| is a blocking method that should return with
every new received chunk.

%\begin{pseudocode}{Buffering\_InterCom}{~}
%  \PROCEDURE{record\_send\_and\_play}{~}
%  \BEGIN
%    \text{chunk} \GETS \text{record}()\\
%    \text{packed\_chunk} \GETS \text{pack}(\text{chunk})\\
%    \text{send}(\text{packed\_chunk})\\
%    \text{chunk} \GETS \text{unbuffer\_next\_chunk}()\\
%    \text{play}(\text{chunk})
%  \END
%  \ENDPROCEDURE
%  \PROCEDURE{receive\_and\_buffer}{~}
%  \BEGIN
%    \text{packed\_chunk} \GETS \text{receive}()\\
%    \text{chunk\_number}, \text{chunk} \GETS \text{unpack}(\text{packe%d\_chunk})\\
%    \text{buffer}(\text{chunk\_number}, \text{chunk})
%  \END
%  \ENDPROCEDURE
%\end{pseudocode}

\subsection{Control of the buffer size in InterCom}
\label{sec:homework2}
\verb|buffer.py| can be run to inter-communicate two users (or one
user in the case of a simulation), and the buffering time (in
miliseconds) can be controlled with the \verb|--buffering_time|
parameter. Using a real o simulated environment, find the minimum
buffering time that allows to hide the jitter in your environment. In
the case of using a simulated one, find such minimal buffering time in
different jitter configurations (value, correlation, and
distribution). Experiment also with the loss of chunks to see the
effect of playing the empty chunks.

\section{Deliverables}

The results of the experiments proposed in the
Section~\ref{sec:homework} and the Section~\ref{sec:homework2}.

\section{Resources}

\bibliography{networking,nat}
