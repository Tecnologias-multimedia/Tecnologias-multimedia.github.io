\title{\href{https://www.ual.es/estudios/grados/presentacion/plandeestudios/asignatura/4015/40154321?idioma=zh_CN}{Tecnolog√≠as Multimedia} - Study Guide - Milestone 11: Spatial decorrelation in stereo audio signals}

\maketitle

\section{Description}

InterCom transmits a
\href{https://en.wikipedia.org/wiki/Stereophonic_sound}{stereo} (two
channels)
\href{https://en.wikipedia.org/wiki/Pulse-code_modulation}{PCM
  signal}. In most cases, the channels are
\href{https://en.wikipedia.org/wiki/Binaural_recording}{highly
  correlated} (especially when the microphone is mono), which means
that we can find a more efficient representation. To perform this
inter-channel
\href{https://en.wikipedia.org/wiki/Decorrelation}{decorrelation}~\cite{thinkstats}
we can use the \href{https://en.wikipedia.org/wiki/Linear_map}{linear
  transform}~\cite{strang4linear}
\begin{equation}
  w = Kx = \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}x,
  \label{eq:forward_transform_matrix_form}
\end{equation}
that can be also written as
\begin{equation}
  \begin{bmatrix}
    w_0 \\
    w_1
  \end{bmatrix}
  = 
  \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}
  \begin{bmatrix}
    x_0 \\
    x_1
  \end{bmatrix},
  \label{eq:forward_transform_matrix_form2}
\end{equation}
where $x$ is a stereo frame, $K$ is the (forward or analysis)
transform matrix and $w=\begin{bmatrix} w_0 & w_1\end{bmatrix}^{\text
  T}$ is the corresponding
\href{https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Example_in_image_processing}{decomposition}. In
this particular transform, the decomposition has two
\href{https://en.wikipedia.org/wiki/Sub-band_coding}{subbands} $w_0$
and $w_1$, and each subband has only one
\href{https://web.stanford.edu/class/ee398a/handouts/lectures/07-TransformCoding.pdf}{coefficient}.

The proposed matrix $K$ corresponds to the transform used in
\href{https://en.wikipedia.org/wiki/Joint_encoding#M/S_stereo_coding}{Mid/Side
  (M/S) stereo coding}~\cite{bosi2003intro} that we will call MST
(Mid/Side Transform), which is similar to the $2\times 2$ KLT
\href{http://fourier.eng.hmc.edu/e161/lectures/klt/node3.html}{(Karhunen-Lo\`eve
  Transform)}, the
\href{http://wavelets.pybytes.com/wavelet/haar/}{Haar
  Transform}~\cite{vetterli1995wavelets} and the $2\times 2$
\href{https://en.wikipedia.org/wiki/Hadamard_transform}{Discrete
  Walsh-Hadamard Transform}~\cite{sayood2017introduction}.

In general (for all the linear transforms),
Eqs.~\ref{eq:forward_transform_matrix_form} and
\ref{eq:forward_transform_matrix_form2} can be also expressed as
\begin{equation}
  w_u = \sum_i K_{u,i}x_i,
  \label{eq:forward_transform_linear_combination_form}
\end{equation}
where $K_{u,i}$ denotes $i$-th element of the $u$-th row of the matrix
$K$.

A major difference between the transformed data $w$ and the original
data $x$ is that the characteristics of the elements of $w$ are
determined by their position within the
decomposition~\cite{sayood2017introduction}. Thus, as a consequence of
how the matrix has been defined, the subband $w_0$ represents (very
roughly) the low frequencies of $x$ and $w_1$ the high
frequencies. This can be also seen in this
\href{https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/stereo_transforms_RD.ipynb}{notebook}.

The inverse (or synthesis) transform
\begin{equation}
  x = K^{-1}w
  \label{eq:inverse_transform}
\end{equation}
can be found from Eq. \ref{eq:forward_transform_matrix_form}, where we
get that
\begin{equation}
  \begin{array}{rcl}
  w_0 & = & x_0 + x_1\\
  w_1 & = & x_0 - x_1.
  \end{array}
\end{equation}
By solving $x_0$ (adding) and $x_1$ (substracting) in
these equations, we obtain that
\begin{equation}
  \begin{array}{rcl}
  x_0 & = & \frac{1}{2}(w_0 + w_1)\\
  x_1 & = & \frac{1}{2}(w_0 - w_1),
  \end{array}
\end{equation}
that in matrix form becomes
\begin{equation}
  \begin{bmatrix}
    x_0 \\
    x_1
  \end{bmatrix}
  = \frac{1}{2}
  \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}
  \begin{bmatrix}
    w_0 \\
    w_1
  \end{bmatrix}.
\end{equation}
Therefore,
\begin{equation}
  x = K^{-1}w = \frac{1}{2}K^{\text T}w = \frac{1}{2}Kw = \frac{1}{2}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}w.
  \label{eq:inverse_transform_matrix_form}
\end{equation}

As can be seen (previously ignoring the $\frac{1}{2}$ scale factor)
the inverse transform is the transpose of the forward transform. This
is a characteristic of all
\href{https://en.wikipedia.org/wiki/Orthogonal_transformation}{orthogonal
  transforms}~\cite{sayood2017introduction}. For the MST,
specifically, it also holds that $K^{\text T}=K$ because $K$ is
\href{https://en.wikipedia.org/wiki/Symmetric_matrix}{symmetric}.

Orthogonality is important for compression applications because the
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlation}
between subbands is 0, and therefore, the contributions of the
subbands to the reconstruction of the original signal are
independent\footnote{The total
  \href{https://en.wikipedia.org/wiki/Distortion}{distortion}
  distortion is the sum of the distortion
  contribution of each subband~\cite{sayood2017introduction}.}. Apart
from checking that $K^{-1}=K^{\text T}$, $K$ is orthogonal if the
\href{https://en.wikipedia.org/wiki/Inner_product_space}{inner
  product}\footnote{The inner product between two vectors is in some
  sense a measure of how ``similar'' they are
  \cite{sayood2017introduction}.}
(\href{https://math.stackexchange.com/questions/476738/difference-between-dot-product-and-inner-product}{also
  called} the \href{https://en.wikipedia.org/wiki/Dot_product}{dot
  product} when we work with
\href{https://en.wikipedia.org/wiki/Real_number}{real} signals) of the
\href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis
  vectors}\footnote{When we are working with discrete signals, we
  usually talk about vectors instead of functions. These vectors are
  sampled versions of the corresponding functions.)} is $0$ between
the different basis\footnote{If a set of vectors are linearly
  independent, then the set is called a basis for the subspace
  generated by linear combinations of this set. The basis set contains
  the smallest number of linearly independent vectors required to
  represent each element of the vector (sub)space. The number of basis
  vectors required to generate the space is called the dimension of
  the vector space~\cite{sayood2017introduction}.} vectors. In our
case $K_0=\begin{bmatrix}1 & 1\end{bmatrix}$~ and
$K_1=\begin{bmatrix} 1 & -1\end{bmatrix}$~, and as we can see
\begin{equation}
  \langle K_0,K_1 \rangle =
  \langle \begin{bmatrix}
    1 & 1
  \end{bmatrix}
  ,
  \begin{bmatrix}
    1 & -1
  \end{bmatrix}
  \rangle =
  \begin{bmatrix}
    1 & 1
  \end{bmatrix}
  \cdot
  \begin{bmatrix}
    1 & -1
  \end{bmatrix}
   = 0,
\end{equation}
which means that $K_0$ and $K_1$ are linearly independent\footnote{We
cannot derive one from the other using the operations that define a
vector space.}, and therefore they can be a part a basis
(set)~\cite{strang4linear}. The basis has also a direct interpretation
in terms of Signal Processing: $K_0$ is a
\href{https://en.wikipedia.org/wiki/Low-pass_filter}{low-pass filter},
$K_1$ is a
\href{https://en.wikipedia.org/wiki/High-pass_filter}{high-pass
  filter}, and $K$ is a
\href{https://en.wikipedia.org/wiki/Filter_bank}{filter bank} with two
\href{https://en.wikipedia.org/wiki/Digital_filter}{filters}.

Notice that
\begin{equation}
  w_i = \langle x, K_i\rangle.
\end{equation}

In our case, it also holds that
\begin{equation}
\begin{array}{l}
  \langle K_0,K_0 \rangle =
  \langle \begin{bmatrix}
    1 & 1
  \end{bmatrix}
  ,
  \begin{bmatrix}
    1 & 1
  \end{bmatrix}
  \rangle =
  \begin{bmatrix}
    1 & 1
  \end{bmatrix}
  \cdot
  \begin{bmatrix}
    1 & 1
  \end{bmatrix}
   = 2,
   \\
     \langle K_1,K_1 \rangle =
  \langle \begin{bmatrix}
    1 & -1
  \end{bmatrix}
  ,
  \begin{bmatrix}
    1 & -1
  \end{bmatrix}
  \rangle =
  \begin{bmatrix}
    1 & -1
  \end{bmatrix}
  \cdot
  \begin{bmatrix}
    1 & -1
  \end{bmatrix}
   = 2,
   \end{array}
\end{equation}
that implies that $K$ is not
\href{https://en.wikipedia.org/wiki/Orthonormality}{orthonormal},
i.e., the analysis transform is not
\href{https://en.wikipedia.org/wiki/Energy_(signal_processing)}{energy}
preserving~\cite{sayood2017introduction}. Another way of saying this
is that the \href{https://en.wikipedia.org/wiki/Parseval%27s_theorem}{Parseval's theorem}
  is not satisfied because
\begin{equation}
  \sum_i {w_i}^2 =
  (x_0+x_1)^2 + (x_0-x_1)^2 =
  (x_0^2+2x_0x_1+x_1^2) + (x_0^2-2x_0x_1+x_1^2) =
  2(x_0^2+x_1^2) =
  2\sum_i {x_i}^2.
  \label{eq:No_Parseval}
\end{equation}

The factor $2$ in the Eq.~\ref{eq:No_Parseval} is indicating that the
analysis-synthesis transform chain defined by $K$ and $K^{-1}$ has a
\href{https://en.wikipedia.org/wiki/Gain_(electronics)}{gain} of $2$
(the output of the synthesis transform will be equal to the input to
the analysis transform multiplied by $2$, which physically means that
we are \href{https://en.wikipedia.org/wiki/Amplifier}{amplifying} the
audio signal by a factor of $2$). To avoid this, as the
Eq.~\ref{eq:inverse_transform_matrix_form} indicates, we must divide
each subband ($w_0$ and $w_1$) by $2$ after aplying $K^{-1}$ to $w$.

Finally, because the gain of each subband can\footnote{We could use
quantization steps $\Delta_1$ and $\Delta_2$ inversely proportional to
the gain of the subbands $w_1$ and $w_2$, removing less
\href{https://en.wikipedia.org/wiki/Information}{information} from the
subband that has a higher gain.} be important in the
\href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)}{quantization}
stage, let's analyze them. By definition, the gain of the subband
$w_i$ is the \href{https://en.wikipedia.org/wiki/Lp_space}{L$_2$
  norm}\footnote{L$_2(f)$ (where $f$ is a function) is the set of all
functions with finite energy and constitues a vector
space~\cite{sayood2017introduction}. $L_2({\mathbb R})$ of simply
$L_2$ is the space of all functions $f(t)$ with a well defined
integral of the square of the modulus of the function. The $L$
signifies a Lebesque integral, the ``2'' denotes the integral of the
square of the modulus of the function, and ${\mathbb R}$ states that
the independent variable of integration is a number over the whole
real line. For a function $g(t)$ to be a member of that space is
denoted: $g\in L_2({\mathbb R})$ or simply $g\in
L_2$~\cite{burrus2013wavelets}.}  (named also
\href{https://en.wikipedia.org/wiki/Euclidean_distance}{Euclidean
  distance} in $N$-dimensional
\href{https://en.wikipedia.org/wiki/Vector_space}{spaces}) of the
basis vector $K_i$. Unfortunately, most of the transform are not
implemented using matrix-vector operations, but using
\href{https://en.wikipedia.org/wiki/Fast_Fourier_transform}{faster
  algorithms} based on a lattice of
\href{https://en.wikipedia.org/wiki/Butterfly_diagram}{computational
  bufferflies}. In general, we can determine $K_i$ simply by computing
the inverse transform of the decomposition $\begin{bmatrix} 0 & \cdots
  & 0 & 1 & 0 & \cdots & 0 \end{bmatrix}^{\text T}$, where the $1$
value is in the position $i$ of the subband $w_i$. In our example, we
get that

\begin{equation}
  \begin{array}{l}
    \begin{bmatrix}
      1 & 1 \\
      1 & -1
    \end{bmatrix}
    \begin{bmatrix}
      1 \\
      0
    \end{bmatrix}
    =
    \begin{bmatrix}
      1 & 1
    \end{bmatrix} = K_0,
    \\
    \begin{bmatrix}
      1 & 1 \\
      1 & -1
    \end{bmatrix}
    \begin{bmatrix}
      0 \\
      1
    \end{bmatrix}
    =
    \begin{bmatrix}
      1 & -1
    \end{bmatrix} = K_1.
  \end{array}
\end{equation}

Next, we compute the L$_2$ norm of the basis vectors as

\begin{equation}
  \begin{array}{l}
    \left\| K_0 \right\|_2 := \sqrt{\langle \begin{bmatrix}1 & 1\end{bmatrix}, \begin{bmatrix}1 & 1\end{bmatrix} \rangle} = \sqrt{\begin{bmatrix}1 & 1\end{bmatrix}\cdot \begin{bmatrix}1 & 1\end{bmatrix}} = \sqrt{2},\\
    \left\| K_1 \right\|_2 := \sqrt{\langle \begin{bmatrix}1 & -1\end{bmatrix}, \begin{bmatrix}1 & -1\end{bmatrix} \rangle} = \sqrt{\begin{bmatrix}1 & -1\end{bmatrix}\cdot \begin{bmatrix}1 & -1\end{bmatrix}} = \sqrt{2},
  \end{array}
\end{equation}

resulting that both subbands $w_1$ and $w_2$ have the same gain
($\sqrt{2}$). This result tell us that both subbands should use the
same quantization step ($\Delta_0=\Delta_1$). See the
\href{https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/stereo_transforms_RD.ipynb}{notebook}.

\begin{comment}
Unfortunately, this
estatement is only true if the
\href{https://en.wikipedia.org/wiki/Entropy_encoding}{entropy coding}
stage generates the same number of bits for both subbands, something
that rarely happens because we are compressing the coefficients of the
subbands considering the complete chunk (remember that we are
exploiting the
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{statistical
  correlation} between the sequence of coefficients generated by all
the frames of a chunk). In general, the amount of information provided
by each subband $w_i$ is different, and therefore, the discrete
\href{https://en.wikipedia.org/wiki/Rate%E2%80%93distortion_theory}{Rate
  Distortion} (RD) curve\footnote{A discrete RD curve is defined by
the
\href{https://en.wikipedia.org/wiki/Multi-objective_optimization}{Pareto
  front} form by the RD points.} generated by each subband is distint.

The standard solution for this problem is to select a $\Delta_i$ value
for each $w_i$ that select RD points with the same RD
\href{https://en.wikipedia.org/wiki/Slope}{slope}~\cite{vetterli2014foundations,sayood2017introduction}.
A RD point is defined as a pair or $(r,d)$ values where $r$ represents
a bit-rate (typically expressed in bits/sample) and $d$ represents a
distortion (that uses to be the
\href{https://en.wikipedia.org/wiki/Root-mean-square_deviation}{RMSE}
when we use the L$_2$ norm to measure distances). Therefore, to find
the two RD curves for the current chunk, we should apply the stereo
transform, use a set of quantization steps to each subband, and
compress the resulting quantization indexes for each quantization
step. This would find the $r$ values of our RD curve. Then,
decompress, dequantize and find the distortion for the chunk. This
would find the $d$ values. Finally, with this RD curve, we should
select the $\Delta_i$ values that provides the same slope for both
subbands.

Obviously, we can not use the previous algoritm for computing the RD
curves in a real-time application such as InterCom.\footnote{The
amount of computational resources would increase significatively.} We
need to make some assumptions in order to reduce the computational
cost of finding the RD curves. The first of our assumptions is that
between (temporally) adjacent chunks the RD curves are going to be
similar. Therefore, we can build the RD curve for the current chunk by
using the RD points generated\footnote{Each chunk is quantized and
compressed, so, we only need to compute the distortion to have the RD
point used for the chunk.} by the compression of previously processed
chunks. The second assumption is that we can estimate the average
slope of the complete RD curve by using only 2 RD points. Using this
information, we will try to use, for the current chunk, a pair of
$\Delta_i$ quantization steps that produce two RD curves (one curve
per subband) with the same average slope.
\end{comment}

\section{What you have to do?}

\begin{enumerate}
\item In a module named spatial.py, inherit the class
  Quantization and create a class named Spatial\_decorrelation.
\item Override the methods pack() and unpack(). In pack() perform the
  analysis transform previously described, and in unpack() the
  synthesis transform. These procedures should be applied to all the
  frames of a chunk using
  \href{https://www.oreilly.com/library/view/python-for-data/9781449323592/ch04.html}{vectorized
    operations}.
\item Has been the
  \href{https://en.wikipedia.org/wiki/Data_compression_ratio}{compression
    ratio} improved (on
  \href{https://en.wikipedia.org/wiki/Average}{average})? How much?
\end{enumerate}

\section{Timming}

You should reach this milestone at most one week.

\section{Deliverables}

The module spatial.py. Store it at the
\href{https://github.com/Tecnologias-multimedia/intercom}{root
  directory} of your InterCom's repo.

\section{Resources}

\bibliography{maths,data-compression,DWT,audio-coding,signal-processing}
