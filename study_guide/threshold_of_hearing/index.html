<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Considering the Threshold of Hearing</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'>Considering the Threshold of Hearing</h2>
 <div class='author'><span class='ecrm-1200'>Vicente González Ruiz</span></div><br />
<div class='date'><span class='ecrm-1200'>September 14, 2022</span></div>
   </div>
   <h3 class='sectionHead'><span class='titlemark'>1   </span> <a id='x1-10001'></a>Description</h3>
<!-- l. 7 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.1   </span> <a id='x1-20001.1'></a>A model of the Threshold of Human Hearing</h4>
<!-- l. 9 --><p class='noindent'>Psychoacoustics (see <a href='https://vicente-gonzalez-ruiz.github.io/the_sound/'>the sound</a>, <a href='https://vicente-gonzalez-ruiz.github.io/human_auditory_system/'>the human auditory system</a>, and <a href='https://vicente-gonzalez-ruiz.github.io/human_sound_perception/'>the human sound
perception</a>) has determined that the HAS (Human Auditory System) has a
sensitivity that depends on the frequency of the sound, the so called THH (<a href='https://en.wikipedia.org/wiki/Absolute_threshold_of_hearing'>Threshold
of Human Hearing</a>). This basically means that some subbands can be quantized with
a larger quantization step than others without a noticeable increase (from a
perfection perspective) of the quantization noise.
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 25 --><p class='noindent'><div style='text-align:center;'> <img src='graphics/ToHH.svg' /> </div>  <a id='x1-2001r1'></a>
<a id='x1-2002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 1: </span><span class='content'>A model for the threshold of human hearing.                    </span></figcaption><!-- tex4ht:label?: x1-2001r1  -->
                                                                  

                                                                  
   </figure>
<!-- l. 30 --><p class='indent'>   A good approximation of the THH (Threshold of Human Hearing) for a 20-years
old person can be obtained with <span class='cite'>[<a href='#Xbosi2003intro'>1</a>]</span> \begin {equation}  T(f)\text {[dB]} = 3.64(f\text {[kHz]})^{-0.8} - 6.5e^{f\text {[kHz]}-3.3)^2} + 10^{-3}(f\text {[kHz]})^4. \label {eq:ToHH}  \end {equation}
This equation has been plotted in the Fig. <a href='#x1-2001r1'>1<!-- tex4ht:ref: fig:ToHH  --></a>.
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.2   </span> <a id='x1-30001.2'></a>DWT subbands and quantization steps</h4>
<!-- l. 39 --><p class='noindent'>The number of DWT subbands \begin {equation}  N_{\text {sb}} = N_{\text {levels}} + 1  \end {equation}
where \(N_{\text {levels}}\) is the number of levels of the DWT. Except for the \({\mathbf l}^{N_{\text {levels}}}\) subband (the lowest-pass
frequency of the decomposition), it holds that \begin {equation}  W({\mathbf h}^s) = \frac {1}{2}W({\mathbf h}^{s-1}),  \end {equation}
being \(W(\cdot )\) the bandwidth of the corresponding subband \(s\). Therefore, considering that the
bandwidth of the audio signal is \(22050\) Hz, the bandwidth \(W({\mathbf h}^1)\) of the \({\mathbf h}^1\) subband is \(11025\) Hz, \(W({\mathbf h} ^2)=22025/4\), and so
on. It also holds that \begin {equation}  W({\mathbf l}^{N_{\text {levels}}}) = W({\mathbf h}^{N_{\text {levels}}}).  \end {equation}
</p><!-- l. 57 --><p class='indent'>   The idea is to determine, knowing the frequencies represented in each
DWT subband and the THH curve, the quantization step that should be
applied to each subband. This idea has been implemented in the module
threshold.py.
</p><!-- l. 62 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>2   </span> <a id='x1-40002'></a>What you have to do?</h3>
<!-- l. 64 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>2.1   </span> <a id='x1-50002.1'></a>Determining your threshold of hearing</h4>
<!-- l. 66 --><p class='noindent'>The threshold of hearing plotted in the Fig. <a href='#x1-2001r1'>1<!-- tex4ht:ref: fig:ToHH  --></a> can be different
to the curve which corresponds with your current “hearing
capabilities”.<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-5001f1'></a>
For this reason, in the module threshold.py, implement a procedure for determining
your threshold curve. The idea is to generate a sequence of pure tones localized at
different frequencies. Each tone should start with an amplitude of zero, and
progressively (linearly) increase the amplitude until the user hit a key when he start
listening the tone. After this procedure, you should be able to plot your
threshold curve similar to the depicted in the Fig. <a href='#x1-2001r1'>1<!-- tex4ht:ref: fig:ToHH  --></a>. Finally, notice that such
threshold curve should be used by your interlocutor, and you should use your
intercolutor’s threshold curve. Please, modify threshold.py to implement such
extra<span class='footnote-mark'><a href='#fn2x0' id='fn2x0-bk'><sup class='textsuperscript'>2</sup></a></span><a id='x1-5002f2'></a>
functionality.
                                                                  

                                                                  
</p><!-- l. 83 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>2.2   </span> <a id='x1-60002.2'></a>Subjective performance</h4>
<!-- l. 85 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-6002x1'>Using a recording tool such as <a href='http://audacity.sourceforge.net'>Audacity</a> or <a href='http://plugin.org.uk/timemachine/'>JACK Timemachine</a>, record the
     simulated transmission of a piece of audio and create a <span class='ectt-1000'>.wav </span>file, when the
     audio has been transmitted using <span class='ectt-1000'>temporal_overlapped_DWT_coding.py</span>
     and <span class='ectt-1000'>threshold.py</span>, using in both cases the same transmission bit-rate.
     Use the quantization step for controlling the bit-rate.
     </li>
<li class='enumerate' id='x1-6004x2'>Determine which audio sounds better, from a subjective point of view.
     Repeat this step the number of times you consider necessary.</li></ol>
<!-- l. 98 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>3   </span> <a id='x1-70003'></a>Deliverables</h3>
<!-- l. 100 --><p class='noindent'>The module threshold.py and a report of how your proposal works, including a
subjective performance comparison.
</p><!-- l. 103 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>4   </span> <a id='x1-80004'></a>Resources</h3>
   <div class='thebibliography'>
   <p class='bibitem'><span class='biblabel'>
 [1]<span class='bibsp'>   </span></span><a id='Xbosi2003intro'></a>M. Bosi and R.E. Goldberd.  <a href='https://last.hit.bme.hu/download/vidtechlab/fcc/literature/audio/audio_coding_standards_book.pdf'><span class='ecti-1000'>Introduction to Digital Audio Coding and
   </span><span class='ecti-1000'>Standards</span></a>. Kluwer Academic Publishers, 2003.
</p>
   </div>
<p><a id='Q1-1-10'></a></p>
   <div class='footnotes'><!-- l. 70 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>For example, your speakers could not have a flat frequency response, or your room could
</span><span class='ecrm-0800'>attenuate more, some freqencies.</span></p>
<!-- l. 81 --><p class='indent'>     <span class='footnote-mark'><a href='#fn2x0-bk' id='fn2x0'><sup class='textsuperscript'>2</sup></a></span><span class='ecrm-0800'>This fine tunning of the threshold of hearing should be optional when you run
</span><span class='ecrm-0800'>InterCom.</span></p>                                                                                                            </div>
 
</body> 
</html>