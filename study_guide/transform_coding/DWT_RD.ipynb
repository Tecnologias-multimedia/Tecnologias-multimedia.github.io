{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A [RD](https://en.wikipedia.org/wiki/Rate%E2%80%93distortion_theory)-Comparison of (Dyadic) DWTs\n",
    "\n",
    "The DWT transforms the complete sequence (no chunks are considered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import pywt # pip install pywavelets\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy import signal\n",
    "import zlib\n",
    "import pylab\n",
    "from IPython.display import display, Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(y, xlabel='', ylabel='', title=''):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.grid()\n",
    "    ax.xaxis.set_label_text(xlabel)\n",
    "    ax.yaxis.set_label_text(ylabel)\n",
    "    x = np.linspace(0, len(y)-1, len(y))\n",
    "    ax.plot(x, y, '.', markersize=1)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce some sound ... for example, speak for 5 seconds\n",
    "The audio signal will be used to compare the RD performance of the transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44100      # Sampling frequency\n",
    "duration = 5.0  # seconds\n",
    "x = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype=np.int16)\n",
    "print(\"Say something!\")\n",
    "while sd.wait():\n",
    "    pass\n",
    "print(\"done\")\n",
    "x = x.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is your audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sd.play(x)\n",
    "plot(x, \"Sample\", \"Amplitude\", \"Audio Signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's remove some samples from the begining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[50000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is your definitive audio sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sd.play(x)\n",
    "plot(x, \"Sample\", \"Amplitude\", \"Audio Signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_levels = 5          # Number of levels of the DWT\n",
    "signal_mode_extension = \"per\"\n",
    "Delta = 32\n",
    "Q_steps = range(Delta, 1024, Delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Filter's response in the frequency domain](https://en.wikipedia.org/wiki/Filter_(signal_processing)#The_transfer_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_complex_energy(x):\n",
    "    #return np.sum(x[:, 0].astype(np.double)*x[:, 0].astype(np.double))/len(x[:, 0]) + \\\n",
    "    #       np.sum(x[:, 1].astype(np.double)*x[:, 1].astype(np.double))/len(x[:, 1])\n",
    "    return np.sum(x.real.astype(np.double)*x.real.astype(np.double) +\n",
    "                  x.imag.astype(np.double)*x.imag.astype(np.double))/len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal filters (1 level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#filters_name = \"haar\"\n",
    "filters_name = \"db5\"\n",
    "#filters_name = \"db7\"\n",
    "#filters_name = \"db11\"\n",
    "#filters_name = \"db20\"\n",
    "wavelet = pywt.Wavelet(filters_name)\n",
    "\n",
    "K0, K1, __ = wavelet.wavefun(level=1) # For orthogonal transforms\n",
    "# phi, psi, x\n",
    "w0, h0 = signal.freqz(K0, fs=44100)\n",
    "w1, h1 = signal.freqz(K1, fs=44100)\n",
    "\n",
    "plt.title(f'{filters_name} Frequency Responses')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Gain')\n",
    "plt.plot(w0, abs(h0), label=\"$\\\\phi (\\mathbf{K}_0)$\")\n",
    "plt.plot(w1, abs(h1), label=\"$\\\\psi (\\mathbf{K}_1)$\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\mathbf{K}_0\" + f\" = {average_complex_energy(h0)}\"))\n",
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\mathbf{K}_1\" + f\" = {average_complex_energy(h1)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal filters (more than 1 level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#filters_name = \"haar\"\n",
    "filters_name = \"db5\"\n",
    "#filters_name = \"db7\"\n",
    "#filters_name = \"db11\"\n",
    "#filters_name = \"db20\"\n",
    "wavelet = pywt.Wavelet(filters_name)\n",
    "\n",
    "N_levels = 3\n",
    "\n",
    "for l in range(N_levels):\n",
    "    filters = wavelet.wavefun(level = (l+1))[:-1]\n",
    "    w0, h0 = signal.freqz(filters[0], fs=44100)\n",
    "    w1, h1 = signal.freqz(filters[1], fs=44100)\n",
    "    #plt.plot(w0, abs(h0))\n",
    "    plt.plot(w1, abs(h1), label=\"$\\\\mathbf{h}$\" + f\"$^{l}$\")\n",
    "    #print(f\"Average energy of K_{l} = {average_complex_energy(h1)}\")\n",
    "    display(Math(\"\\\\text{Average energy of}~\" + \"\\mathbf{h}\" + f\"^{l}\" + f\" = {average_complex_energy(h1)}\"))\n",
    "plt.plot(w0, abs(h0), label=\"$\\\\mathbf{l}$\" + f\"$^{l}$\")\n",
    "#print(f\"Average energy of K_{l} = {average_complex_energy(h1)}\")\n",
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\mathbf{l}\" + f\"^{l}\" + f\" = {average_complex_energy(h0)}\"))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, after the decimation by 2, the definitive energy of each subband remains equal to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's see how to obtain the synthesis filters using the inverse transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter(wavelet, coef_index, N):\n",
    "    '''Generate the taps of the inverse transform setting a delta in the transform\n",
    "    domain and running the inverse transform.'''\n",
    "    zeros = np.zeros(N)\n",
    "    decomposition = pywt.wavedec(zeros, wavelet=wavelet, level=1, mode=\"per\")\n",
    "    coefficients, slices = pywt.coeffs_to_array(decomposition)\n",
    "    coefficients[coef_index] = 1\n",
    "    decomposition = pywt.array_to_coeffs(coefficients, slices, output_format=\"wavedec\")\n",
    "    samples = pywt.waverec(decomposition, wavelet=wavelet, mode=\"per\")\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#K0, K1, __ = wavelet.wavefun(level=1) # For orthogonal transforms\n",
    "#K0_basis, K0_dual, K1_basis, K1_dual__ = wavelet.wavefun(level=1) # For bi-orthogonal transforms\n",
    "#K0 = get_filter(wavelet, 8, 64)\n",
    "#K1 = get_filter(wavelet, 56, 64)\n",
    "K0 = get_filter(wavelet, 32, 128)\n",
    "K1 = get_filter(wavelet, 96, 128)\n",
    "w0, h0 = signal.freqz(K0, fs=44100)\n",
    "w1, h1 = signal.freqz(K1, fs=44100)\n",
    "\n",
    "plt.title(f'{filters_name} Frequency Responses')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Gain')\n",
    "plt.plot(w0, abs(h0), label=\"$\\\\phi (\\mathbf{K}_0)$\")\n",
    "plt.plot(w1, abs(h1), label=\"$\\\\psi (\\mathbf{K}_1)$\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\mathbf{K}_0\" + f\" = {average_complex_energy(h0)}\"))\n",
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\mathbf{K}_1\" + f\" = {average_complex_energy(h1)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the gain is ~1 for both filters (for both, the analysis and the synthesis). When the DWT domain is quantized, this implies that the quantization error will be multiplied by the same gain in all the subbands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-orthogonal filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#filters_name = \"bior1.1\"\n",
    "#filters_name = \"bior2.2\"\n",
    "filters_name = \"bior3.5\"\n",
    "#filters_name = \"rbio2.2\"\n",
    "wavelet = pywt.Wavelet(filters_name)\n",
    "\n",
    "#K0, K1, __ = wavelet.wavefun(level=1) # For orthogonal transforms\n",
    "K0_basis, K1_basis, K0_dual, K1_dual, __ = wavelet.wavefun(level=1) # For bi-orthogonal transforms\n",
    "# phi_d, psi_d, phi_r, psi_r, x\n",
    "w0_basis, h0_basis = signal.freqz(K0_basis, fs=44100)\n",
    "w1_basis, h1_basis = signal.freqz(K1_basis, fs=44100)\n",
    "w0_dual, h0_dual = signal.freqz(K0_dual, fs=44100)\n",
    "w1_dual, h1_dual = signal.freqz(K1_dual, fs=44100)\n",
    "\n",
    "plt.title(f'{filters_name} Frequency Responses')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Gain')\n",
    "plt.plot(w0_basis, abs(h0_basis), label=\"$\\\\tilde\\\\phi~(\\mathbf{K}_0)$\")\n",
    "plt.plot(w1_basis, abs(h1_basis), label=\"$\\\\phi~(\\mathbf{K}_0^{-1})$\")\n",
    "plt.plot(w0_dual, abs(h0_dual), label=\"$\\\\tilde\\\\psi~(\\mathbf{K}_1)$\")\n",
    "plt.plot(w1_dual, abs(h1_dual), label=\"$\\\\psi~(\\mathbf{K}_1^{-1})$\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\\\tilde\\\\phi~(\\mathbf{K}_0)\" + f\" = {average_complex_energy(h0_basis)}\"))\n",
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\\\phi~(\\mathbf{K}_0^{-1})\" + f\" = {average_complex_energy(h1_basis)}\"))\n",
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\\\tilde\\\\psi~(\\mathbf{K}_1)\" + f\" = {average_complex_energy(h0_dual)}\"))\n",
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\\\psi~(\\mathbf{K}_1^{-1})\" + f\" = {average_complex_energy(h1_dual)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen,  $\\psi\\bot\\tilde\\phi$ and $\\phi\\bot\\tilde\\psi$. Moreover, now the gain of the subbands after considering the decimation, is not constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total gain of the filters\n",
    "\n",
    "The gain of the synthesis filters can be computed as the squared norm ($L^2$ norm) of the inverse transform of a [Dirac delta function](https://en.wikipedia.org/wiki/Dirac_delta_function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthogonal\n",
    "#filters_name = \"haar\"\n",
    "#filters_name = \"db5\"\n",
    "#filters_name = \"db7\"\n",
    "#filters_name = \"db11\"\n",
    "#filters_name = \"db20\"\n",
    "\n",
    "# Bi-orthogonal\n",
    "#filters_name = \"bior1.1\"\n",
    "#filters_name = \"bior2.2\"\n",
    "filters_name = \"bior3.5\"\n",
    "#filters_name = \"rbio2.2\"\n",
    "\n",
    "wavelet = pywt.Wavelet(filters_name)\n",
    "K0 = get_filter(wavelet, 32, 128)\n",
    "K1 = get_filter(wavelet, 96, 128)\n",
    "w0, h0 = signal.freqz(K0, fs=44100)\n",
    "w1, h1 = signal.freqz(K1, fs=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.title(f'{filters_name} Frequency Responses')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Gain')\n",
    "plt.plot(w0, abs(h0), label=\"$\\\\phi~(\\mathbf{K}_0^{-1})$\")\n",
    "plt.plot(w1, abs(h1), label=\"$\\\\psi~(\\mathbf{K}_1^{-1})$\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\mathbf{K}_0^{-1}\" + f\" = {average_complex_energy(h0)}\"))\n",
    "display(Math(\"\\\\text{Average energy of}~\" + \"\\mathbf{K}_1^{-1}\" + f\" = {average_complex_energy(h1)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Orthogonal transforms implemented in PyWavelets have the same gain in both filters, but this is not true for bi-orthogonal transforms. In general, the low frequency subbands in bi-orthogonal subbands need a higher dynamic range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the gain of the full transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_energy(x):\n",
    "    #return np.sum(x[:, 0].astype(np.double)*x[:, 0].astype(np.double))/len(x[:, 0]) + \\\n",
    "    #       np.sum(x[:, 1].astype(np.double)*x[:, 1].astype(np.double))/len(x[:, 1])\n",
    "    return np.sum(x.astype(np.double)*x.astype(np.double))/len(x)\n",
    "\n",
    "def analyze(chunk, wavelet, N_levels):\n",
    "    decomposition = pywt.wavedec(chunk, wavelet=wavelet, level=N_levels,\n",
    "                                 mode=signal_mode_extension)\n",
    "    return decomposition\n",
    "\n",
    "def synthesize(decomposition, wavelet):\n",
    "    reconstructed_chunk = pywt.waverec(decomposition, wavelet=wavelet,\n",
    "                                       mode=signal_mode_extension)\n",
    "    return reconstructed_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthogonal\n",
    "#filters_name = \"haar\"\n",
    "#filters_name = \"db5\"\n",
    "#filters_name = \"db7\"\n",
    "#filters_name = \"db11\"\n",
    "#filters_name = \"db20\"\n",
    "\n",
    "# Bi-orthogonal (but not orthogonal)\n",
    "#filters_name = \"bior1.1\"\n",
    "#filters_name = \"bior2.2\"\n",
    "#filters_name = \"bior3.5\"\n",
    "filters_name = \"rbio2.2\"\n",
    "\n",
    "wavelet = pywt.Wavelet(filters_name)\n",
    "\n",
    "y = analyze(x, wavelet, 3)\n",
    "z = synthesize(y, wavelet)\n",
    "print(average_energy(x), average_energy(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All transform are energy preserving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD (Rate Distortion) curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some RD stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(x, y):\n",
    "    error_signal = x - y\n",
    "    return math.sqrt(average_energy(error_signal))\n",
    "\n",
    "# Based on https://stackoverflow.com/questions/15450192/fastest-way-to-compute-entropy-in-python\n",
    "def entropy_in_bits_per_symbol(sequence_of_symbols):\n",
    "    value, counts = np.unique(sequence_of_symbols, return_counts = True)\n",
    "    probs = counts / len(sequence_of_symbols)\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    entropy = 0.\n",
    "    for i in probs:\n",
    "        entropy -= i * math.log(i, 2)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def deadzone_quantize(x, quantization_step):\n",
    "    k = (x / quantization_step).astype(np.int32)\n",
    "    return k\n",
    "\n",
    "def deadzone_dequantize(k, quantization_step):\n",
    "    y = quantization_step * k\n",
    "    return y\n",
    "\n",
    "def deadzone_qdeq(x, quantization_step):\n",
    "    k = deadzone_quantize(x, quantization_step)\n",
    "    y = deadzone_dequantize(k, quantization_step)\n",
    "    return k, y\n",
    "\n",
    "def quantize(decomposition, q_steps):\n",
    "    quantized_decomposition = []\n",
    "    for subband, q_step in zip(decomposition, q_steps):\n",
    "        quantized_subband = deadzone_quantize(subband, q_step)\n",
    "        quantized_decomposition.append(quantized_subband)\n",
    "    return quantized_decomposition\n",
    "\n",
    "def analyze_and_quantize(chunk, wavelet, N_levels, q_steps):\n",
    "    decomposition = analyze(chunk, wavelet, N_levels)\n",
    "    quantized_decomposition = quantize(decomposition, q_steps)\n",
    "    return quantized_decomposition\n",
    "\n",
    "def dequantize(quantized_decomposition, q_steps):\n",
    "    dequantized_decomposition = []\n",
    "    for subband, q_step in zip(quantized_decomposition, q_steps):\n",
    "        dequantized_subband = deadzone_dequantize(subband, q_step)\n",
    "        dequantized_decomposition.append(dequantized_subband)\n",
    "    return dequantized_decomposition\n",
    "\n",
    "def dequantize_and_synthesize(quantized_decomposition, wavelet, q_steps):\n",
    "    dequantized_decomposition = dequantize(quantized_decomposition, q_steps)\n",
    "    reconstructed_chunk = synthesize(dequantized_decomposition, wavelet)\n",
    "    return reconstructed_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic RD curve using the RMSE VS the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RD_curve_entropy(chunk, wavelet, N_levels):\n",
    "    RD_points = []\n",
    "    for q_step in Q_steps:\n",
    "        q_steps = [q_step] * (N_levels + 1)\n",
    "        quantized_decomposition = analyze_and_quantize(chunk, wavelet, N_levels, q_steps)\n",
    "        k = np.concatenate(quantized_decomposition)\n",
    "        #rate = 8*len(zlib.compress(k.copy()))/len(chunk)\n",
    "        rate = entropy_in_bits_per_symbol(k) + entropy_in_bits_per_symbol(k)\n",
    "        reconstructed_chunk = dequantize_and_synthesize(quantized_decomposition, wavelet, q_steps)\n",
    "        distortion = RMSE(chunk, reconstructed_chunk)\n",
    "        RD_points.append((rate, distortion))\n",
    "    return RD_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_levels = 6\n",
    "\n",
    "# Orthogonal\n",
    "#filters_name = \"haar\"\n",
    "#filters_name = \"db5\"\n",
    "#filters_name = \"db7\"\n",
    "#filters_name = \"db11\"\n",
    "#filters_name = \"db20\"\n",
    "\n",
    "# Bi-orthogonal\n",
    "#filters_name = \"bior1.1\"\n",
    "#filters_name = \"bior2.2\"\n",
    "filters_name = \"bior3.5\"\n",
    "#filters_name = \"rbio2.2\"\n",
    "\n",
    "wavelet = pywt.Wavelet(filters_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RD_points = RD_curve(x[0:frames_per_chunk], wavelet, 3)\n",
    "RD_points_entropy = RD_curve_entropy(x, wavelet, N_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.title(\"RD Tradeoff\")\n",
    "plt.xlabel(\"Bits per Sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*RD_points_entropy), c='b', marker=\"+\", label=f'{wavelet}')\n",
    "#plt.scatter(*zip(*KLT_RD_points), c='r', marker=\"x\", label='KLT')\n",
    "#plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RD curve using DEFLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RD_curve_DEFLATE(chunk, wavelet, N_levels):\n",
    "    RD_points = []\n",
    "    for q_step in Q_steps:\n",
    "        q_steps = [q_step] * (N_levels + 1)\n",
    "        quantized_decomposition = analyze_and_quantize(chunk, wavelet, N_levels, q_steps)\n",
    "        #print(len(quantized_decomposition[3]))\n",
    "        k = np.concatenate(quantized_decomposition)\n",
    "        rate = 8*len(zlib.compress(k.copy()))/len(chunk)\n",
    "        #print(len(zlib.compress(k.copy())))\n",
    "        #rate = entropy_in_bits_per_symbol(k) + entropy_in_bits_per_symbol(k)\n",
    "        reconstructed_chunk = dequantize_and_synthesize(quantized_decomposition, wavelet, q_steps)\n",
    "        distortion = RMSE(chunk, reconstructed_chunk)\n",
    "        RD_points.append((rate, distortion))\n",
    "    return RD_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_points_DEFLATE = RD_curve_DEFLATE(x, wavelet, N_levels)\n",
    "#print(RD_points_DEFLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.title(\"RD Tradeoff\")\n",
    "plt.xlabel(\"Bits per Sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.scatter(*zip(*RD_points_entropy), c='b', marker=\"+\", label='entropy')\n",
    "plt.scatter(*zip(*RD_points_DEFLATE), c='r', marker=\"x\", label='DEFLATE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_gains(N_samples, wavelet, N_levels):\n",
    "    gains = []\n",
    "    chunk = np.zeros(N_samples)\n",
    "    decomposition = analyze(chunk, wavelet, N_levels)\n",
    "    decomposition[0][len(decomposition[0])//2] = 1\n",
    "    reconstructed_chunk = synthesize(decomposition, wavelet)\n",
    "    gains.append(average_energy(reconstructed_chunk))\n",
    "    prev_sb = decomposition[0]\n",
    "    for sb in decomposition[1:]:\n",
    "        prev_sb[...] = 0\n",
    "        sb[len(sb)//2] = 1\n",
    "        reconstructed_chunk = synthesize(decomposition, wavelet)\n",
    "        gains.append(average_energy(reconstructed_chunk))\n",
    "        prev_sb = sb\n",
    "    \n",
    "    return gains/sum(gains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = normalized_gains(1024, wavelet, N_levels)\n",
    "print(gains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RD_curve_entropy_gains(chunk, wavelet, N_levels, gains):\n",
    "    # The gains has been used with the squared norm!\n",
    "    Q_factors = np.array([math.sqrt(gains[0]/i) for i in gains])\n",
    "    RD_points = []\n",
    "    for q_step in Q_steps:\n",
    "        q_steps = q_step / Q_factors\n",
    "        quantized_decomposition = analyze_and_quantize(chunk, wavelet, N_levels, q_steps)\n",
    "        k = np.concatenate(quantized_decomposition)\n",
    "        #rate = 8*len(zlib.compress(k.copy()))/len(chunk)\n",
    "        rate = entropy_in_bits_per_symbol(k) + entropy_in_bits_per_symbol(k)\n",
    "        reconstructed_chunk = dequantize_and_synthesize(quantized_decomposition, wavelet, q_steps)\n",
    "        distortion = RMSE(chunk, reconstructed_chunk)\n",
    "        RD_points.append((rate, distortion))\n",
    "    return RD_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_points_entropy_gains = RD_curve_entropy_gains(x, wavelet, N_levels, gains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.title(\"RD Tradeoff\")\n",
    "plt.xlabel(\"Bits per Sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.plot(*zip(*RD_points_entropy), c='b', label='Without gains')\n",
    "plt.plot(*zip(*RD_points_entropy_gains), c='r', label='Considering gains')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RD_curve_DEFLATE_gains(chunk, wavelet, N_levels, gains):\n",
    "    # The gains has been used with the squared norm!\n",
    "    Q_factors = np.array([math.sqrt(gains[0]/i) for i in gains])\n",
    "    print(\"Didiving QSS by \", Q_factors)\n",
    "    RD_points = []\n",
    "    for q_step in Q_steps:\n",
    "        # The bigger the quantization step size, the larger the Q error\n",
    "        q_steps = q_step / Q_factors\n",
    "        quantized_decomposition = analyze_and_quantize(chunk, wavelet, N_levels, q_steps)\n",
    "        k = np.concatenate(quantized_decomposition)\n",
    "        rate = 8*len(zlib.compress(k.copy()))/len(chunk)\n",
    "        #rate = entropy_in_bits_per_symbol(k) + entropy_in_bits_per_symbol(k)\n",
    "        reconstructed_chunk = dequantize_and_synthesize(quantized_decomposition, wavelet, q_steps)\n",
    "        distortion = RMSE(chunk, reconstructed_chunk)\n",
    "        RD_points.append((rate, distortion))\n",
    "    return RD_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_points_DEFLATE_gains = RD_curve_DEFLATE_gains(x, wavelet, N_levels, gains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.title(\"RD Tradeoff\")\n",
    "plt.xlabel(\"Bits per Sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.plot(*zip(*RD_points_DEFLATE), c='b', label='Without gains')\n",
    "plt.plot(*zip(*RD_points_DEFLATE_gains), c='r', label='Considering gains')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions about the filter gains and the quantization step size\n",
    "1. For orthogonal transforms, there results is exactly the same.\n",
    "2. For bi-orthogonal transforms, there is a minor advantage on modulating the quantization step sizes with the relative gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of  each subband in the distortion of the reconstructed chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subbands_DEFLATE_RD_curve(chunk, wavelet, N_levels):\n",
    "    '''RD curves per subband.'''    \n",
    "    subbands_RD_points = [None] * (N_levels + 1)\n",
    "    decomposition = analyze(chunk, wavelet, N_levels)\n",
    "    #print(len(decomposition))\n",
    "    for l in range(N_levels + 1):\n",
    "        #print(len(chunk), len(decomposition[l]))\n",
    "        #print(decomposition)\n",
    "        zero_chunk = np.zeros_like(chunk)\n",
    "        zero_decomposition = analyze(zero_chunk, wavelet, N_levels)\n",
    "        zero_decomposition[l][:] = decomposition[l]\n",
    "        #print(decomposition[l])\n",
    "        subbands_RD_points[l] = []\n",
    "        for q_step in Q_steps:\n",
    "            #print(q_step)\n",
    "            quantized_subband = deadzone_quantize(zero_decomposition[l], q_step)\n",
    "            zero_decomposition[l][:] = quantized_subband\n",
    "            k = np.concatenate(zero_decomposition)\n",
    "            rate = 8*len(zlib.compress(k.copy()))/len(chunk)\n",
    "            dequantized_subband = deadzone_dequantize(quantized_subband, q_step)\n",
    "            zero_decomposition[l][:] = dequantized_subband\n",
    "            reconstructed_chunk = synthesize(zero_decomposition, wavelet)\n",
    "            distortion = RMSE(chunk, reconstructed_chunk)\n",
    "            #print(l, rate, distortion)\n",
    "            subbands_RD_points[l].append((rate, distortion))\n",
    "        subbands_RD_points[l].reverse()\n",
    "\n",
    "    return subbands_RD_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subband_DEFLATE_RD_points = subbands_DEFLATE_RD_curve(x, wavelet, N_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "plt.title(\"RD using only one subband\")\n",
    "plt.xlabel(\"Bits per Sample\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "i = 0\n",
    "for s in subband_DEFLATE_RD_points:\n",
    "    plt.plot(*zip(*s), marker=\".\", label=f'Using only subband index {i}', color=cm.cool(i/4))\n",
    "    i += 1\n",
    "plt.plot(*zip(*RD_points_DEFLATE), label=\"Using all subbands\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"RMSE (using only zeros) =\", RMSE(x, np.zeros(x.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def animate(frame):\n",
    "    i = 0\n",
    "    #plt.xscale(\"log\")\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.xscale(\"linear\")\n",
    "    plt.yscale(\"linear\")\n",
    "    plt.xlabel(\"Bits per Sample\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    for s in subband_DEFLATE_RD_points:\n",
    "        plt.title(f\"$\\Delta={frame*Delta}$\")\n",
    "        plt.plot(*zip(*s[0:frame]), marker=\".\", color=cm.cool(i/4))\n",
    "        # Plotear además la reconstrucción\n",
    "        plt.plot(*zip(*RD_points_DEFLATE[::-1][0:frame]), color='black')\n",
    "        i += 1\n",
    "    #return plt,\n",
    "    \n",
    "def init():\n",
    "    for s in subband_DEFLATE_RD_points:\n",
    "        plt.plot(*zip(*s), marker=\".\", color='white')\n",
    "    plt.plot(*zip(*RD_points_DEFLATE[::-1]), color=\"white\")\n",
    "    #return plt,\n",
    "\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, animate, init_func=init, interval=1000, frames=len(Q_steps), repeat=True)\n",
    "\n",
    "# To save the animation, use e.g.\n",
    "#\n",
    "# ani.save(\"movie.mp4\")\n",
    "#\n",
    "# or\n",
    "#\n",
    "# writer = animation.FFMpegWriter(\n",
    "#     fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "# ani.save(\"movie.mp4\", writer=writer)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "1. The $\\mathbf{l}^{l+1}$ subband is, with a lot of difference, the most important subband.\n",
    "2. The $\\mathbf{h}^1$ subband is, with a lot of difference, the least important one.\n",
    "3. If we use the same quantization step size for all the subbands, the quality of the reconstruction should be good because the *quality layers* are used by their slope. This is true, even for bi-orthogonal transforms.\n",
    "4. Bi-orthogonal filters behave has orthogonal ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra considerations\n",
    "1. Bi-orthogonal subbands are \"in-phase\", which means that we can establish a spatial/temporal relation between the coefficients of different subbands.\n",
    "2. The previous aspect cannot be done for orthogonal wavelet transforms, except when the length of the filters is 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
