<!DOCTYPE html> 
<html lang="en-US" xml:lang="en-US" > 
<head> <title>Transform Coding for Redundancy Removal</title> 
<meta  charset="utf-8" /> 
<meta name="generator" content="TeX4ht (https://tug.org/tex4ht/)" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" /> 
<link rel="stylesheet" type="text/css" href="index.css" /> 
<meta name="src" content="index.tex" /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script type="text/javascript" async="async" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>  
</head><body 
>
<!--l. 3--><p class="noindent" >Use 16 bits/coeﬃcient and CTE (Chunk Truncation Encoding).
</p>
   <div class="maketitle">
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class="titleHead">Transform Coding for Redundancy Removal</h2>
 <div class="author" ><a 
href="https://cms.ual.es/UAL/personas/persona.htm?id=515256515553484875" ><span 
class="ecrm-1200">Vicente Gonz</span><span 
class="ecrm-1200">á</span><span 
class="ecrm-1200">lez Ruiz</span></a> <span 
class="ecrm-1200">- </span><a 
href="https://cms.ual.es/UAL/universidad/departamentos/informatica/index.htm" ><span 
class="ecrm-1200">Depto Inform</span><span 
class="ecrm-1200">á</span><span 
class="ecrm-1200">tica</span></a> <span 
class="ecrm-1200">- </span><a 
href="https://www.ual.es" ><span 
class="ecrm-1200">UAL</span></a></div><br />
<div class="date" ><span 
class="ecrm-1200">June 4, 2022</span></div>
   </div>
   <h3 class="sectionHead"><span class="titlemark">1   </span> <a 
 id="x1-10001"></a>Description</h3>
<!--l. 10--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">1.1   </span> <a 
 id="x1-20001.1"></a>Spatial decorrelation in stereo audio signals</h4>
<!--l. 12--><p class="noindent" >NOTE: see if the transform is orthonormal. Otherwise, quantization should be used
considering the subband gains.
</p><!--l. 15--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">1.1.1   </span> <a 
 id="x1-30001.1.1"></a>An analysis transform</h5>
<!--l. 17--><p class="noindent" >InterCom transmits a <a 
href="https://en.wikipedia.org/wiki/Stereophonic_sound" >stereo</a> (two channels) <a 
href="https://en.wikipedia.org/wiki/Pulse-code_modulation" >PCM signal</a>. In most cases, the channels
are <a 
href="https://en.wikipedia.org/wiki/Binaural_recording" >highly correlated</a> (especially when the microphone is mono because both channels
are identical), which means that we can ﬁnd a more eﬃcient representation. To
perform this inter-channel <a 
href="https://en.wikipedia.org/wiki/Decorrelation" >decorrelation</a> <span class="cite">[<a 
href="#Xthinkstats">4</a>]</span> we can use the <a 
href="https://en.wikipedia.org/wiki/Linear_map" >linear transform</a> <span class="cite">[<a 
href="#Xstrang4linear">8</a>]</span>
\begin {equation}  {\mathbf w} = {\mathbf K}{\mathbf x} = \begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix} {\mathbf x}, \label {eq:forward_transform_matrix_form}  \end {equation}
that can be also written as \begin {equation}  \begin {bmatrix} {\mathbf w}_0 \\ {\mathbf w}_1 \end {bmatrix} = \begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix} \begin {bmatrix} {\mathbf x}_0 \\ {\mathbf x}_1 \end {bmatrix}, \label {eq:forward_transform_matrix_form2}  \end {equation}
where \({\mathbf x}\in \mathbb {Z}^2\) is a stereo frame, \(\mathbf K\) is the (forward or analysis) transform matrix, and \({\mathbf w}=\begin {bmatrix} {\mathbf w}_0 &amp; {\mathbf w}_1\end {bmatrix}^{\text T}\) is the
corresponding <a 
href="https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Example_in_image_processing" >decomposition</a>. In this particular transform, the decomposition has two
<a 
href="https://en.wikipedia.org/wiki/Sub-band_coding" >subbands</a> \({\mathbf w}_0\) and \({\mathbf w}_1\), and each subband has only one <a 
href="https://web.stanford.edu/class/ee398a/handouts/lectures/07-TransformCoding.pdf" >coeﬃcient</a>. Notice that \({\mathbf x}\in \mathbb {Z}^2\) is a vector
space<span class="footnote-mark"><a 
href="#fn1x0" id="fn1x0-bk"><sup class="textsuperscript">1</sup></a></span><a 
 id="x1-3001f1"></a>.
</p><!--l. 64--><p class="indent" >   The proposed matrix \(\mathbf K\) corresponds to the transform used in <a 
href="https://en.wikipedia.org/wiki/Joint_encoding#M/S_stereo_coding" >Mid/Side (M/S)
stereo coding</a> <span class="cite">[<a 
href="#Xbosi2003intro">2</a>]</span> that we will call MST (Mid/Side Transform). This is similar to the \(2\times 2\)
KLT <a 
href="http://fourier.eng.hmc.edu/e161/lectures/klt/node3.html" >(Karhunen-Loève Transform)</a>, the <a 
href="http://wavelets.pybytes.com/wavelet/haar/" >Haar Transform</a> <span class="cite">[<a 
href="#Xvetterli1995wavelets">10</a>]</span> and the \(2\times 2\) <a 
href="https://en.wikipedia.org/wiki/Hadamard_transform" >Discrete
Walsh-Hadamard Transform</a> <span class="cite">[<a 
href="#Xsayood2017introduction">7</a>]</span>.
                                                                  

                                                                  
</p><!--l. 75--><p class="indent" >   In general (for all the linear transforms), Eqs. <span 
class="ecbx-1000">??</span> and <span 
class="ecbx-1000">??</span> can be also expressed as
\begin {equation}  {\mathbf w}_u = \sum _i {\mathbf K}_{u,i}{\mathbf x}_i, \label {eq:forward_transform_linear_combination_form}  \end {equation}
where \({\mathbf K}_{u,i}\) denotes \(i\)-th element of the \(u\)-th row of the matrix \(\mathbf K\).
</p><!--l. 85--><p class="indent" >   A major diﬀerence between the transformed data \(\mathbf w\) and the original data \(\mathbf x\) is that
the characteristics of the elements of \(\mathbf w\) are determined by their position within the
decomposition \(\mathbf w\) <span class="cite">[<a 
href="#Xsayood2017introduction">7</a>]</span>. Thus, as a consequence of how the matrix has been deﬁned, the
subband \({\mathbf w}_0\) represents (very roughly) the low frequencies of \(\mathbf x\), and \({\mathbf w}_1\) the high frequencies.
Therefore, the values of \({\mathbf K}_0\) (the row 0 of \(\mathbf K\)) describe a <a 
href="https://en.wikipedia.org/wiki/Low-pass_filter" >low-pass ﬁlter</a>, the values of \({\mathbf K}_1\)
describe a <a 
href="https://en.wikipedia.org/wiki/High-pass_filter" >high-pass ﬁlter</a>, and \(\mathbf K\) represents the <a 
href="https://en.wikipedia.org/wiki/Digital_filter" >ﬁlters</a> of a <a 
href="https://en.wikipedia.org/wiki/Filter_bank" >ﬁlter bank</a> with two ﬁlters.
This can be also seen in this <a 
href="https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/11-stereo_coding/stereo_transforms_RD.ipynb" >notebook</a>.
</p><!--l. 103--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">1.1.2   </span> <a 
 id="x1-40001.1.2"></a>The synthesis transform</h5>
<!--l. 105--><p class="noindent" >The inverse (or synthesis) transform \begin {equation}  {\mathbf x} = {\mathbf K}^{-1}{\mathbf w} \label {eq:inverse_transform}  \end {equation}
can be found from Eq. <span 
class="ecbx-1000">??</span>, where we get that \begin {equation}  \begin {array}{rcl} {\mathbf w}_0 &amp; = &amp; {\mathbf x}_0 + {\mathbf x}_1\\ {\mathbf w}_1 &amp; = &amp; {\mathbf x}_0 - {\mathbf x}_1. \end {array}  \end {equation}
By solving \({\mathbf x}_0\) (adding) and \({\mathbf x}_1\) (substracting) in these equations, we obtain that
\begin {equation}  \begin {array}{rcl} {\mathbf x}_0 &amp; = &amp; \frac {1}{2}({\mathbf w}_0 + {\mathbf w}_1)\\ {\mathbf x}_1 &amp; = &amp; \frac {1}{2}({\mathbf w}_0 - {\mathbf w}_1), \end {array}  \end {equation}
that in matrix form becomes \begin {equation}  \begin {bmatrix} {\mathbf x}_0 \\ {\mathbf x}_1 \end {bmatrix} = \frac {1}{2} \begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix} \begin {bmatrix} {\mathbf w}_0 \\ {\mathbf w}_1 \end {bmatrix}.  \end {equation}
Therefore, \begin {equation}  {\mathbf x} = {\mathbf K}^{-1}{\mathbf w} = \frac {1}{2}{\mathbf K}^{\text T}{\mathbf w} = \frac {1}{2}{\mathbf K}{\mathbf w} = \frac {1}{2}\begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix}{\mathbf w}. \label {eq:inverse_transform_matrix_form}  \end {equation}
</p><!--l. 146--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">1.1.3   </span> <a 
 id="x1-50001.1.3"></a>Orthogonality of the transform</h5>
<!--l. 148--><p class="noindent" >As can be seen (previously ignoring the \(\frac {1}{2}\) scale factor) the inverse transform is the
transpose of the forward transform (\({\mathbf K}^{-1}={\mathbf K}^{\text T}\)). This is a characteristic of all <a 
href="https://en.wikipedia.org/wiki/Orthogonal_transformation" >orthogonal
transforms</a> <span class="cite">[<a 
href="#Xsayood2017introduction">7</a>]</span>. For the MST, speciﬁcally, it also holds that \({\mathbf K}^{\text T}={\mathbf K}\) because \(\mathbf K\) is
<a 
href="https://en.wikipedia.org/wiki/Symmetric_matrix" >symmetric</a>.
</p><!--l. 158--><p class="indent" >   Apart from checking that \({\mathbf K}^{-1}={\mathbf K}^{\text T}\), \(\mathbf K\) is orthogonal if the <a 
href="https://en.wikipedia.org/wiki/Inner_product_space" >inner
product</a><span class="footnote-mark"><a 
href="#fn2x0" id="fn2x0-bk"><sup class="textsuperscript">2</sup></a></span><a 
 id="x1-5001f2"></a> of the
ﬁlters<span class="footnote-mark"><a 
href="#fn3x0" id="fn3x0-bk"><sup class="textsuperscript">3</sup></a></span><a 
 id="x1-5002f3"></a> of \(\mathbf K\) is \(0\) between
the diﬀerent ﬁlters<span class="footnote-mark"><a 
href="#fn4x0" id="fn4x0-bk"><sup class="textsuperscript">4</sup></a></span><a 
 id="x1-5003f4"></a>.
In our case \({\mathbf K}_0=\begin {bmatrix}1 &amp; 1\end {bmatrix}\)  and \({\mathbf K}_1=\begin {bmatrix} 1 &amp; -1\end {bmatrix}\) , and as we can see \begin {equation}  \langle {\mathbf K}_0,{\mathbf K}_1 \rangle = \langle \begin {bmatrix} 1 &amp; 1 \end {bmatrix} , \begin {bmatrix} 1 &amp; -1 \end {bmatrix} \rangle = \begin {bmatrix} 1 &amp; 1 \end {bmatrix} \cdot \begin {bmatrix} 1 &amp; -1 \end {bmatrix} = 1\times 1 + 1\times -1 = 0,  \end {equation}
which means that the ﬁlters \({\mathbf K}_0\) and \({\mathbf K}_1\) are linearly
independent<span class="footnote-mark"><a 
href="#fn5x0" id="fn5x0-bk"><sup class="textsuperscript">5</sup></a></span><a 
 id="x1-5004f5"></a>.
</p><!--l. 214--><p class="indent" >   Notice also that \begin {equation}  {\mathbf w}_i = \langle {\mathbf x}, {\mathbf K}_i\rangle ,  \end {equation}
which basically means<span class="footnote-mark"><a 
href="#fn6x0" id="fn6x0-bk"><sup class="textsuperscript">6</sup></a></span><a 
 id="x1-5005f6"></a>
that \({\mathbf w}_i\) is proportional to the similarity between the input signal \(\mathbf x\) and the <a 
href="https://en.wikipedia.org/wiki/Finite_impulse_response" >taps</a> of the
ﬁlter \({\mathbf K}_i\). These <a 
href="https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf" >slides</a> can help you with this key idea.
</p><!--l. 229--><p class="indent" >   Orthogonality is important in compression applications because the
<a 
href="https://en.wikipedia.org/wiki/Correlation_and_dependence" >correlation</a> between subbands is 0, and therefore, the contributions
of the subbands to the reconstruction of the original signal are
                                                                  

                                                                  
independent<span class="footnote-mark"><a 
href="#fn7x0" id="fn7x0-bk"><sup class="textsuperscript">7</sup></a></span><a 
 id="x1-5006f7"></a>.
Another interesting property satisﬁed by a lot of famous transforms (such as the
<a 
href="https://en.wikipedia.org/wiki/Fourier_transform" >Fourier Transform</a>) is <a 
href="https://en.wikipedia.org/wiki/Orthonormality" >orthonormality</a>, which means that the transform is <a 
href="https://en.wikipedia.org/wiki/Energy_(signal_processing)" >energy</a>
preserving <span class="cite">[<a 
href="#Xsayood2017introduction">7</a>]</span> (or that the <a 
href="https://en.wikipedia.org/wiki/Parseval%27s_theorem" >Parseval’s theorem</a> is satisﬁed, in both, the analysis and
the synthesis transform).
</p><!--l. 247--><p class="indent" >   The MST analysis is not orthonormal, because \begin {equation}  \sum _i {{\mathbf w}_i}^2 = ({\mathbf x}_0 + {\mathbf x}_1)^2 + ({\mathbf x}_0 - {\mathbf x}_1)^2 = ({\mathbf x}_0^2 + 2{\mathbf x}_0{\mathbf x}_1+{\mathbf x}_1^2) + ({\mathbf x}_0^2-{\mathbf 2}x_0{\mathbf x}_1+{\mathbf x}_1^2) = 2({\mathbf x}_0^2+{\mathbf x}_1^2) = 2\sum _i {{\mathbf x}_i}^2. \label {eq:No_Parseval}  \end {equation}
For this reason, we must divide the synthesized samples by \(2\) (see Eq. <span 
class="ecbx-1000">??</span>). On the
contrary, we would get \(2{\mathbf x}\) as the reconstructed signal instead of \(\mathbf x\).
</p><!--l. 261--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">1.1.4   </span> <a 
 id="x1-60001.1.4"></a>Quantization of the subbands</h5>
<!--l. 263--><p class="noindent" >Ideally, the quantization step \(\Delta _i\) used for a subband \({\mathbf w}_i\) must operate in the RD curve \(f_i\)
with the same slope <span class="cite">[<a 
href="#Xvetterli2014foundations">11</a>, <a 
href="#Xsayood2017introduction">7</a>]</span> (this is the same to say that we must satisfy that \(f'_0(x)=f'_1(x)\), where
\(f'\) denotes the derivative of \(f\)). The main drawback of this approach is that the ﬁnding
of \(f_i\) is computationally intensive (we must analyze, quantize, compress, decompress,
dequantize, synthesize and compute the distortion of the data for a enoughly high
number of quantization steps), and usually we cannot do that in real-time
applications.<span class="footnote-mark"><a 
href="#fn8x0" id="fn8x0-bk"><sup class="textsuperscript">8</sup></a></span><a 
 id="x1-6001f8"></a>
</p><!--l. 276--><p class="indent" >   An approximation to this could be to suppose that the RD curves of the subbands
resulting from the analysis of our current piece of data (remember, two samples of a
stereo frame in our case) are similar to the curves of previous pieces, that has
already been compressed and transmitted, and therefore, we can compute
also the distortion. Using this information, we can estimate a RD curve
for the current piece, and ﬁnd the quantization steps. This procedure is
much faster than the described in the previou paragraph, but it may still be
time-consuming.
</p><!--l. 286--><p class="indent" >   For this reason, in the previous <a 
href="https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/11-stereo_coding/stereo_transforms_RD.ipynb" >notebook</a> we explore a diﬀerent solution
based on the idea of that the contribution (in terms of energy) of the
subbands to the reconstruction of the signal \(\mathbf x\) is proportional to the <a 
href="https://en.wikipedia.org/wiki/Filter_(signal_processing)" >gain</a>
of each analysis ﬁlter of \(\mathbf K\) (remember that we are working with orthogonal
transforms and therefore, the contribution of the subbands are independent), or
what is the same, proportional to the gain of each column of the syntesis
matrix<span class="footnote-mark"><a 
href="#fn9x0" id="fn9x0-bk"><sup class="textsuperscript">9</sup></a></span><a 
 id="x1-6002f9"></a>.
Thus, if the ﬁlters had diﬀerent gains, the quantization steps should consider this
fact.<span class="footnote-mark"><a 
href="#fn10x0" id="fn10x0-bk"><sup class="textsuperscript">10</sup></a></span><a 
 id="x1-6003f10"></a>
</p><!--l. 305--><p class="indent" >   By deﬁnition, the gain of the subband \({\mathbf w}_i\) is the <a 
href="https://en.wikipedia.org/wiki/Lp_space" >L\(_2\)
norm</a><span class="footnote-mark"><a 
href="#fn11x0" id="fn11x0-bk"><sup class="textsuperscript">11</sup></a></span><a 
 id="x1-6004f11"></a>
of the ﬁlter \({\mathbf K}_i\) (remember that for the MST, the rows of the analysis matrix are equal
to the columns of the synthesis matrix). Thus
</p><!--l. 331--><p class="indent" >   \begin {equation}  \begin {array}{l} \left \| {\mathbf K}_0 \right \|_2 := \sqrt {\langle \begin {bmatrix}1 &amp; 1\end {bmatrix}, \begin {bmatrix}1 &amp; 1\end {bmatrix} \rangle } = \sqrt {\begin {bmatrix}1 &amp; 1\end {bmatrix} \cdot \begin {bmatrix}1 &amp; 1\end {bmatrix}} = \sqrt {2},\\ \left \| {\mathbf K}_1 \right \|_2 := \sqrt {\langle \begin {bmatrix}1 &amp; -1\end {bmatrix}, \begin {bmatrix}1 &amp; -1\end {bmatrix} \rangle } = \sqrt {\begin {bmatrix}1 &amp; -1\end {bmatrix}\cdot \begin {bmatrix}1 &amp; -1\end {bmatrix}} = \sqrt {2}, \end {array}  \end {equation}
resulting that both subbands \({\mathbf w}_1\) and \({\mathbf w}_2\) have the same gain (\(\sqrt {2}\)). This result tell us that
both subbands could use the same quantization step (\(\Delta _0=\Delta _1\)). In the <a 
href="https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/11-stereo_coding/stereo_transforms_RD.ipynb" >notebook</a> there are
some evidences of this.
                                                                  

                                                                  
</p><!--l. 338--><p class="indent" >   Unfortunately, most of the transform are not implemented using matrix-vector
operations, but using <a 
href="https://en.wikipedia.org/wiki/Fast_Fourier_transform" >faster algorithms</a> based on a lattice of <a 
href="https://en.wikipedia.org/wiki/Butterfly_diagram" >computational buﬀerﬂies</a>
or ﬁlter <a 
href="https://en.wikipedia.org/wiki/Filter_(signal_processing)" >convolutions</a> (and therefore, we don’t know \(\mathbf K\)). In general, we can
determine \({\mathbf K}_i\) simply by computing the inverse transform of the decomposition
\(\begin {bmatrix} 0 &amp; \cdots &amp; 0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \end {bmatrix}^{\text T}\), where the \(1\) value is in the position \(i\) (only the subband \({\mathbf w}_i=1\), the rest are
“zeroed”)).<span class="footnote-mark"><a 
href="#fn12x0" id="fn12x0-bk"><sup class="textsuperscript">12</sup></a></span><a 
 id="x1-6005f12"></a>
In our example, we get that
</p><!--l. 388--><p class="indent" >   \begin {equation}  \begin {array}{l} {\mathbf K}_0 = \begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix} \begin {bmatrix} 1 \\ 0 \end {bmatrix} = \begin {bmatrix} 1 &amp; 1 \end {bmatrix}, \\ {\mathbf K}_1 = \begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix} \begin {bmatrix} 0 \\ 1 \end {bmatrix} = \begin {bmatrix} 1 &amp; -1 \end {bmatrix}, \end {array}  \end {equation}
that as you can see, correspond to the columns of the inverse transform matrix \({\mathbf K}^{-1}\).
Notice that this is true for all the orthogonal transforms whose analysis and synthesis
matrices are simmetrical.
</p><!--l. 397--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">1.2   </span> <a 
 id="x1-70001.2"></a>Temporal Coding (without chunks overlapping)</h4>
<!--l. 400--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">1.2.1   </span> <a 
 id="x1-80001.2.1"></a>About temporal redundancy in audio</h5>
<!--l. 403--><p class="noindent" >After exploiting the spatial (stereo) redundancy in the previous
milestone, the next natural step in the development of InterCom is
to remove the temporal redundancy that can be found inside of each
subband<span class="footnote-mark"><a 
href="#fn13x0" id="fn13x0-bk"><sup class="textsuperscript">13</sup></a></span><a 
 id="x1-8001f13"></a>.
As it can be seen in this <a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/tools/audio_viewer.ipynb" >notebook</a>, most audio signals show “patterns” of samples
that tends to repeat, especially locally. Another clear source of temporal
redundancy is that the neighbor audio samples usually show similar amplitude
values.
</p><!--l. 417--><p class="indent" >   There are several techniques that can be used for removing the temporal
redundancy of a sequence of audio. One of the most straightforward is <a 
href="https://en.wikipedia.org/wiki/Differential_pulse-code_modulation" >Diﬀerential
Pulse Code Modulation (DPCM) <span class="cite">[<a 
href="#Xsayood2017introduction">7</a>]</span></a>. However, there are more eﬃcient decorrelation
algorithms based on <a 
href="https://en.wikipedia.org/wiki/Transform_coding" >transform coding</a>, such as the used in the previous milestone and
in this one.
</p><!--l. 428--><p class="indent" >   Transform coding is based on the idea that we can decompose (we can generate a
decomposition from) the input signal into a set of subbands, and if the used ﬁlters
are the adecuate ones for removing the temporal redundancy, we can achieve a high
transform coding gain <span class="cite">[<a 
href="#Xsayood2017introduction">7</a>]</span>, accumulating most of the signal energy (and presumably
most of the information) in a small number of subbands. When this happens,
the quantization of the subbands will remove basically the least signiﬁcant
information (usually <a 
href="https://en.wikipedia.org/wiki/Noise_(electronics)" >electronic noise</a>), allowing better compression ratios
than those in which we apply the same quantization process to the original
samples.<span class="footnote-mark"><a 
href="#fn14x0" id="fn14x0-bk"><sup class="textsuperscript">14</sup></a></span><a 
 id="x1-8002f14"></a>
</p>
   <figure class="figure"> 

                                                                  

                                                                  
                                                                  

                                                                  
<!--l. 445--><p class="noindent" ><div style="text-align:center;"> <img width=400 src="graphics/PRFB.svg" /> </div>  <a 
 id="x1-8003r1"></a>
<a 
 id="x1-8004"></a>
</p>
<figcaption class="caption" ><span class="id">Figure 1: </span><span  
class="content">A 2-channels PRFB (Perfect Reconstruction Filter Bank).         </span></figcaption><!--tex4ht:label?: x1-8003r1 -->
                                                                  

                                                                  
   </figure>
   <h5 class="subsubsectionHead"><span class="titlemark">1.2.2   </span> <a 
 id="x1-90001.2.2"></a>Transform and subband coding</h5>
<!--l. 456--><p class="noindent" >The name that has been given to the previous process is <a 
href="https://en.wikipedia.org/wiki/Sub-band_coding" >subband coding</a>. In this
context, our analysis transform matrix \(\mathbf K\) (see the previous milestone) represents the
taps of a 2-channels analysis <a 
href="https://en.wikipedia.org/wiki/Filter_bank" >Filter Bank (FB)</a> <span class="cite">[<a 
href="#Xvetterli1995wavelets">10</a>]</span>, and the forward transform is in
fact “descomposing” \(\mathbf x\) into two subbands \({\mathbf w}_0\) and \({\mathbf w}_1\) (see the Figure <a 
href="#x1-8003r1">1<!--tex4ht:ref: fig:PRFB --></a>, and this <a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/PRFB.ipynb" >notebook</a>).
On the other hand, the synthesis transform matrix \({\mathbf K}^{-1}\) denotes the taps of the
corresponding synthesis FB that allows to recover \(\mathbf x\) (notice that in the ﬁgure, \({\mathbf x}={\mathbf l}^i\), \({\mathbf w}_0={\mathbf l}^{i+1}\), \({\mathbf w}_1={\mathbf h}^{i+1}\), \(\tilde \phi ={\mathbf K}_0\), \(\tilde \psi ={\mathbf K}_1\), \(\phi ={\mathbf K}^{-1}_0\),
and \(\psi ={\mathbf K}^{-1}_1\)).
</p><!--l. 475--><p class="indent" >   Let’s suppose now that the analysis ﬁlters (represented by the taps of) \({\mathbf K}_0\)
and \({\mathbf K}_1\) are applied to the input signal \(\mathbf x\) (now a sequence of \(N\) samples) using a
<a 
href="https://en.wikipedia.org/wiki/Kernel_(image_processing)" >convolution</a> (without splitting \(x\) into blocks). Let’s also suppose (as happens in the
MST) that \({\mathbf K}_0\) is a low-pass ﬁlter and \({\mathbf K}_1\) is a high-pass ﬁlter, and that the <a 
href="https://en.wikipedia.org/wiki/Filter_(signal_processing)#The_transfer_function" >transfer
function</a><span class="footnote-mark"><a 
href="#fn15x0" id="fn15x0-bk"><sup class="textsuperscript">15</sup></a></span><a 
 id="x1-9001f15"></a>
of both ﬁlters <a 
href="https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks" >are one the inverse of the other</a>. Under these assumptions,
the complete (analysis/synthesis) transform is called a (2-channels) <a 
href="https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks" >Perfect
Reconstruction Filter Bank (PRFB)</a>, and \(\mathbf x\) can be recovered (perfectly)
from a subsampled version (in this case <a 
href="https://en.wikipedia.org/wiki/Downsampling_(signal_processing)" >decimating</a> by 2) of \({\mathbf w}_0\) and \({\mathbf w}_1\) (see
the <a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/PRFB.ipynb" >notebook</a>). Notice that this subsampling is possible because the
<a 
href="https://en.wikipedia.org/wiki/Aliasing" >aliasing</a><span class="footnote-mark"><a 
href="#fn16x0" id="fn16x0-bk"><sup class="textsuperscript">16</sup></a></span><a 
 id="x1-9002f16"></a>
generated in the low-pass subband is compensated by the aliasing generated in
the high-pass subband. To achieve this, the <a 
href="https://en.wikipedia.org/wiki/Filter_(signal_processing)#The_transfer_function" >frequency response</a> of \({\mathbf K}_0\) must be
equal to the mirrored frequency response of \({\mathbf K}_1\), and obviously, both ﬁlters
must have the same <a 
href="https://en.wikipedia.org/wiki/Bandwidth_(signal_processing)" >bandwidth</a> <span class="cite">[<a 
href="#Xsayood2017introduction">7</a>]</span>. In this situation, in which \({\mathbf K}_1\) and \({\mathbf K}_2\) are
mirror ﬁlters, we say that they form a <a 
href="https://en.wikipedia.org/wiki/Quadrature_mirror_filter" >Quadrature Mirror Filters (QMF)
Bank</a>.
</p><!--l. 516--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">1.2.3   </span> <a 
 id="x1-100001.2.3"></a>Multichannel ﬁlter banks and psychoacoustic frequency resolution</h5>
<!--l. 520--><p class="noindent" >Using the suitable ﬁlters, it is possible to build \(M\)-channels
PRFBs.<span class="footnote-mark"><a 
href="#fn17x0" id="fn17x0-bk"><sup class="textsuperscript">17</sup></a></span><a 
 id="x1-10001f17"></a>
These ﬁlters can analyze (and synthesize) the signal \(\mathbf x\), decomposing it in
(<a 
href="https://en.wikipedia.org/wiki/Low-pass_filter#Ideal_and_real_filters" >almost for sure</a>) overlaping frequency subbands with diﬀerent bandwidth.
The question here is to know how many ﬁlters should be used and what
<a 
href="https://en.wikipedia.org/wiki/Band-pass_filter" >pass-band</a> width should they have. At this design point, we must also consider
that the accuracy of the <a 
href="https://en.wikipedia.org/wiki/Psychoacoustics" >humman perception of the sound</a> depends on the
frequency: (as it can be checked in this <a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/frequency_resolution.ipynb" >notebook</a>) we are more sensitive to
frequency variations when the frequency of the sound is low. This fact is
related with the way in which the <a 
href="https://en.wikipedia.org/wiki/Critical_band" >critical bands</a> are distributed in <a 
href="https://en.wikipedia.org/wiki/Bark_scale" >the bark
scale</a>.
                                                                  

                                                                  
</p><!--l. 545--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">1.2.4   </span> <a 
 id="x1-110001.2.4"></a>The Discrete Wavelet Transform</h5>
<!--l. 549--><p class="noindent" >As it can be seen, the bark scale divides the audible spectrum into 24 subband of (a
priori) “whimsical” bandwidths. However, it’s clear that a <a 
href="https://en.wikipedia.org/wiki/Octave_band" >dyadic partition of the
spectrum</a> ﬁts better than <a 
href="https://en.wikipedia.org/wiki/Wavelet_transform#Principle" >a lineal partition</a>. Considering this reason, from all
the families of transforms designed to date, the most suitable one, from a
frequency partitioning point of view, is the Discrete Wavelet Transform
(DWT).
</p><!--l. 559--><p class="indent" >   The DWT has also other interesting features:
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-11002x1">
     <!--l. 561--><p class="noindent" >It is <a 
href="https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Time_complexity" >fast</a> (\(O(N)\), where \(N\) is the number of “transformed” samples).
     </p></li>
<li 
  class="enumerate" id="x1-11004x2">
     <!--l. 564--><p class="noindent" >It can represent eﬃcienty <a 
href="https://en.wikipedia.org/wiki/Transient_(oscillation)" >transient</a> signals, which can happen frequently
     in audio.
     </p></li>
<li 
  class="enumerate" id="x1-11006x3">
     <!--l. 567--><p class="noindent" >Although we are not going to take advantage of the following characteristic
     (for now), one of the most interesting features of the DWT is that it can
     used to ﬁnd a <a 
href="https://en.wikipedia.org/wiki/Multiresolution_analysis" >multiresolution representation</a> of the signal.</p></li></ol>
   <figure class="figure"> 

                                                                  

                                                                  
                                                                  

                                                                  
<!--l. 576--><p class="noindent" ><div style="text-align:center;"> <img width=800 src="graphics/cascade.svg" /> </div>  <a 
 id="x1-11007r2"></a>
<a 
 id="x1-11008"></a>
</p>
<figcaption class="caption" ><span class="id">Figure 2: </span><span  
class="content">A dyadic 2-levels cascade of PRFBs.                           </span></figcaption><!--tex4ht:label?: x1-11007r1 -->
                                                                  

                                                                  
   </figure>
   <h5 class="subsubsectionHead"><span class="titlemark">1.2.5   </span> <a 
 id="x1-120001.2.5"></a>Implementation of the DWT</h5>
<!--l. 587--><p class="noindent" >The DWT can be implemented in diﬀerent ways:
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-12002x1">
     <!--l. 589--><p class="noindent" >Deﬁning  the  transform  matrix  \(\mathbf K\)  (see  these  <a 
href="https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf" >slides</a>)  and  computing
     vector-matrix   multiplications,   which   requires   a   calculation   time
     proportional   to   \(O(N^2)\).   However,   the   main   problem   of   this   type   of
     implementation is generated by the amount of memory that \(\mathbf K\) requires, that
     is proportional to \(N^2\).
     </p></li>
<li 
  class="enumerate" id="x1-12004x2">
     <!--l. 596--><p class="noindent" ><a 
href="https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Cascading_and_filter_banks" >Cascading PRFBs</a> (see the Figure <a 
href="#x1-11007r2">2<!--tex4ht:ref: fig:cascade --></a>). Considering that the <a 
href="https://en.wikipedia.org/wiki/Convolution" >convolution</a>
     is a \(O(N\log _2N)\) operation (if it is <a 
href="https://en.wikipedia.org/wiki/Convolution_theorem" >implemented in the frequency domain</a>), and that
     the number of levels in the cascade is generally small (5 for example), this
     implementation is faster than the based in vector-matrix arithmetic. And
     most importantly, we don’t need to store \(\mathbf K\), but only the taps of the ﬁlters
     that in a software implementation of a cascade can be as small as the
     number of diﬀerent ﬁlters.<span class="footnote-mark"><a 
href="#fn18x0" id="fn18x0-bk"><sup class="textsuperscript">18</sup></a></span><a 
 id="x1-12005f18"></a>
     </p></li>
<li 
  class="enumerate" id="x1-12007x3">
     <!--l. 608--><p class="noindent" >Using <a 
href="https://en.wikipedia.org/wiki/Lifting_scheme" >lifting</a> <span class="cite">[<a 
href="#Xsweldens1997building">9</a>]</span>, which provides an extra speed-up factor of 2 compared
     to the FB implementation. DWTs implemented with lifting do not need
     to downsample and upsample the subbands, an operation that is wasting
     the calculus of half of the coeﬃcients at each level of the cascade.</p></li></ol>
<!--l. 619--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">1.2.6   </span> <a 
 id="x1-130001.2.6"></a>Example of a DWT using the MST ﬁlters</h5>
<!--l. 623--><p class="noindent" >In order to clarify the previously introduced concepts, let’s build a DWT using the
MST ﬁlters and lifting.
</p><!--l. 626--><p class="indent" >
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-13002x1">
                                                                  

                                                                  
     <!--l. 627--><p class="noindent" >Lifting is based on the concept of dyadic <a 
href="https://en.wikipedia.org/wiki/Multiresolution_analysis" >multiresolution analysis</a>, and also with
     the so called <a 
href="https://en.wikipedia.org/wiki/Polyphase_matrix" >polyphase representation</a> of signals. In order to do that, we can
     rewrite the MST ﬁlter equations (our \({\mathbf K}_0\) and \(-{\mathbf K}_1\) ﬁlters in the previous milestone) as
     \begin {equation}  \begin {array}{rcl} {\mathbf l}^1_i &amp; = &amp; {\mathbf x}_{2i} + {\mathbf x}_{2i+1} \\ {\mathbf h}^1_i &amp; = &amp; {\mathbf x}_{2i+1} - {\mathbf x}_{2i}, \end {array} \label {eq:1dwt}  \end {equation}
     where the \(l\)-th subband \({\mathbf z}^l=\{{\mathbf z}_i^l~|~0\le i\le 2^{n-l}\}\), being \(2^n=N\) the number of samples in \(\mathbf x\), and where, by
     deﬁnition, \({\mathbf l}^0={\mathbf x}\), the original resolution level of the signal. The subbands \({\mathbf l}^1\) and \({\mathbf h}^1\)
     computed by Eq. <span 
class="ecbx-1000">??</span> are the same than the decimated subbands computed by a
     1-levels PRFB (based on that ﬁlters), and we say, therefore, that Eq. <span 
class="ecbx-1000">??</span>
     computes the 1-levels DWT.
     </p><!--l. 651--><p class="noindent" >Based on the 1-levels DWT, we deﬁne the 2-levels DWT as \begin {equation}  \begin {array}{rcl} {\mathbf l}^2_i &amp; = &amp; {\mathbf l}^1_{2i} + {\mathbf l}^1_{2i+1} \\ {\mathbf h}^2_i &amp; = &amp; {\mathbf l}^1_{2i+1} - {\mathbf l}^1_{2i}, \end {array} \label {eq:2dwt}  \end {equation}
     that, as we can see, uses as input the output of Eq. <span 
class="ecbx-1000">??</span>.
     </p><!--l. 661--><p class="noindent" >In general, for a \(l\)-levels DWT, we get \begin {equation}  \begin {array}{rcl} {\mathbf l}^l_i &amp; = &amp; {\mathbf l}^{l-1}_{2i} + {\mathbf l}^{l-1}_{2i+1} \\ {\mathbf h}^l_i &amp; = &amp; {\mathbf l}^{l-1}_{2i+1} - {\mathbf l}^{l-1}_{2i}. \end {array} \label {eq:ldwt}  \end {equation}
     </p><!--l. 670--><p class="noindent" >The \(l\)-levels DWT splits the signal spectrum in \(l+1\) subbands. If \(l=n\) (where \(N=2^n\)), we have
     the spectrum partition \begin {equation*}  | {\mathbf l}^l_0 | {\mathbf h}^l_0 | {\mathbf h}^{l-1}_0 {\mathbf h}^{l-1}_1 | {\mathbf h}^{l-2}_0 {\mathbf h}^{l-2}_1 {\mathbf h}^{l-2}_2 {\mathbf h}^{l-2}_3 | \cdots | {\mathbf h}^1_0 {\mathbf h}^1_1 \cdots {\mathbf h}^1_{2^{n-1}-1} |,  \end {equation*}
     where<span class="footnote-mark"><a 
href="#fn19x0" id="fn19x0-bk"><sup class="textsuperscript">19</sup></a></span><a 
 id="x1-13003f19"></a>
     it holds that \begin {equation}  1+\sum _{j=1}^l 2^{j-1}=2^n,  \end {equation}
     i.e., the number of DWT coeﬃcients is also \(N\).
     </p></li>
<li 
  class="enumerate" id="x1-13005x2">
     <!--l. 684--><p class="noindent" >DWT performs a number of lifting steps, each one with 2 (sub)steps:
         </p><ol  class="enumerate2" >
<li 
  class="enumerate" id="x1-13007x1">
         <!--l. 687--><p class="noindent" >A <span 
class="ecbx-1000">predict step</span>, that computes the \(\mathbf h\) subbands as a prediction error (that
         in general should be minimized) between the even samples (usually,
         the values used to predict) and the odd samples (usually, the
         values predicted). For the MST ﬁlters, we have that (see Eq. <span 
class="ecbx-1000">??</span>) \begin {equation}  {\mathbf h}^l_i = {\mathbf l}^{l-1}_{2i+1} - {\mathbf l}^{l-1}_{2i}.  \end {equation}
         </p></li>
<li 
  class="enumerate" id="x1-13009x2">
         <!--l. 696--><p class="noindent" >An <span 
class="ecbx-1000">update step</span>, which computes the \(\mathbf l\) subbands considering (only) the
         even samples and the prediction errors. For the MST, we have that (see
         also Eq. <span 
class="ecbx-1000">??</span>) \begin {equation}  {\mathbf l}^l_i = 2{\mathbf l}^{l-1}_{2i} + {\mathbf h}^l_i.  \end {equation}
         </p></li></ol>
     <!--l. 704--><p class="noindent" >Notice that these steps are invertible: \begin {equation}  \begin {array}{rcl} {\mathbf l}^{l-1}_{2i} &amp; = &amp; \frac {1}{2}({\mathbf l}^l_i - {\mathbf h}^l_i)\\ {\mathbf l}^{l-1}_{2i+1} &amp; = &amp; {\mathbf l}^{l-1}_{2i} + {\mathbf h}^l_i. \end {array}  \end {equation}
</p>
     </li></ol>
                                                                  

                                                                  
<!--l. 716--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">1.2.7   </span> <a 
 id="x1-140001.2.7"></a>Wavelets and ﬁlter banks</h5>
<!--l. 719--><p class="noindent" >In the context of the wavelet theory <span class="cite">[<a 
href="#Xburrus2013wavelets">3</a>]</span>, the response of the analysis low-pass ﬁlter (\({\mathbf K}_0\) in the MST) to
the <a 
href="https://en.wikipedia.org/?title=Unit_impulse&redirect=no" >unit impulse</a><span class="footnote-mark"><a 
href="#fn20x0" id="fn20x0-bk"><sup class="textsuperscript">20</sup></a></span><a 
 id="x1-14001f20"></a>
is known as the <span 
class="ecti-1000">scaling function </span>and is usually denoted by \(\tilde \phi \), the response of the
analysis high-pass ﬁlter (\({\mathbf K}_1\)) is known as the <span 
class="ecti-1000">wavelet function </span>and it is usually denoted
by \(\tilde \psi \), the response of the synthesis low-pass ﬁlter (\({\mathbf K}^{-1}_0\)) is denoted by \(\phi \) and the synthesis
high-pass ﬁlter (\({\mathbf K}^{-1}_1\)) is represented by \(\psi \).
</p><!--l. 733--><p class="indent" >   For the MST it holds that \(\tilde \phi \bot \tilde \psi \), \(\tilde \phi =\psi \) and \(\tilde \psi =\phi \), and this is also true for all orthogonal DWTs.
Another important characteristic of orthogonal DWTs is that the ﬁlters cannot be
<a 
href="https://en.wikipedia.org/wiki/Symmetry" >symmetric</a>.<span class="footnote-mark"><a 
href="#fn21x0" id="fn21x0-bk"><sup class="textsuperscript">21</sup></a></span><a 
 id="x1-14002f21"></a>
</p><!--l. 746--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">1.2.8   </span> <a 
 id="x1-150001.2.8"></a>Example of a DWT using high-order ﬁlters</h5>
<!--l. 749--><p class="noindent" >The previous MST-based DWT is similar to other transforms such as the <a 
href="https://en.wikipedia.org/wiki/Haar_wavelet" >Haar
transform</a>, in which we are using an 1-order predictor for removing the temporal
redundancy. Let’s extend the idea of lifting to a prediction of order two. For that, we
deﬁne the predict step as \begin {equation}  {\mathbf h}^l_i = {\mathbf l}^{l-1}_{2i+1} - \frac {1}{2}({\mathbf l}^{l-1}_{2i} + {\mathbf l}^{l-1}_{2i+2})  \end {equation}
and the update step as \begin {equation}  {\mathbf l}^l_i = {\mathbf l}^{l-1}_{2i} + \frac {1}{4}({\mathbf h}^l_{i-1} + {\mathbf h}^l_i),  \end {equation}
where the factor \(1/4\) is used to preserve the energy <span class="cite">[<a 
href="#Xsweldens1997building">9</a>]</span>. This transform is known as the
<a 
href="https://en.wikipedia.org/wiki/Biorthogonal_wavelet" >biorthogonal</a> (2,2) of Cohen-Daubechies-Feauveau, and also as the linear transform.
Biorthogonal<span class="footnote-mark"><a 
href="#fn22x0" id="fn22x0-bk"><sup class="textsuperscript">22</sup></a></span><a 
 id="x1-15001f22"></a>
ﬁlters can be <a 
href="http://wavelets.pybytes.com/" >easely recognized</a> because they are always symmetric. When the ﬁlters
of the PRFB are biorthogonal, they also satisfy that \(\psi \bot \tilde \phi \) and \(\phi \bot \tilde \psi \).
</p><!--l. 775--><p class="indent" >   The linear transform is also invertible by simply reversing the steps: \begin {equation}  \begin {array}{rcl} {\mathbf l}^{l-1}_{2i} &amp; = &amp; {\mathbf l}^l_i - \frac {1}{4}({\mathbf h}^l_{i-1} + {\mathbf h}^l_i)\\ {\mathbf l}^{l-1}_{2i+1} &amp; = &amp; {\mathbf h}^l_i + \frac {1}{2}({\mathbf l}^{l-1}_{2i} + {\mathbf l}^{l-1}_{2i+2}). \end {array}  \end {equation}
</p><!--l. 787--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">1.3   </span> <a 
 id="x1-160001.3"></a>Overlapping the DWT</h4>
<!--l. 790--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">1.4   </span> <a 
 id="x1-170001.4"></a><a 
href="https://en.wikipedia.org/wiki/Lapped_transform" >Overlapped block transforms</a> for minimizing the distortion</h4>
<!--l. 793--><p class="noindent" >Transform coding implies to split the signal into blocks of data (chunks), and to
compute the transform of each chunk. When the output coeﬃcients are quantized, it
is possible that signiﬁcative (and unpleasant) distortions may appear in the border
                                                                  

                                                                  
frames of the chunks (see Fig <a 
href="#x1-17001r3">3<!--tex4ht:ref: fig:3_chunks --></a>). This is a consequence of that in the prediction step
used by the DWT in the limits of the chunks generate diﬀerent predictions at the
beginning and the end of the chunks.
</p>
   <figure class="figure"> 

                                                                  

                                                                  
                                                                  

                                                                  
<div class="tabular"> <table id="TBL-2" class="tabular" 
 
><colgroup id="TBL-2-1g"><col 
id="TBL-2-1" /><col 
id="TBL-2-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-2-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-1"  
class="td11"> <div style="text-align:center;"> <img width=500 src="3_chunks.svg" /> </div>   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-2"  
class="td11"> <div style="text-align:center;"> <img width=500 src="without.svg" /> </div>   </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-1"  
class="td11"> <div style="text-align:center;"> <img width=500 src="extended.svg" /> </div>   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-2"  
class="td11"> <div style="text-align:center;"> <img width=500 src="reconstructed.svg" /> </div>   </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-2-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-1"  
class="td11">    </td></tr></table>
</div> <a 
 id="x1-17001r3"></a>
<a 
 id="x1-17002"></a>
<figcaption class="caption" ><span class="id">Figure 3:  </span><span  
class="content">On  the  top-left,  three  consecutive  chunks  of  a  real  mono  audio
sequence.  On  the  top-right,  the  reconstruction  of  the  chunks  without
overlapping.  On  the  bottom-left,  the  extended  central  chunk.  On  the
bottom-right, the reconstruction of the extended chunk. See this <a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/quantization_DWT.ipynb" >notebook</a>.
</span></figcaption><!--tex4ht:label?: x1-17001r1 -->
                                                                  

                                                                  
   </figure>
<!--l. 816--><p class="indent" >   One solution to avoid signal discontinuitites between chunks is to overlap the
chunks. Thus, the current (\(i\)-th) chunk uses also the last frames of the previous (\((i-1)\)-th)
chunk and the ﬁrst frames of the next (\((i+1)\)-th) chunk to compute the transform of the
current extended (\(i\)-th) chunk (see the Fig. <a 
href="#x1-19009r4">4<!--tex4ht:ref: fig:subbands --></a>). This has been described in the
following algorithm:
</p>
   <h4 class="likesubsectionHead"><a 
 id="x1-180001.4"></a>Encoder:</h4>
<!--l. 824--><p class="noindent" >
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-18002x1">
     <!--l. 825--><p class="noindent" >\({\mathbf C}_{-1}\leftarrow {\mathbf 0}\), a zero chunk.
     </p></li>
<li 
  class="enumerate" id="x1-18004x2">
     <!--l. 826--><p class="noindent" >Input \({\mathbf C}_0\).
     </p></li>
<li 
  class="enumerate" id="x1-18006x3">
     <!--l. 827--><p class="noindent" >For \(i\in \{0,1,\cdots \}\):
         </p><ol  class="enumerate2" >
<li 
  class="enumerate" id="x1-18008x1">
         <!--l. 829--><p class="noindent" >Input \({\mathbf C}_{i+1}\).
         </p></li>
<li 
  class="enumerate" id="x1-18010x2">
         <!--l. 830--><p class="noindent" >Build extended chunk \({\mathbf E}={\mathbf C}_{i-1}[-o:]|{\mathbf C}_i|{\mathbf C}_{i+1}[:o]\), where \(\cdot |\cdot \) denotes the concatenation of chunks, \(o\)
         is the overlapped area size in frames, \({\mathbf C}_{i-1}[-o:]\) the last \(o\) frames of chunk \({\mathbf C}_{i-1}\), and
         \({\mathbf C}_{i+1}[:o]\) are the ﬁrst \(o\) frames of the chunk \({\mathbf C}_{i+1}\).
         </p></li>
<li 
  class="enumerate" id="x1-18012x3">
         <!--l. 837--><p class="noindent" >Compute decomposition \({\mathbf D}_i \leftarrow \text {DWT}^l({\mathbf E})\), where \(l\) is the number of levels of the DWT
         (\(l=2\) in the Fig. <a 
href="#x1-19009r4">4<!--tex4ht:ref: fig:subbands --></a>).
         </p></li>
                                                                  

                                                                  
<li 
  class="enumerate" id="x1-18014x4">
         <!--l. 840--><p class="noindent" >Output decomposition \({\mathbf D}_i\).
         </p></li>
<li 
  class="enumerate" id="x1-18016x5">
         <!--l. 841--><p class="noindent" >\({\mathbf C}_{i-1}\leftarrow {\mathbf C}_i\) (notice that we can assign the pointers, not the contents).
         </p></li>
<li 
  class="enumerate" id="x1-18018x6">
         <!--l. 842--><p class="noindent" >\({\mathbf C}_i\leftarrow {\mathbf C}_{i+1}\).</p></li></ol>
     </li></ol>
<!--l. 846--><p class="noindent" >Notice that we are following the <a 
href="https://numpy.org/doc/stable/reference/" >NumPy</a> <span class="cite">[<a 
href="#Xnumpy">1</a>, <a 
href="#Xharris2020array">5</a>]</span> <a 
href="https://www.pythoninformer.com/python-libraries/numpy/index-and-slice/" >slicing</a> notation.
</p><!--l. 855--><p class="noindent" >
</p>
   <h4 class="likesubsectionHead"><a 
 id="x1-190001.4"></a>Decoder:</h4>
<!--l. 856--><p class="noindent" >
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-19002x1">
     <!--l. 857--><p class="noindent" >For \(i\in \{0,1,\cdots \}\):
         </p><ol  class="enumerate2" >
<li 
  class="enumerate" id="x1-19004x1">
         <!--l. 859--><p class="noindent" >Input decomposition \({\mathbf D}_i\).
         </p></li>
<li 
  class="enumerate" id="x1-19006x2">
         <!--l. 860--><p class="noindent" >Compute extended chunk \({\mathbf E}\leftarrow \text {DWT}^{-l}({\mathbf D}_i)\).
         </p></li>
<li 
  class="enumerate" id="x1-19008x3">
         <!--l. 861--><p class="noindent" >Output chunk \({\mathbf C}_i={\mathbf E}[o:-o]\).</p></li></ol>
     </li></ol>
   <figure class="figure"> 

                                                                  

                                                                  
                                                                  

                                                                  
<!--l. 876--><p class="noindent" ><div style="text-align:center;"> <img width=550 src="graphics/subbands.svg" /> </div>  <a 
 id="x1-19009r4"></a>
<a 
 id="x1-19010"></a>
</p>
<figcaption class="caption" ><span class="id">Figure 4: </span><span  
class="content">Structure in the DWT domain of an extended chunk for \(l=2\). \(o\) is the
number of overlapped frames between adajacent chunks. \({\mathbf C}_{i-1}[-o:]\) represents the last \(o\)
frames of chunk \({\mathbf C}_{i-1}\), and \({\mathbf C}_{i+1}[:o]\) the ﬁrst \(o\) frames of the chunk \({\mathbf C}_{i+1}\).                     </span></figcaption><!--tex4ht:label?: x1-19009r1 -->
                                                                  

                                                                  
   </figure>
<!--l. 885--><p class="indent" >   This idea has been implemented in this <a 
href="https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/overlapped_DWT_I.ipynb" >notebook</a>, and the result can be seen in
the Fig. <a 
href="#x1-17001r3">3<!--tex4ht:ref: fig:3_chunks --></a>.
</p>
   <h4 class="subsectionHead"><span class="titlemark">1.5   </span> <a 
 id="x1-200001.5"></a>Reducing the data overhead</h4>
<!--l. 896--><p class="noindent" >Unfortunately, the previous algorithm sends twice the DWT coeﬃcients of the
overlapped areas (in the Fig. <a 
href="#x1-19009r4">4<!--tex4ht:ref: fig:subbands --></a>, \(\{{\mathbf D}_i.{\mathbf l}^2[-o/4:], {\mathbf D}_i.{\mathbf l}^2[:o/4], {\mathbf D}_i.{\mathbf h}^2[-o/4:], {\mathbf D}_i.{\mathbf h}^2[:o/4], {\mathbf D}_i.{\mathbf h}^1[-o/2:], {\mathbf D}_i.{\mathbf h}^1[:o/2]\}\)). To avoid this waste of bandwidth, we can reuse the
received coeﬃcients of the overlapped areas. This procedure has been described in
the Fig. <a 
href="#x1-20001r5">5<!--tex4ht:ref: fig:overlapping --></a>, and, as it can be seen, the encoding algorithm is identical to the
previous one except in that only the central (stereo) coeﬃcients are sent.
The rest of coeﬃcients that are needed to compute the inverse transform
are extracted from the neighbor chunks (represented in the DWT domain).
Notice that now, the number of sent coeﬃcients is \(\text {len}({\mathbf C}_i)\), the number of samples in
\({\mathbf C}_i\).
</p>
   <figure class="figure"> 

                                                                  

                                                                  
                                                                  

                                                                  
<!--l. 913--><p class="noindent" ><div style="text-align:center;"> <img width=800 src="graphics/overlapping.svg" /> </div>  <a 
 id="x1-20001r5"></a>
<a 
 id="x1-20002"></a>
</p>
<figcaption class="caption" ><span class="id">Figure 5:  </span><span  
class="content">Block  overlapping  in  the  DWT  domain  for  \(l=2\).  Only  the  shadded
coeﬃcients  are  transmitted.  Notice  that,  to  be  reconstructed,  each  chunk
depends on some coeﬃcients of the adjacent blocks (only some dependencies
have been indicated).                                                </span></figcaption><!--tex4ht:label?: x1-20001r1 -->
                                                                  

                                                                  
   </figure>
<!--l. 933--><p class="indent" >   The codec now can be described by:
</p>
   <h4 class="likesubsectionHead"><a 
 id="x1-210001.5"></a>Encoder:</h4>
<!--l. 936--><p class="noindent" >
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-21002x1">
     <!--l. 937--><p class="noindent" >\({\mathbf C}_{-1}\leftarrow {\mathbf 0}\), a zero chunk.
     </p></li>
<li 
  class="enumerate" id="x1-21004x2">
     <!--l. 938--><p class="noindent" >Input \({\mathbf C}_0\).
     </p></li>
<li 
  class="enumerate" id="x1-21006x3">
     <!--l. 939--><p class="noindent" >For \(i\in \{0,1,\cdots \}\):
         </p><ol  class="enumerate2" >
<li 
  class="enumerate" id="x1-21008x1">
         <!--l. 941--><p class="noindent" >Input \({\mathbf C}_{i+1}\).
         </p></li>
<li 
  class="enumerate" id="x1-21010x2">
         <!--l. 942--><p class="noindent" >Build extended chunk \({\mathbf E} = {\mathbf C}_{i-1}[-o:]|{\mathbf C}_i|{\mathbf C}_{i+1}[:o]\).
         </p></li>
<li 
  class="enumerate" id="x1-21012x3">
         <!--l. 944--><p class="noindent" >Compute decomposition \({\mathbf D}_i \leftarrow \text {DWT}^l({\mathbf E})\).
         </p></li>
<li 
  class="enumerate" id="x1-21014x4">
         <!--l. 946--><p class="noindent" >Output decomposition subset \(\Big \{{\mathbf D}_i.{\mathbf l}^l[\frac {o}{2^l}:-\frac {o}{2^l}], {\mathbf D}_i.{\mathbf h}^l[\frac {o}{2^l}:-\frac {o}{2^l}], {\mathbf D}_i.{\mathbf h}^{l-1}[\frac {o}{2^{l-1}}:-\frac {o}{2^{l-1}}], \cdots , {\mathbf D}_i.{\mathbf h}^1[\frac {o}{2^1}:-\frac {o}{2^1}]\Big \}\).
         </p></li>
<li 
  class="enumerate" id="x1-21016x5">
         <!--l. 951--><p class="noindent" >\({\mathbf C}_{i-1}\leftarrow {\mathbf C}_i\).
                                                                  

                                                                  
         </p></li>
<li 
  class="enumerate" id="x1-21018x6">
         <!--l. 952--><p class="noindent" >\({\mathbf C}_i\leftarrow {\mathbf C}_{i+1}\).</p></li></ol>
     </li></ol>
<!--l. 965--><p class="noindent" >
</p>
   <h4 class="likesubsectionHead"><a 
 id="x1-220001.5"></a>Decoder (ignores overlapping):</h4>
<!--l. 966--><p class="noindent" >This decoder ignores the adjacent chunks in the DWT domain, but notice that it uses
the right coeﬃcients (those computed using overlapping chunks). This should provide
reconstructions of the chunks with a higher quality that in the previous
milestone.
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-22002x1">
     <!--l. 968--><p class="noindent" >For \(i\in \{0,1,\cdots \}\):
         </p><ol  class="enumerate2" >
<li 
  class="enumerate" id="x1-22004x1">
         <!--l. 970--><p class="noindent" >Input decomposition subset \({\mathbf D}_i\).
         </p></li>
<li 
  class="enumerate" id="x1-22006x2">
         <!--l. 971--><p class="noindent" >Compute chunk \({\mathbf C}_i\leftarrow \text {DWT}^{-l}({\mathbf D}_i)\).
         </p></li>
<li 
  class="enumerate" id="x1-22008x3">
         <!--l. 972--><p class="noindent" >Output \({\mathbf C}_i\).</p></li></ol>
     </li></ol>
<!--l. 976--><p class="noindent" >
</p>
   <h4 class="likesubsectionHead"><a 
 id="x1-230001.5"></a>Decoder (uses overlapping):</h4>
<!--l. 978--><p class="noindent" >
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-23002x1">
     <!--l. 979--><p class="noindent" >\({\mathbf D}_{-1}\leftarrow {\mathbf 0}\).
                                                                  

                                                                  
     </p></li>
<li 
  class="enumerate" id="x1-23004x2">
     <!--l. 980--><p class="noindent" >Input decomposition \({\mathbf D}_0\).
     </p></li>
<li 
  class="enumerate" id="x1-23006x3">
     <!--l. 981--><p class="noindent" >For \(i\in \{0,1,\cdots \}\):
         </p><ol  class="enumerate2" >
<li 
  class="enumerate" id="x1-23008x1">
         <!--l. 983--><p class="noindent" >Input decomposition \({\mathbf D}_{i+1}\).
         </p></li>
<li 
  class="enumerate" id="x1-23010x2">
         <!--l. 984--><p class="noindent" >Build extended decomposition \({\mathbf E}_i = {\mathbf D}_{i-1}.{\mathbf l}^l[-\frac {o}{2^l}:]|{\mathbf D}_i.{\mathbf l}^l|{\mathbf D}_{i+1}.{\mathbf l}^l[:\frac {o}{2^l}]|{\mathbf D}_{i-1}.{\mathbf h}^l[-\frac {o}{2^l}:]|{\mathbf D}_i.{\mathbf h}^l|{\mathbf D}_{i+1}.{\mathbf h}^l[:\frac {o}{2^l}]|\cdots |{\mathbf D}_{i-1}.{\mathbf h}^1[-\frac {o}{2^1}:]|{\mathbf D}_i.{\mathbf h}^1|{\mathbf D}_{i+1}.{\mathbf h}^1[:\frac {o}{2^1}]\).
         </p></li>
<li 
  class="enumerate" id="x1-23012x3">
         <!--l. 986--><p class="noindent" >Compute extended chunk \({\mathbf C}_i\leftarrow \text {DWT}^{-l}({\mathbf E}_i)\).
         </p></li>
<li 
  class="enumerate" id="x1-23014x4">
         <!--l. 987--><p class="noindent" >Output \({\mathbf C}_i[o:-o]\).
         </p></li>
<li 
  class="enumerate" id="x1-23016x5">
         <!--l. 988--><p class="noindent" >\({\mathbf D}_{i-1} \leftarrow {\mathbf D}_i\).
         </p></li>
<li 
  class="enumerate" id="x1-23018x6">
         <!--l. 989--><p class="noindent" >\({\mathbf D}_i \leftarrow {\mathbf D}_{i+1}\).</p></li></ol>
     </li></ol>
<!--l. 1005--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">2   </span> <a 
 id="x1-240002"></a>What you have to do?</h3>
                                                                  

                                                                  
<!--l. 1008--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">2.1   </span> <a 
 id="x1-250002.1"></a>Determine the RD curves for the MST</h4>
<!--l. 1010--><p class="noindent" >As we did in the previous milestone, generate the RD curves for a set of simulated
transmission contexts. Use the modules <span 
class="ectt-1000">stereo_MST_coding{|_16|_32}.py</span>. As you
can see, they diﬀers in how the transform has been implemented.
</p><!--l. 1016--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">2.2   </span> <a 
 id="x1-260002.2"></a>Determine the RD curves for the DWT</h4>
<!--l. 1019--><p class="noindent" >Rebuild the RD curves considering also the temporal decorrelation. Use
<span class="obeylines-h"><span class="verb"><span 
class="ectt-1000">temporal_no_overlapped_DWT_coding.py</span></span></span>. Notice that the number of levels \(l\) of
the DWT (computed using <a 
href="https://pywavelets.readthedocs.io/en/latest/" >PyWavelets</a> <span class="cite">[<a 
href="#Xlee2019pywavelets">6</a>]</span>) can have a high impact on the
amount of energy concentration achieved by the DWT, and therefore, on the
eﬃciency of coding system. Show such impact. Experiment also with the wavelet
name.
</p><!--l. 1029--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">2.3   </span> <a 
 id="x1-270002.3"></a>Determine the RD curves for the overlapped DWT</h4>
<!--l. 1032--><p class="noindent" >
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-27002x1">
     <!--l. 1033--><p class="noindent" >In a module named <span class="obeylines-h"><span class="verb"><span 
class="ectt-1000">temporal_overlapped_DWT_coding.py</span></span></span>, inherit from
     <span class="obeylines-h"><span class="verb"><span 
class="ectt-1000">temporal_no_overlapped_DWT_coding.py</span></span></span>
     the  class  <span class="obeylines-h"><span class="verb"><span 
class="ectt-1000">Temporal_No_Overlapped_DWT</span></span></span>,  and  create  a  class  named
     <span class="obeylines-h"><span class="verb"><span 
class="ectt-1000">Temporal_Overlapped_DWT</span></span></span> which must implement the codec described in
     the Section <a 
href="#x1-200001.5">1.5<!--tex4ht:ref: sec:reducing --></a>.
     </p></li>
<li 
  class="enumerate" id="x1-27004x2">
     <!--l. 1038--><p class="noindent" >Build the RD curves to see how this improvement impacts on the eﬃciency
     of intercom.
     </p></li>
<li 
  class="enumerate" id="x1-27006x3">
     <!--l. 1040--><p class="noindent" >Determine which decoder is better from the RD perspective.
                                                                  

                                                                  
     </p></li>
<li 
  class="enumerate" id="x1-27008x4">
     <!--l. 1041--><p class="noindent" >Which  is  the  latency  of  the  encoder  and  the  decoders,  measured  in
     chunk-times?</p></li></ol>
<!--l. 1047--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">2.4   </span> <a 
 id="x1-280002.4"></a>Implement a Chunk Truncation Encoding (CTE)</h4>
<!--l. 1052--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">2.5   </span> <a 
 id="x1-290002.5"></a>Visualize</h4>
<!--l. 1055--><p class="noindent" >Visualize the eﬀects (in the DWT domain) of quantization.
                                                                  

                                                                  
</p>
   <pre class="verbatim" id="verbatim-1">
qjackctl &#x0026; # Select sampling frequency 44100 Hz
python temporal_overlapped_DWT_coding.py -i 6 -o 6 --show_stats -q 8192
# Connect the output of temporal_overlapped_DWT_coding.py to the input of dwt5.py
python dwt5.py -d 9
</pre>
<!--l. 1061--><p class="nopar" >
</p><!--l. 1067--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">3   </span> <a 
 id="x1-300003"></a>Deliverables</h3>
<!--l. 1068--><p class="noindent" >A description of the experiments and the results proposed.
</p><!--l. 1070--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">4   </span> <a 
 id="x1-310004"></a>Resources</h3>
    <div class="thebibliography">
    <p class="bibitem" ><span class="biblabel">
  [1]<span class="bibsp">   </span></span><a 
 id="Xnumpy"></a>S. Berg et al. <a 
href="https://numpy.org/" >The NumPy project</a>.
    </p>
    <p class="bibitem" ><span class="biblabel">
  [2]<span class="bibsp">   </span></span><a 
 id="Xbosi2003intro"></a>M. Bosi and R.E. Goldberd. <a 
href="https://last.hit.bme.hu/download/vidtechlab/fcc/literature/audio/audio_coding_standards_book.pdf" ><span 
class="ecti-1000">Introduction to Digital Audio Coding and</span>
    <span 
class="ecti-1000">Standards</span></a>. Kluwer Academic Publishers, 2003.
    </p>
    <p class="bibitem" ><span class="biblabel">
  [3]<span class="bibsp">   </span></span><a 
 id="Xburrus2013wavelets"></a>C.S.  Burrus,  R. Gopinath,  and  H. Guo.     <a 
href="https://cnx.org/contents/EQurkhlI@6.9:ZcNjPhDo@15/Preface" ><span 
class="ecti-1000">Wavelets  and  Wavelet</span>
    <span 
class="ecti-1000">Transforms</span></a>. Rice University, 2013.
    </p>
    <p class="bibitem" ><span class="biblabel">
  [4]<span class="bibsp">   </span></span><a 
 id="Xthinkstats"></a>A.B. Downey. <a 
href="https://greenteapress.com/thinkstats/thinkstats.pdf" ><span 
class="ecti-1000">Think Stats Probability and Statistics for Programmers</span></a>.
    O’Reilly, 2011.
                                                                  

                                                                  
    </p>
    <p class="bibitem" ><span class="biblabel">
  [5]<span class="bibsp">   </span></span><a 
 id="Xharris2020array"></a>C. R.  Harris,  K. J.  Millman,  S. J.  van der  Walt,  R. Gommers,
    P. Virtanen, D. Cournapeau, E. Wieser, J. Taylor, S. Berg, N. J. Smith,
    et al. <a 
href="https://www.nature.com/articles/s41586-020-2649-2" >Array programming with NumPy</a>. <span 
class="ecti-1000">Nature</span>, 585(7825):357–362, 2020.
    </p>
    <p class="bibitem" ><span class="biblabel">
  [6]<span class="bibsp">   </span></span><a 
 id="Xlee2019pywavelets"></a>G. Lee, R. Gommers, F. Waselewski, K. Wohlfahrt, and A. O’Leary.
    PyWavelets:  A  Python  package  for  wavelet  analysis.   <span 
class="ecti-1000">Journal of Open</span>
    <span 
class="ecti-1000">Source Software</span>, 4(36):1237, 2019.
    </p>
    <p class="bibitem" ><span class="biblabel">
  [7]<span class="bibsp">   </span></span><a 
 id="Xsayood2017introduction"></a>K. Sayood.  <a 
href="http://rahilshaikh.weebly.com/uploads/1/1/6/3/11635894/data_compression.pdf" ><span 
class="ecti-1000">Introduction to Data Compression</span></a>.  Morgan Kaufmann,
    2017.
    </p>
    <p class="bibitem" ><span class="biblabel">
  [8]<span class="bibsp">   </span></span><a 
 id="Xstrang4linear"></a>G. Strang.    <a 
href="https://ia802906.us.archive.org/18/items/StrangG.LinearAlgebraAndItsApplications45881001/%5BStrang_G.%5D_Linear_algebra_and_its_applications%284%29%5B5881001%5D.pdf" ><span 
class="ecti-1000">Linear  Algebra  and  Its  Applications</span></a>.    Belmont,  CA:
    Thomson, Brooks/Cole, 2006.
    </p>
    <p class="bibitem" ><span class="biblabel">
  [9]<span class="bibsp">   </span></span><a 
 id="Xsweldens1997building"></a>W. Sweldens and P. Schröder. <a 
href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.5600&rep=rep1&type=pdf" >Building Your Own Wavelets at Home</a>.
    <span 
class="ecti-1000">Wavelets in Computer Graphics</span>, 1997.
    </p>
    <p class="bibitem" ><span class="biblabel">
 [10]<span class="bibsp">   </span></span><a 
 id="Xvetterli1995wavelets"></a>M. Vetterli  and  J. Kovačević.    <a 
href="http://waveletsandsubbandcoding.org/Repository/VetterliKovacevic95_Manuscript.pdf" ><span 
class="ecti-1000">Wavelets  and  Subband  Coding</span></a>.
    Prentice-hall, 1995.
    </p>
    <p class="bibitem" ><span class="biblabel">
 [11]<span class="bibsp">   </span></span><a 
 id="Xvetterli2014foundations"></a>M. Vetterli, J. Kovačević, and V.K. Goyal.  <a 
href="http://www.fourierandwavelets.org/FSP_v1.1_2014.pdf" ><span 
class="ecti-1000">Foundations of Signal</span>
    <span 
class="ecti-1000">Processing</span></a>. Cambridge University Press, 2014.
</p>
    </div>
<a 
 id="Q1-1-37"></a>
                                                                  

                                                                  
   <div class="footnotes"><!--l. 62--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn1x0-bk" id="fn1x0"><sup class="textsuperscript">1</sup></a></span><span 
class="ecrm-0800">Adding two vectors in the plane produces a third one also in the plane; multiplying a vector</span>
<span 
class="ecrm-0800">by a real scalar produces a second vector also in the plane. These two ingrained facts make the real</span>
<span 
class="ecrm-0800">plane be a vector space.</span><span 
class="ecrm-0800"> </span><span class="cite"><span 
class="ecrm-0800">[</span><a 
href="#Xvetterli2014foundations"><span 
class="ecrm-0800">11</span></a><span 
class="ecrm-0800">]</span></span></p>
<!--l. 171--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn2x0-bk" id="fn2x0"><sup class="textsuperscript">2</sup></a></span><span 
class="ecrm-0800">The inner product between two vectors is in some sense a measure of how “similar” they are</span>
<span class="cite"><span 
class="ecrm-0800">[</span><a 
href="#Xsayood2017introduction"><span 
class="ecrm-0800">7</span></a><span 
class="ecrm-0800">]</span></span><span 
class="ecrm-0800">. In fact, the dot product computes the norm (a measure of the distance between vectors).</span><span 
class="ecrm-0800"> </span><span class="cite"><span 
class="ecrm-0800">[</span><a 
href="#Xvetterli2014foundations"><span 
class="ecrm-0800">11</span></a><span 
class="ecrm-0800">]</span></span>
<span 
class="ecrm-0800">Notice also, that the inner product is </span><a 
href="https://math.stackexchange.com/questions/476738/difference-between-dot-product-and-inner-product" ><span 
class="ecrm-0800">also called</span></a> <span 
class="ecrm-0800">the </span><a 
href="https://en.wikipedia.org/wiki/Dot_product" ><span 
class="ecrm-0800">dot product</span></a> <span 
class="ecrm-0800">and the scalar product when we</span>
<span 
class="ecrm-0800">work with </span><a 
href="https://en.wikipedia.org/wiki/Real_number" ><span 
class="ecrm-0800">real</span></a> <span 
class="ecrm-0800">signals.</span><span 
class="ecrm-0800"> </span><span class="cite"><span 
class="ecrm-0800">[</span><a 
href="#Xvetterli2014foundations"><span 
class="ecrm-0800">11</span></a><span 
class="ecrm-0800">]</span></span></p>
<!--l. 178--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn3x0-bk" id="fn3x0"><sup class="textsuperscript">3</sup></a></span><span 
class="ecrm-0800">When we are working with discrete signals, we usually talk about vectors instead of</span>
<span 
class="ecrm-0800">functions. These vectors are sampled versions of the corresponding functions, or as happen in our</span>
<span 
class="ecrm-0800">case, the </span><a 
href="https://en.wikipedia.org/wiki/Finite_impulse_response" ><span 
class="ecrm-0800">taps</span></a> <span 
class="ecrm-0800">of the ﬁlters, each one representing a </span><a 
href="https://en.wikipedia.org/wiki/Basis_(linear_algebra)" ><span 
class="ecrm-0800">basis vectors</span></a><span 
class="ecrm-0800">.</span></p>
<!--l. 186--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn4x0-bk" id="fn4x0"><sup class="textsuperscript">4</sup></a></span><span 
class="ecrm-0800">If a set of vectors are linearly independent, then the set is called a basis for the subspace</span>
<span 
class="ecrm-0800">generated by linear combinations of this set. The basis set contains the smallest number of linearly</span>
<span 
class="ecrm-0800">independent vectors required to represent each element of the vector (sub)space. The number of</span>
<span 
class="ecrm-0800">basis vectors required to generate the space is called the dimension of the vector space</span><span 
class="ecrm-0800"> </span><span class="cite"><span 
class="ecrm-0800">[</span><a 
href="#Xsayood2017introduction"><span 
class="ecrm-0800">7</span></a><span 
class="ecrm-0800">]</span></span><span 
class="ecrm-0800">. In our</span>
<span 
class="ecrm-0800">case, for the MST, we have two basis vectors.</span></p>
<!--l. 212--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn5x0-bk" id="fn5x0"><sup class="textsuperscript">5</sup></a></span><span 
class="ecrm-0800">In terms of orthogonality, this means that we cannot derive one from the other using the</span>
<span 
class="ecrm-0800">operations that deﬁne a vector space, and therefore the basis vectors can be a part a basis</span>
<span 
class="ecrm-0800">(set)</span><span 
class="ecrm-0800"> </span><span class="cite"><span 
class="ecrm-0800">[</span><a 
href="#Xstrang4linear"><span 
class="ecrm-0800">8</span></a><span 
class="ecrm-0800">]</span></span><span 
class="ecrm-0800">.</span></p>
<!--l. 222--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn6x0-bk" id="fn6x0"><sup class="textsuperscript">6</sup></a></span><span 
class="ecrm-0800">Remember that for the MST a subband has only one coeﬃcient. For other transforms,</span> \({\mathbf w}_i\) <span 
class="ecrm-0800">can</span>
<span 
class="ecrm-0800">be made up of more than one coeﬃcient and therefore, we would be speaking of the coeﬃcients of</span>
<span 
class="ecrm-0800">the subband, instead of only one coeﬃcient.</span></p>
<!--l. 236--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn7x0-bk" id="fn7x0"><sup class="textsuperscript">7</sup></a></span><span 
class="ecrm-0800">The total </span><a 
href="https://en.wikipedia.org/wiki/Distortion" ><span 
class="ecrm-0800">distortion</span></a> <span 
class="ecrm-0800">is the sum of the distortion contribution of each subband</span><span 
class="ecrm-0800"> </span><span class="cite"><span 
class="ecrm-0800">[</span><a 
href="#Xsayood2017introduction"><span 
class="ecrm-0800">7</span></a><span 
class="ecrm-0800">]</span></span><span 
class="ecrm-0800">.</span></p>
<!--l. 274--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn8x0-bk" id="fn8x0"><sup class="textsuperscript">8</sup></a></span><span 
class="ecrm-0800">Notice, however, that this would solve the problem of controlling the bit-rate because using</span>
<span 
class="ecrm-0800">the RD curves we know how many bits will require each subband.</span></p>
<!--l. 297--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn9x0-bk" id="fn9x0"><sup class="textsuperscript">9</sup></a></span><span 
class="ecrm-0800">Notice that the quantization error is generated in the transform domain and perceived in the</span>
<span 
class="ecrm-0800">signal domain after appliying the inverse transform.</span></p>
<!--l. 303--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn10x0-bk" id="fn10x0"><sup class="textsuperscript">10</sup></a></span><span 
class="ecrm-0800">Notice that the important here is the relative gain of each subband. For example, if the gain</span>
<span 
class="ecrm-0800">of</span> \({\mathbf K}_0\) <span 
class="ecrm-0800">were</span> \(2\) <span 
class="ecrm-0800">and the gain of</span> \({\mathbf K}_1\) <span 
class="ecrm-0800">were</span> \(1\)<span 
class="ecrm-0800">, and the dynamic range of</span> \({\mathbf w}_0\) <span 
class="ecrm-0800">and</span> \({\mathbf w}_1\) <span 
class="ecrm-0800">is the same, we could use</span> \(\Delta _1=2\Delta _0\) <span 
class="ecrm-0800">and</span>
<span 
class="ecrm-0800">expect to minimize the distortion.</span></p>
<!--l. 321--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn11x0-bk" id="fn11x0"><sup class="textsuperscript">11</sup></a></span><span 
class="ecrm-0800">L</span>\(_2(f)\) <span 
class="ecrm-0800">(where</span> \(f\) <span 
class="ecrm-0800">is a function) is the set of all functions with ﬁnite energy and constitues a</span>
<span 
class="ecrm-0800">vector space</span><span 
class="ecrm-0800"> </span><span class="cite"><span 
class="ecrm-0800">[</span><a 
href="#Xsayood2017introduction"><span 
class="ecrm-0800">7</span></a><span 
class="ecrm-0800">]</span></span><span 
class="ecrm-0800">.</span> \(L_2({\mathbb R})\) <span 
class="ecrm-0800">of simply</span> \(L_2\) <span 
class="ecrm-0800">is the space of all functions</span> \(f(t)\) <span 
class="ecrm-0800">with a well deﬁned integral of</span>
<span 
class="ecrm-0800">the square of the modulus of the function. The</span> \(L\) <span 
class="ecrm-0800">signiﬁes a Lebesque integral, the “2”</span>
<span 
class="ecrm-0800">denotes the integral of the square of the modulus of the function, and</span> \(\mathbb R\) <span 
class="ecrm-0800">states that the</span>
<span 
class="ecrm-0800">independent variable of integration is a number over the whole real line. For a function</span>
\(g(t)\) <span 
class="ecrm-0800">to be a member of that space is denoted:</span> \(g\in L_2({\mathbb R})\) <span 
class="ecrm-0800">or simply</span> \(g\in L_2\)<span 
class="ecrm-0800"> </span><span class="cite"><span 
class="ecrm-0800">[</span><a 
href="#Xburrus2013wavelets"><span 
class="ecrm-0800">3</span></a><span 
class="ecrm-0800">]</span></span><span 
class="ecrm-0800">. The computation of the L</span>\(_2\)
<span 
class="ecrm-0800">form is equivalent to compute the </span><a 
href="https://en.wikipedia.org/wiki/Euclidean_distance" ><span 
class="ecrm-0800">Euclidean distance</span></a> <span 
class="ecrm-0800">in</span> \(N\)<span 
class="ecrm-0800">-dimensional (in our case,</span> \(N=2\)<span 
class="ecrm-0800">)</span>
<a 
href="https://en.wikipedia.org/wiki/Vector_space" ><span 
class="ecrm-0800">spaces</span></a><span 
class="ecrm-0800">.</span></p>
<!--l. 355--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn12x0-bk" id="fn12x0"><sup class="textsuperscript">12</sup></a></span><span 
class="ecrm-0800">Notice that this operation will “extract” the</span> \(i\)<span 
class="ecrm-0800">-th column from</span> \({\mathbf K}^{-1}\) <span 
class="ecrm-0800">that is equivalent</span>
<span 
class="ecrm-0800">to say that will “extract” the</span> \(i\)<span 
class="ecrm-0800">-th row of</span> \(\mathbf K\)<span 
class="ecrm-0800">,</span> \({\mathbf K}_i\) <span 
class="ecrm-0800">(remember that for orthogonal transforms,</span>
\({\mathbf K}^{-1}={\mathbf K}^{\text T}\)<span 
class="ecrm-0800">).</span></p>
<!--l. 410--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn13x0-bk" id="fn13x0"><sup class="textsuperscript">13</sup></a></span><span 
class="ecrm-0800">Notice that, beacuse the MST and the transform used in this milestone are both lineal, the</span>
<span 
class="ecrm-0800">order in which the transforms are applied is irrelevant. For this reason, we could also have used</span>
<span 
class="ecrm-0800">the temporal transform inside of each channel of samples, and then, remove the spatial</span>
<span 
class="ecrm-0800">redundancy.</span></p>
<!--l. 441--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn14x0-bk" id="fn14x0"><sup class="textsuperscript">14</sup></a></span><span 
class="ecrm-0800">Notice that is we dead-zone quantize a decomposition and most of the coeﬃcients</span>
<span 
class="ecrm-0800">are close to zero, the information removed from the signal will be those with a smaller</span>
<span 
class="ecrm-0800">energy.</span></p>
<!--l. 485--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn15x0-bk" id="fn15x0"><sup class="textsuperscript">15</sup></a></span><span 
class="ecrm-0800">The response of the ﬁlter to the </span><a 
href="https://en.wikipedia.org/?title=Unit_impulse&redirect=no" ><span 
class="ecrm-0800">unit impulse</span></a><span 
class="ecrm-0800">.</span></p>
<!--l. 502--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn16x0-bk" id="fn16x0"><sup class="textsuperscript">16</sup></a></span><span 
class="ecrm-0800">Because the ﬁlters are not ideal, the bandwidth of the ﬁltered signals</span> \({\mathbf w}_0\) <span 
class="ecrm-0800">and</span> \({\mathbf w}_1\) <span 
class="ecrm-0800">is bigger than</span>
<span 
class="ecrm-0800">half of the bandwidth of</span> \(\mathbf x\)<span 
class="ecrm-0800">. Therefore, subsampling at a ratio of one of each two coeﬃcients, we are</span>
<span 
class="ecrm-0800">generating aliasing. See the </span><a 
href="https://en.wikipedia.org/wiki/Nyquist-Shannon_sampling_theorem" ><span 
class="ecrm-0800">sampling theorem</span></a><span 
class="ecrm-0800">.</span></p>
<!--l. 524--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn17x0-bk" id="fn17x0"><sup class="textsuperscript">17</sup></a></span><span 
class="ecrm-0800">Notice that our matrix</span> \(K\) <span 
class="ecrm-0800">would have</span> \(M\) <span 
class="ecrm-0800">rows in this case, and also</span> \(M\) <span 
class="ecrm-0800">colums, to satisfy that</span> \({\mathbf K}^{-1}={\mathbf K}^{\text T}\) <span 
class="ecrm-0800">if we</span>
<span 
class="ecrm-0800">are implementing an orthogonal transform.</span></p>
<!--l. 607--><p class="noindent" ><span class="footnote-mark"><a 
href="#fn18x0-bk" id="fn18x0"><sup class="textsuperscript">18</sup></a></span><span 
class="ecrm-0800">Notice that in a typical cascade, the ﬁlters are always the same.</span></p>
<!--l. 677--><p class="noindent" ><span class="footnote-mark"><a 
href="#fn19x0-bk" id="fn19x0"><sup class="textsuperscript">19</sup></a></span><span 
class="ecrm-0800">The coeﬃcient</span> \({\mathbf l}^l_0\) <span 
class="ecrm-0800">is called the DC (Direct Current) coeﬃcient, and the rest of</span> \(\mathbf h\) <span 
class="ecrm-0800">coeﬃcients are</span>
<span 
class="ecrm-0800">called AC (Alternating Current) coeﬃcients.</span></p>
<!--l. 725--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn20x0-bk" id="fn20x0"><sup class="textsuperscript">20</sup></a></span><span 
class="ecrm-0800">The response of a ﬁlter to the unit impulse characterize the ﬁlter because the output of the</span>
<span 
class="ecrm-0800">ﬁlter is the set of taps of the ﬁlter.</span></p>
<!--l. 739--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn21x0-bk" id="fn21x0"><sup class="textsuperscript">21</sup></a></span><span 
class="ecrm-0800">The symmetry of the ﬁlters is important to produce the same type of artifacts in the</span>
<span 
class="ecrm-0800">boundaries of the signal.</span></p>
<!--l. 769--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn22x0-bk" id="fn22x0"><sup class="textsuperscript">22</sup></a></span><span 
class="ecrm-0800">All transforms express a change of basis. When the basis are not orthogonal, the</span>
<span 
class="ecrm-0800">synthesis transform is not the transpose of the analysis transform. When the synthesis</span>
<span 
class="ecrm-0800">ﬁlters are orthogonal to their corresponding </span><span 
class="ecti-0800">dual </span><span 
class="ecrm-0800">analysis ﬁlters, the transform is said</span>
<span 
class="ecrm-0800">biorthogonal.</span><span 
class="ecrm-0800"> </span><span class="cite"><span 
class="ecrm-0800">[</span><a 
href="#Xvetterli2014foundations"><span 
class="ecrm-0800">11</span></a><span 
class="ecrm-0800">]</span></span></p>                                                                                                  </div>
                                                                  

                                                                  
 
</body> 
</html>
                                                                  


