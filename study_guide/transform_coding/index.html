<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Transform Coding for Redundancy Removal</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'><a href='https://en.wikipedia.org/wiki/Transform_coding'>Transform Coding</a> for <a href='https://en.wikipedia.org/wiki/Data_redundancy'>Redundancy</a> Removal</h2>
 <div class='author'><a href='https://cms.ual.es/UAL/personas/persona.htm?id=515256515553484875'><span class='ecrm-1200'>Vicente González Ruiz</span></a> <span class='ecrm-1200'>- </span><a href='https://cms.ual.es/UAL/universidad/departamentos/informatica/index.htm'><span class='ecrm-1200'>Depto Informática</span></a> <span class='ecrm-1200'>- </span><a href='https://www.ual.es'><span class='ecrm-1200'>UAL</span></a></div><br />
<div class='date'><span class='ecrm-1200'>November 18, 2022</span></div>
   </div>
   <h3 class='likesectionHead'><a id='x1-1000'></a>Contents</h3>
   <div class='tableofcontents'>
    <span class='sectionToc'>1 <a href='#x1-20001' id='QQ2-1-2'>Description</a></span>
<br />     <span class='subsectionToc'>1.1 <a href='#x1-30001.1' id='QQ2-1-3'>Spatial (stereo) decorrelation with the MST (Mid/Side Transform)</a></span>
<br />     <span class='subsectionToc'>1.2 <a href='#x1-80001.2' id='QQ2-1-8'>Temporal decorrelation using the DWT (Discrete Wavelet Transform)</a></span>
<br />     <span class='subsectionToc'>1.3 <a href='#x1-180001.3' id='QQ2-1-20'>Overlapped block transforms for minimizing the distortion</a></span>
<br />     <span class='subsectionToc'>1.4 <a href='#x1-210001.4' id='QQ2-1-25'>Reducing the data overhead</a></span>
<br />    <span class='sectionToc'>2 <a href='#x1-250002' id='QQ2-1-30'>What you have to do?</a></span>
<br />     <span class='subsectionToc'>2.1 <a href='#x1-260002.1' id='QQ2-1-31'>Determine the RD curves for the MST</a></span>
<br />     <span class='subsectionToc'>2.2 <a href='#x1-270002.2' id='QQ2-1-32'>Determine the RD curves for the DWT</a></span>
<br />     <span class='subsectionToc'>2.3 <a href='#x1-280002.3' id='QQ2-1-33'>Determine the RD curves for the overlapped DWT</a></span>
<br />     <span class='subsectionToc'>2.4 <a href='#x1-290002.4' id='QQ2-1-34'>Answer these questions</a></span>
<br />     <span class='subsectionToc'>2.5 <a href='#x1-300002.5' id='QQ2-1-35'>Visualize</a></span>
<br />    <span class='sectionToc'>3 <a href='#x1-310003' id='QQ2-1-36'>Deliverables</a></span>
<br />    <span class='sectionToc'>4 <a href='#x1-320004' id='QQ2-1-37'>Resources</a></span>
<br />    <span class='sectionToc'><a href='#Q1-1-38'>References</a></span>
   </div>
<!-- l. 10 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>1   </span> <a id='x1-20001'></a>Description</h3>
                                                                  

                                                                  
<!-- l. 13 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.1   </span> <a id='x1-30001.1'></a>Spatial (stereo) decorrelation with the MST (Mid/Side Transform)</h4>
<!-- l. 16 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.1.1   </span> <a id='x1-40001.1.1'></a>Analysis transform</h5>
<!-- l. 18 --><p class='noindent'>InterCom transmits a <a href='https://en.wikipedia.org/wiki/Stereophonic_sound'>stereo</a> (two channels) <a href='https://en.wikipedia.org/wiki/Pulse-code_modulation'>PCM signal</a>. In most cases, the channels
are <a href='https://en.wikipedia.org/wiki/Binaural_recording'>highly correlated</a> (especially when the microphone is mono because both channels
are identical), which means that we can find a more efficient representation. To
perform this inter-channel <a href='https://en.wikipedia.org/wiki/Decorrelation'>decorrelation</a> <span class='cite'>[<a href='#Xthinkstats'>4</a>]</span> we can use the <a href='https://en.wikipedia.org/wiki/Linear_map'>linear transform</a> <span class='cite'>[<a href='#Xstrang4linear'>8</a>]</span>
\begin {equation}  {\mathbf w} = {\mathbf K}{\mathbf x} = \begin {bmatrix} \mathbf {K}_0 \\ \mathbf {K}_1 \end {bmatrix} = \begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix} {\mathbf x}, \label {eq:forward_transform_matrix_form}  \end {equation}
that can be also written as \begin {equation}  \begin {bmatrix} {\mathbf w}_0 \\ {\mathbf w}_1 \end {bmatrix} = \begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix} \begin {bmatrix} {\mathbf x}_0 \\ {\mathbf x}_1 \end {bmatrix}, \label {eq:forward_transform_matrix_form2}  \end {equation}
where \({\mathbf x}\in \mathbb {Z}^2\) is a stereo frame, \(\mathbf K\) is the forward (or analysis) transform matrix, and \({\mathbf w}=\begin {bmatrix} {\mathbf w}_0 &amp; {\mathbf w}_1\end {bmatrix}^{\text T}\) is the
corresponding <a href='https://en.wikipedia.org/wiki/Discrete_wavelet_transform'>decomposition</a>. In this particular transform, the decomposition has two
<a href='https://en.wikipedia.org/wiki/Sub-band_coding'>subbands</a> \({\mathbf w}_0\) and \({\mathbf w}_1\), and each subband has only one <a href='https://web.stanford.edu/class/ee398a/handouts/lectures/07-TransformCoding.pdf'>coefficient</a>. Notice that \({\mathbf x}\in \mathbb {Z}^2\) is a vector
space<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-4001f1'></a>
if we consider also the required operations.
</p><!-- l. 67 --><p class='indent'>   The proposed matrix \(\mathbf K\) corresponds to the transform used in <a href='https://en.wikipedia.org/wiki/Joint_encoding#M/S_stereo_coding'>Mid/Side (M/S)
stereo coding</a> <span class='cite'>[<a href='#Xbosi2003intro'>2</a>]</span> that we will call MST (Mid/Side Transform). This is similar to the \(2\times 2\)
KLT <a href='https://en.wikipedia.org/wiki/Kosambi%E2%80%93Karhunen%E2%80%93Lo%C3%A8ve_theorem'>(Karhunen-Loève Transform)</a>, the <a href='http://wavelets.pybytes.com/wavelet/haar/'>Haar Transform</a> <span class='cite'>[<a href='#Xvetterli1995wavelets'>10</a>]</span> and the \(2\times 2\) <a href='https://en.wikipedia.org/wiki/Hadamard_transform'>Discrete
Walsh-Hadamard Transform</a> <span class='cite'>[<a href='#Xsayood2017introduction'>7</a>]</span>.
</p><!-- l. 78 --><p class='indent'>   In general (for all the linear transforms), Eqs. \eqref{eq:forward_transform_matrix_form}
and \eqref{eq:forward_transform_matrix_form2} can be also expressed as
\begin {equation}  {\mathbf w}_u = \sum _i {\mathbf K}_{u,i}{\mathbf x}_i, \label {eq:forward_transform_linear_combination_form}  \end {equation}
where \({\mathbf K}_{u,i}\) denotes \(i\)-th element of the \(u\)-th row of the matrix \(\mathbf K\).
</p><!-- l. 88 --><p class='indent'>   A major difference between the transformed data \(\mathbf w\) and the original data \(\mathbf x\) is that
the characteristics of the elements of \(\mathbf w\) are determined by their position within the
decomposition \(\mathbf w\) <span class='cite'>[<a href='#Xsayood2017introduction'>7</a>]</span>. Thus, as a consequence of how the matrix has been defined, the
subband \({\mathbf w}_0\) represents (very roughly) the low frequencies of \(\mathbf x\), and \({\mathbf w}_1\) the high frequencies.
Therefore, the values of \({\mathbf K}_0\) (the row 0 of \(\mathbf K\)) describe a <a href='https://en.wikipedia.org/wiki/Low-pass_filter'>low-pass filter</a>, the values of \({\mathbf K}_1\)
describe a <a href='https://en.wikipedia.org/wiki/High-pass_filter'>high-pass filter</a>, and \(\mathbf K\) represents the <a href='https://en.wikipedia.org/wiki/Digital_filter'>filters</a> of a <a href='https://en.wikipedia.org/wiki/Filter_bank'>filter bank (FB)</a> with two
filters. This can be also seen in the notebook <a href='https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/transform_coding/stereo_transforms_RD.ipynb'>A RD-comparison of “Stereo”
Transforms</a>.
</p><!-- l. 106 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.1.2   </span> <a id='x1-50001.1.2'></a>Synthesis transform</h5>
<!-- l. 108 --><p class='noindent'>The inverse (or synthesis) transform \begin {equation}  {\mathbf x} = {\mathbf K}^{-1}{\mathbf w} \label {eq:inverse_transform}  \end {equation}
can be deduced from Eq. \eqref{eq:forward_transform_matrix_form}, where we get
that \begin {equation}  \begin {array}{rcl} {\mathbf w}_0 &amp; = &amp; {\mathbf x}_0 + {\mathbf x}_1\\ {\mathbf w}_1 &amp; = &amp; {\mathbf x}_0 - {\mathbf x}_1. \end {array}  \end {equation}
By solving \({\mathbf x}_0\) (adding) and \({\mathbf x}_1\) (substracting) in these equations, we obtain that
\begin {equation}  \begin {array}{rcl} {\mathbf x}_0 &amp; = &amp; \frac {1}{2}({\mathbf w}_0 + {\mathbf w}_1)\\ {\mathbf x}_1 &amp; = &amp; \frac {1}{2}({\mathbf w}_0 - {\mathbf w}_1), \end {array}  \end {equation}
                                                                  

                                                                  
that in matrix form becomes \begin {equation}  \begin {bmatrix} {\mathbf x}_0 \\ {\mathbf x}_1 \end {bmatrix} = \frac {1}{2} \begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix} \begin {bmatrix} {\mathbf w}_0 \\ {\mathbf w}_1 \end {bmatrix}.  \end {equation}
Therefore, \begin {equation}  {\mathbf x} = {\mathbf K}^{-1}{\mathbf w} = \frac {1}{2}{\mathbf K}^{\text T}{\mathbf w} = \frac {1}{2}{\mathbf K}{\mathbf w} = \frac {1}{2}\begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix}{\mathbf w}. \label {eq:inverse_transform_matrix_form}  \end {equation}
</p><!-- l. 149 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.1.3   </span> <a id='x1-60001.1.3'></a>Orthogonality of the transform</h5>
<!-- l. 151 --><p class='noindent'>As can be seen (if we ignore the \(\frac {1}{2}\) scale factor) the inverse transform is the
transpose of the forward transform (\({\mathbf K}^{-1}={\mathbf K}^{\text T}\)). This is a characteristic of all <a href='https://en.wikipedia.org/wiki/Orthogonal_transformation'>orthogonal
transforms</a> <span class='cite'>[<a href='#Xsayood2017introduction'>7</a>]</span>. For the MST, specifically, it also holds that \({\mathbf K}^{\text T}={\mathbf K}\) because \(\mathbf K\) is
<a href='https://en.wikipedia.org/wiki/Symmetric_matrix'>symmetric</a>.
</p><!-- l. 161 --><p class='indent'>   Apart from checking that \({\mathbf K}^{-1}={\mathbf K}^{\text T}\), \(\mathbf K\) is orthogonal if the <a href='https://en.wikipedia.org/wiki/Inner_product_space'>inner
product</a><span class='footnote-mark'><a href='#fn2x0' id='fn2x0-bk'><sup class='textsuperscript'>2</sup></a></span><a id='x1-6001f2'></a> of
the filters<span class='footnote-mark'><a href='#fn3x0' id='fn3x0-bk'><sup class='textsuperscript'>3</sup></a></span><a id='x1-6002f3'></a>
of \(\mathbf K\) is \(0\) between the different filters (rows of the
matrix)<span class='footnote-mark'><a href='#fn4x0' id='fn4x0-bk'><sup class='textsuperscript'>4</sup></a></span><a id='x1-6003f4'></a>.
In our case \({\mathbf K}_0=\begin {bmatrix}1 &amp; 1\end {bmatrix}\)  and \({\mathbf K}_1=\begin {bmatrix} 1 &amp; -1\end {bmatrix}\) , and as we can see \begin {equation}  \langle {\mathbf K}_0,{\mathbf K}_1 \rangle = \langle \begin {bmatrix} 1 &amp; 1 \end {bmatrix} , \begin {bmatrix} 1 &amp; -1 \end {bmatrix} \rangle = \begin {bmatrix} 1 &amp; 1 \end {bmatrix} \cdot \begin {bmatrix} 1 &amp; -1 \end {bmatrix} = 1\times 1 + 1\times -1 = 0,  \end {equation}
which means that the filters \({\mathbf K}_0\) and \({\mathbf K}_1\) are linearly
independent<span class='footnote-mark'><a href='#fn5x0' id='fn5x0-bk'><sup class='textsuperscript'>5</sup></a></span><a id='x1-6004f5'></a>.
</p><!-- l. 219 --><p class='indent'>   Notice also that \begin {equation}  {\mathbf w}_i = \langle {\mathbf x}, {\mathbf K}_i\rangle ,  \end {equation}
which basically means<span class='footnote-mark'><a href='#fn6x0' id='fn6x0-bk'><sup class='textsuperscript'>6</sup></a></span><a id='x1-6005f6'></a>
that \({\mathbf w}_i\) is proportional to the similarity between the input signal \(\mathbf x\) and the <a href='https://en.wikipedia.org/wiki/Finite_impulse_response'>taps</a> of the
filter \({\mathbf K}_i\). These <a href='https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf'>slides</a> can help you with this key idea.
</p><!-- l. 234 --><p class='indent'>   Orthogonality is important in compression applications because
the <a href='https://en.wikipedia.org/wiki/Correlation_and_dependence'>statistical correlation</a> between subbands is 0, and therefore, the
contributions of the subbands to the reconstruction of the original signal are
independent<span class='footnote-mark'><a href='#fn7x0' id='fn7x0-bk'><sup class='textsuperscript'>7</sup></a></span><a id='x1-6006f7'></a>.
Another interesting property satisfied by a lot of famous transforms (such as the
<a href='https://en.wikipedia.org/wiki/Fourier_transform'>Fourier Transform</a>) is <a href='https://en.wikipedia.org/wiki/Orthonormality'>orthonormality</a>, which means that the transform is <a href='https://en.wikipedia.org/wiki/Energy_(signal_processing)'>energy</a>
preserving <span class='cite'>[<a href='#Xsayood2017introduction'>7</a>]</span> (or that the <a href='https://en.wikipedia.org/wiki/Parseval%27s_theorem'>Parseval’s theorem</a> is satisfied, in both, the analysis and
the synthesis transform).
</p><!-- l. 253 --><p class='indent'>   The MST is not orthonormal, because \begin {equation}  \sum _i {{\mathbf w}_i}^2 = ({\mathbf x}_0 + {\mathbf x}_1)^2 + ({\mathbf x}_0 - {\mathbf x}_1)^2 = ({\mathbf x}_0^2 + 2{\mathbf x}_0{\mathbf x}_1+{\mathbf x}_1^2) + ({\mathbf x}_0^2-{\mathbf 2}x_0{\mathbf x}_1+{\mathbf x}_1^2) = 2({\mathbf x}_0^2+{\mathbf x}_1^2) = 2\sum _i {{\mathbf x}_i}^2. \label {eq:No_Parseval}  \end {equation}
For this reason, we must divide the synthesized samples by \(2\) (see
Eq. \eqref{eq:inverse_transform_matrix_form}). On the contrary, we would get \(2{\mathbf x}\) as
the reconstructed signal instead of \(\mathbf x\).
</p><!-- l. 267 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.1.4   </span> <a id='x1-70001.1.4'></a>Quantization of the subbands</h5>
<!-- l. 271 --><p class='noindent'>Ideally, the QSS (Quantization Step Size) \(\Delta _i\) used for a subband \({\mathbf w}_i\) must operate
in the RD curve \(f_i\) with the same slope than the rest of subbands <span class='cite'>[<a href='#Xvetterli2014foundations'>11</a>, <a href='#Xsayood2017introduction'>7</a>]</span>
(this is the same to say that we must satisfy that \(f'_0(x)=f'_1(x)\), where \(f'\) denotes the
derivative of \(f\)). The main drawback of this approach is that the finding of \(f_i\) is
                                                                  

                                                                  
computationally intensive (we must analyze, quantize, compress, decompress,
dequantize, synthesize and compute the distortion of the data for a enoughly
high number of quantization steps), and usually we cannot do that in
real-time.<span class='footnote-mark'><a href='#fn8x0' id='fn8x0-bk'><sup class='textsuperscript'>8</sup></a></span><a id='x1-7001f8'></a>
</p><!-- l. 298 --><p class='indent'>   For this reason, in the notebook <a href='https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/transform_coding/stereo_transforms_RD.ipynb'>A RD-comparison of “Stereo” Transforms</a> we explore
a different solution based on the idea that the contribution (in terms of energy) of the
subbands to the reconstruction of the signal \(\mathbf x\) should be proportional to the <a href='https://en.wikipedia.org/wiki/Filter_(signal_processing)'>gain</a> of each
synthesis<span class='footnote-mark'><a href='#fn9x0' id='fn9x0-bk'><sup class='textsuperscript'>9</sup></a></span><a id='x1-7002f9'></a>
filter of \({\mathbf K}^{-1}\) (remember that we are working with orthogonal transforms and therefore,
the contribution of the subbands are independent). Thus, if the filters had different
gains, the QSSs should consider this fact using a smaller QSS where the gain is
higher.<span class='footnote-mark'><a href='#fn10x0' id='fn10x0-bk'><sup class='textsuperscript'>10</sup></a></span><a id='x1-7003f10'></a>
</p><!-- l. 319 --><p class='indent'>   By definition, the contribution of the subband \({\mathbf w}_i\) to the reconstruction of the frame is proportional
to the <a href='https://en.wikipedia.org/wiki/Lp_space'>L\(^2\) norm</a><span class='footnote-mark'><a href='#fn11x0' id='fn11x0-bk'><sup class='textsuperscript'>11</sup></a></span><a id='x1-7004f11'></a>
(or “squared” norm) of the (analysis) filter \({\mathbf K}_i^{-1}\). Thus \begin {equation}  \begin {array}{l} \left \| {\mathbf K}_0^{-1} \right \|_2 := \sqrt {\langle \begin {bmatrix} \frac {1}{2} &amp; \frac {1}{2} \end {bmatrix}, \begin {bmatrix} \frac {1}{2} &amp; \frac {1}{2} \end {bmatrix} \rangle } = \sqrt {\begin {bmatrix}\frac {1}{2} &amp; \frac {1}{2} \end {bmatrix} \cdot \begin {bmatrix} \frac {1}{2} &amp; \frac {1}{2} \end {bmatrix}} = \frac {1}{\sqrt {2}},\\ \left \| {\mathbf K}_1^{-1} \right \|_2 := \sqrt {\langle \begin {bmatrix} \frac {1}{2} &amp; -\frac {1}{2} \end {bmatrix}, \begin {bmatrix} \frac {1}{2} &amp; -\frac {1}{2} \end {bmatrix} \rangle } = \sqrt {\begin {bmatrix} \frac {1}{2} &amp; -\frac {1}{2} \end {bmatrix}\cdot \begin {bmatrix} \frac {1}{2} &amp; -\frac {1}{2} \end {bmatrix}} = \frac {1}{\sqrt {2}}, \end {array}  \end {equation}
resulting that both subbands \({\mathbf w}_1\) and \({\mathbf w}_2\) have the same gain (\(1/\sqrt {2}\)). This result tell us
that both subbands could use the same quantization step size (\(\Delta _0=\Delta _1\)). In the
notebook <a href='https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/transform_coding/stereo_transforms_RD.ipynb'>A RD-comparison of "Stereo" Transforms</a> there are some evidences of
this.
</p><!-- l. 352 --><p class='indent'>   Unfortunately, most of the transform are not implemented using matrix-vector
operations, but using <a href='https://en.wikipedia.org/wiki/Fast_Fourier_transform'>faster algorithms</a> based on a lattice of <a href='https://en.wikipedia.org/wiki/Butterfly_diagram'>computational bufferflies</a>
or filter <a href='https://en.wikipedia.org/wiki/Filter_(signal_processing)'>convolutions</a> (and therefore, we don’t know \(\mathbf K\)). Fortunately, we can
determine \({\mathbf K}_i^{-1}\) (and therefore, \(\mathbf K\)) by simply computing the inverse transform of the
decomposition \(\begin {bmatrix} 0 &amp; \cdots &amp; 0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \end {bmatrix}^{\text T}\), where the \(1\) value is in the position \(i\) (only the subband \({\mathbf w}_i=1\), the rest are
“zeroed”)).<span class='footnote-mark'><a href='#fn12x0' id='fn12x0-bk'><sup class='textsuperscript'>12</sup></a></span><a id='x1-7005f12'></a>
In our example, we get that
</p><!-- l. 402 --><p class='indent'>   \begin {equation}  \begin {array}{l} {\mathbf K}_0^{-1} = \frac {1}{2} \begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix} \begin {bmatrix} 1 \\ 0 \end {bmatrix} = \frac {1}{2} \begin {bmatrix} 1 &amp; 1 \end {bmatrix}, \\ {\mathbf K}_1^{-1} = \frac {1}{2} \begin {bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end {bmatrix} \begin {bmatrix} 0 \\ 1 \end {bmatrix} = \frac {1}{2} \begin {bmatrix} 1 &amp; -1 \end {bmatrix}. \end {array}  \end {equation}
</p><!-- l. 410 --><p class='indent'>   As a final remark, we could also consider that any alternative other than \(\Delta _0=\Delta _1\) will
affect to the spatial perception of the audio. The notebook <a href='https://github.com/Tecnologias-multimedia/Tecnologias-multimedia.github.io/blob/master/study_guide/transform_coding/stereo_transforms_RD.ipynb'>A RD-comparison of
"Stereo" Transforms</a> gives more information about this.
</p><!-- l. 417 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.2   </span> <a id='x1-80001.2'></a>Temporal decorrelation using the DWT (Discrete Wavelet Transform)</h4>
<!-- l. 420 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.2.1   </span> <a id='x1-90001.2.1'></a>About temporal redundancy in audio</h5>
<!-- l. 423 --><p class='noindent'>After exploiting the spatial (stereo) redundancy, the next natural step in the development
of InterCom is to remove the temporal redundancy that can be found inside of each
subband<span class='footnote-mark'><a href='#fn13x0' id='fn13x0-bk'><sup class='textsuperscript'>13</sup></a></span><a id='x1-9001f13'></a>.
                                                                  

                                                                  
As it can be seen in the notebook <a href='https://github.com/Tecnologias-multimedia/intercom/blob/master/tools/audio_viewer.ipynb'>Audio Viewer</a>, most audio signals show “patterns”
of samples that tends to repeat, especially locally. Another clear source of temporal
redundancy is that the neighbor audio samples usually show similar amplitude
values.
</p><!-- l. 437 --><p class='indent'>   There are several techniques that can be used for removing the temporal
redundancy of a sequence of audio. One of the most straightforward is <a href='https://en.wikipedia.org/wiki/Differential_pulse-code_modulation'>Differential
Pulse Code Modulation (DPCM) <span class='cite'>[<a href='#Xsayood2017introduction'>7</a>]</span></a>. However, there are more efficient decorrelation
algorithms based on <a href='https://en.wikipedia.org/wiki/Transform_coding'>Transform Coding</a>, such as the described in the previous section
and in this one.
</p><!-- l. 449 --><p class='indent'>   As it has been explained before, Transform Coding is based on the idea that we
can decompose the input signal into a set of subbands, and if the used filters are the
adecuate ones for removing the (in this case, temporal) redundancy, we can achieve a
high Transform Coding Gain <span class='cite'>[<a href='#Xsayood2017introduction'>7</a>]</span>, accumulating the most part of the signal energy
(and presumably most of the information) in a small number of subbands. When this
happens, the quantization of the subbands will remove basically the least significant
information (usually <a href='https://en.wikipedia.org/wiki/Noise_(electronics)'>electronic noise</a>), allowing better compression ratios
than those in which we apply the same quantization process to the original
samples.<span class='footnote-mark'><a href='#fn14x0' id='fn14x0-bk'><sup class='textsuperscript'>14</sup></a></span><a id='x1-9002f14'></a>
</p><!-- l. 467 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.2.2   </span> <a id='x1-100001.2.2'></a>Subband Coding</h5>
<!-- l. 473 --><p class='noindent'><a href='https://en.wikipedia.org/wiki/Sub-band_coding'>Subband Coding</a><span class='footnote-mark'><a href='#fn15x0' id='fn15x0-bk'><sup class='textsuperscript'>15</sup></a></span><a id='x1-10001f15'></a>
is a particular case of Transform Coding where the rows of the transform matrix are the taps of
digital filters<span class='footnote-mark'><a href='#fn16x0' id='fn16x0-bk'><sup class='textsuperscript'>16</sup></a></span><a id='x1-10002f16'></a>
In this context, our analysis transform matrix \(\mathbf K\) (see the previous section) represents
the taps of a 2-channels analysis <a href='https://en.wikipedia.org/wiki/Filter_bank'>Filter Bank (FB)</a> <span class='cite'>[<a href='#Xvetterli1995wavelets'>10</a>]</span>, and the forward transform is
in fact “descomposing” \(\mathbf x\) into two subbands \({\mathbf w}_0\) and \({\mathbf w}_1\) (see the Figure <a href='#x1-10003r1'>1<!-- tex4ht:ref: fig:PRFB  --></a>, and the
notebook <a href='https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/PRFB.ipynb'>A Perfect Reconstruction Filter Bank (PRFB)</a>). On the other
hand, the synthesis transform matrix \({\mathbf K}^{-1}\) denotes the taps of the corresponding
synthesis FB that allows to recover \(\mathbf x\) (notice that in the figure, \({\mathbf x}={\mathbf l}^i\), \({\mathbf w}_0={\mathbf l}^{i+1}\), \({\mathbf w}_1={\mathbf h}^{i+1}\), \(\tilde \phi ={\mathbf K}_0\), \(\tilde \psi ={\mathbf K}_1\), \(\phi ={\mathbf K}^{-1}_0\), and
\(\psi ={\mathbf K}^{-1}_1\)).
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 497 --><p class='noindent'><div style='text-align:center;'> <img src='graphics/PRFB.svg' /> </div>  <a id='x1-10003r1'></a>
<a id='x1-10004'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 1: </span><span class='content'>A 2-channels PRFB (Perfect Reconstruction Filter Bank).         </span></figcaption><!-- tex4ht:label?: x1-10003r1  -->
                                                                  

                                                                  
   </figure>
<!-- l. 503 --><p class='indent'>   Let’s suppose now that the analysis filters (represented by the taps of) \({\mathbf K}_0\) and \({\mathbf K}_1\) are
applied to the input signal \(\mathbf x\) (now a sequence of \(N\) samples) using a <a href='https://en.wikipedia.org/wiki/Kernel_(image_processing)'>convolution</a>
(without splitting \(\mathbf {x}\) into blocks). Let’s also suppose (as happens in the MST)
that \({\mathbf K}_0\) is a low-pass filter and \({\mathbf K}_1\) is a high-pass filter, and that the <a href='https://en.wikipedia.org/wiki/Filter_(signal_processing)'>frequency
response</a><span class='footnote-mark'><a href='#fn17x0' id='fn17x0-bk'><sup class='textsuperscript'>17</sup></a></span><a id='x1-10005f17'></a>
of both filters <a href='https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks'>are one the inverse of the other</a>. Under these assumptions,
the complete (analysis/synthesis) transform is called a (2-channels) <a href='https://en.wikipedia.org/wiki/Filter_bank#Perfect_reconstruction_filter_banks'>Perfect
Reconstruction Filter Bank (PRFB)</a>, and \(\mathbf x\) can be recovered (perfectly) from
a subsampled version (in this case <a href='https://en.wikipedia.org/wiki/Downsampling_(signal_processing)'>decimating</a> by 2 because we have two
channels in the FB) of \({\mathbf w}_0\) and \({\mathbf w}_1\) (see the notebook <a href='https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/PRFB.ipynb'>A Perfect Reconstruction
Filter Bank (PRFB)</a>). Notice that this subsampling is possible because the
<a href='https://en.wikipedia.org/wiki/Aliasing'>aliasing</a><span class='footnote-mark'><a href='#fn18x0' id='fn18x0-bk'><sup class='textsuperscript'>18</sup></a></span><a id='x1-10006f18'></a>
generated in the low-pass subband is attenuated by the aliasing generated in
the high-pass subband. To achieve this, the <a href='https://en.wikipedia.org/wiki/Filter_(signal_processing)'>frequency response</a> of \({\mathbf K}_0\) must be
equal to the mirrored frequency response of \({\mathbf K}_1\), and obviously, both filters
must have the same <a href='https://en.wikipedia.org/wiki/Bandwidth_(signal_processing)'>bandwidth</a> <span class='cite'>[<a href='#Xsayood2017introduction'>7</a>]</span>. In this situation, in which \({\mathbf K}_1\) and \({\mathbf K}_2\) are
mirror filters, we say that they form a <a href='https://en.wikipedia.org/wiki/Quadrature_mirror_filter'>Quadrature Mirror Filters (QMF)
Bank</a>.
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.2.3   </span> <a id='x1-110001.2.3'></a>Multichannel filter banks and psychoacoustic frequency resolution</h5>
<!-- l. 551 --><p class='noindent'>Using the suitable filters, it is possible to build \(M\)-channels
PRFBs.<span class='footnote-mark'><a href='#fn19x0' id='fn19x0-bk'><sup class='textsuperscript'>19</sup></a></span><a id='x1-11001f19'></a>
These filters can analyze (and synthesize) the signal \(\mathbf x\), decomposing it in (<a href='https://en.wikipedia.org/wiki/Low-pass_filter#Ideal_and_real_filters'>almost for
sure</a>) overlaping frequency subbands with different bandwidth. The question here is
to know how many filters should be used and what <a href='https://en.wikipedia.org/wiki/Band-pass_filter'>pass-band</a> width should they
have. At this design point, we must also consider that the accuracy of the
<a href='https://en.wikipedia.org/wiki/Psychoacoustics'>humman perception of the sound</a> depends on the frequency: (as it can be
checked<span class='footnote-mark'><a href='#fn20x0' id='fn20x0-bk'><sup class='textsuperscript'>20</sup></a></span><a id='x1-11002f20'></a>
with the notebook <a href='https://github.com/Tecnologias-multimedia/InterCom/blob/master/docs/tonal_generator.ipynb'>Tonal Generator</a>) we are more sensitive
to frequency variations when the frequency of the sound is
low<span class='footnote-mark'><a href='#fn21x0' id='fn21x0-bk'><sup class='textsuperscript'>21</sup></a></span><a id='x1-11003f21'></a>.
This fact is related with the way in which the <a href='https://en.wikipedia.org/wiki/Critical_band'>critical bands</a> are distributed in <a href='https://en.wikipedia.org/wiki/Bark_scale'>the
Bark Scale</a>.
</p><!-- l. 579 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.2.4   </span> <a id='x1-120001.2.4'></a>The Discrete Wavelet Transform</h5>
<!-- l. 583 --><p class='noindent'>As it can be seen, the Bark Scale divides the audible spectrum into 24 subband of (a
priori) “whimsical” bandwidths. However, it’s clear that a <a href='https://en.wikipedia.org/wiki/Octave_band'>dyadic partition of the
spectrum</a> fits better than <a href='https://en.wikipedia.org/wiki/Wavelet_transform#Principle'>a lineal partition</a>. Considering this reason, from all
the families of transforms designed to date, the most suitable one, from a
                                                                  

                                                                  
frequency partitioning point of view, is the Discrete Wavelet Transform
(DWT).
</p><!-- l. 593 --><p class='indent'>   The DWT has also other interesting features:
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-12002x1'>It is <a href='https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Time_complexity'>fast</a> (\(O(N)\), where \(N\) is the number of “transformed” samples).
     </li>
<li class='enumerate' id='x1-12004x2'>It can represent efficienty <a href='https://en.wikipedia.org/wiki/Transient_(oscillation)'>transient</a> signals, which can happen frequently
     in audio.
     </li>
<li class='enumerate' id='x1-12006x3'>Although we are not going to take advantage of the following characteristic
     (for now), one of the most interesting features of the DWT is that it can
     used to find a <a href='https://en.wikipedia.org/wiki/Multiresolution_analysis'>multiresolution representation</a> of the signal.</li></ol>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 610 --><p class='noindent'><div style='text-align:center;'> <img src='graphics/cascade.svg' /> </div>  <a id='x1-12007r2'></a>
<a id='x1-12008'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 2: </span><span class='content'>A dyadic 2-levels cascade of PRFBs.                           </span></figcaption><!-- tex4ht:label?: x1-12007r1  -->
                                                                  

                                                                  
   </figure>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.2.5   </span> <a id='x1-130001.2.5'></a>Implementation of the DWT</h5>
<!-- l. 621 --><p class='noindent'>The DWT can be implemented in different ways:
</p><!-- l. 623 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-13002x1'>Defining  the  transform  matrix  \(\mathbf K\)  (see  these  <a href='https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf'>slides</a>)  and  computing
     matrix-vector   multiplications,   which   requires   a   calculation   time
     proportional   to   \(O(N^2)\).   However,   the   main   problem   of   this   type   of
     implementation is generated by the amount of memory that \(\mathbf K\) requires, that
     is proportional to \(N^2\).
     </li>
<li class='enumerate' id='x1-13004x2'><a href='https://en.wikipedia.org/wiki/Discrete_wavelet_transform#Cascading_and_filter_banks'>Cascading PRFBs</a> (see the Figure <a href='#x1-12007r2'>2<!-- tex4ht:ref: fig:cascade  --></a>). Considering that the <a href='https://en.wikipedia.org/wiki/Convolution'>convolution</a>
     is a \(O(N\log _2N)\) operation (if it is <a href='https://en.wikipedia.org/wiki/Convolution_theorem'>implemented in the frequency domain</a>), and that
     the number of levels in the cascade is generally small (5 for example), this
     implementation is faster than the based in vector-matrix arithmetic. And
     most importantly, we don’t need to store \(\mathbf K\), but only the taps of the different
     filters that are used.<span class='footnote-mark'><a href='#fn22x0' id='fn22x0-bk'><sup class='textsuperscript'>22</sup></a></span><a id='x1-13005f22'></a>
     </li>
<li class='enumerate' id='x1-13007x3'>Using <a href='https://en.wikipedia.org/wiki/Lifting_scheme'>lifting</a> <span class='cite'>[<a href='#Xsweldens1997building'>9</a>]</span>, which provides an extra speed-up factor of 2 compared
     to the FB implementation. DWTs implemented with lifting do not need
     to downsample and upsample the subbands, an operation that is wasting
     the calculus of half of the coefficients at each level of the cascade.
</li></ol>
<!-- l. 658 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.2.6   </span> <a id='x1-140001.2.6'></a>Example of a DWT using the MST filters</h5>
<!-- l. 662 --><p class='noindent'>In order to clarify the previously introduced concepts, let’s build a DWT using the
MST filters and lifting.
</p><!-- l. 665 --><p class='indent'>
                                                                  

                                                                  
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-14002x1'>
     <!-- l. 667 --><p class='noindent'>Lifting is based on the concept of dyadic <a href='https://en.wikipedia.org/wiki/Multiresolution_analysis'>multiresolution analysis</a>, and also with
     the so called <a href='https://en.wikipedia.org/wiki/Polyphase_matrix'>polyphase representation</a> of signals. In order to do that, we can
     rewrite the MST filter equations (our \({\mathbf K}_0\) and \(-{\mathbf K}_1\) filters in the previous section) as
     \begin {equation}  \begin {array}{rcl} {\mathbf l}^1_i &amp; = &amp; {\mathbf x}_{2i} + {\mathbf x}_{2i+1} \\ {\mathbf h}^1_i &amp; = &amp; {\mathbf x}_{2i+1} - {\mathbf x}_{2i}, \end {array} \label {eq:1dwt}  \end {equation}
     where the \(l\)-th subband \({\mathbf z}^l=\{{\mathbf z}_i^l~|~0\le i\le 2^{n-l}\}\), being \(2^n=N\) the number of samples in \(\mathbf x\), and where, by
     definition, \({\mathbf l}^0={\mathbf x}\), the original resolution level of the signal. The subbands \({\mathbf l}^1\) and \({\mathbf h}^1\)
     computed by Eq. \eqref{eq:1dwt} are the same than the decimated subbands
     computed by a 1-levels PRFB (based on that filters), and we say, therefore,
     that Eq. \eqref{eq:1dwt} computes the 1-levels DWT.
     </p><!-- l. 691 --><p class='noindent'>Based on the 1-levels DWT, we define the 2-levels DWT as \begin {equation}  \begin {array}{rcl} {\mathbf l}^2_i &amp; = &amp; {\mathbf l}^1_{2i} + {\mathbf l}^1_{2i+1} \\ {\mathbf h}^2_i &amp; = &amp; {\mathbf l}^1_{2i+1} - {\mathbf l}^1_{2i}, \end {array} \label {eq:2dwt}  \end {equation}
     that, as we can see, uses as input the output of Eq. \eqref{eq:1dwt}.
     </p><!-- l. 701 --><p class='noindent'>In general, for a \(l\)-levels DWT, we get \begin {equation}  \begin {array}{rcl} {\mathbf l}^l_i &amp; = &amp; {\mathbf l}^{l-1}_{2i} + {\mathbf l}^{l-1}_{2i+1} \\ {\mathbf h}^l_i &amp; = &amp; {\mathbf l}^{l-1}_{2i+1} - {\mathbf l}^{l-1}_{2i}. \end {array} \label {eq:ldwt}  \end {equation}
     </p><!-- l. 710 --><p class='noindent'>The \(l\)-levels DWT splits the signal spectrum in \(l+1\) subbands. If \(l=n\) (where \(N=2^n\)), we have
     the spectrum partition \begin {equation*}  | \mathbf {l}^s_0 | \mathbf {h}^s_0 | \mathbf {h}^{s-1}_0 \mathbf {h}^{s-1}_1 | \mathbf {h}^{s-2}_0 \mathbf {h}^{s-2}_1 \mathbf {h}^{s-2}_2 \mathbf {h}^{s-2}_3 | \cdots | \mathbf {h}^1_0 \mathbf {h}^1_1 \cdots \mathbf {h}^1_{2^{n-1}-1} |,  \end {equation*}
     where<span class='footnote-mark'><a href='#fn23x0' id='fn23x0-bk'><sup class='textsuperscript'>23</sup></a></span><a id='x1-14003f23'></a>
     it holds that \begin {equation}  1+\sum _{j=1}^l 2^{j-1}=2^n,  \end {equation}
     i.e., the number of DWT coefficients is also \(N\).
     </p></li>
<li class='enumerate' id='x1-14005x2'>
     <!-- l. 724 --><p class='noindent'>DWT performs a number of lifting steps, each one with 2 (sub)steps:
         </p><ol class='enumerate2'>
<li class='enumerate' id='x1-14007x1'>A <span class='ecbx-1000'>predict step</span>, that computes the \(\mathbf h\) subbands as a prediction error (that
         in general should be minimized) between the even samples (usually, the
         values used to predict) and the odd samples (usually, the values
         predicted). For the MST filters, we have that (see Eq. \eqref{eq:ldwt}) \begin {equation}  {\mathbf h}^l_i = {\mathbf l}^{l-1}_{2i+1} - {\mathbf l}^{l-1}_{2i}.  \end {equation}
         </li>
<li class='enumerate' id='x1-14009x2'>An <span class='ecbx-1000'>update step</span>, which computes the \(\mathbf l\) subband considering (only) the
         even samples and the prediction errors. For the MST, we have that (see
         also Eq. \eqref{eq:ldwt}) \begin {equation}  {\mathbf l}^l_i = 2{\mathbf l}^{l-1}_{2i} + {\mathbf h}^l_i.  \end {equation}
         </li></ol>
                                                                  

                                                                  
     <!-- l. 744 --><p class='noindent'>Notice that these steps are invertible: \begin {equation}  \begin {array}{rcl} {\mathbf l}^{l-1}_{2i} &amp; = &amp; \frac {1}{2}({\mathbf l}^l_i - {\mathbf h}^l_i)\\ {\mathbf l}^{l-1}_{2i+1} &amp; = &amp; {\mathbf l}^{l-1}_{2i} + {\mathbf h}^l_i. \end {array}  \end {equation}
</p>
     </li></ol>
<!-- l. 756 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.2.7   </span> <a id='x1-150001.2.7'></a>Wavelets and filter banks</h5>
<!-- l. 759 --><p class='noindent'>In the context of the wavelet theory <span class='cite'>[<a href='#Xburrus2013wavelets'>3</a>]</span>, the response of the analysis low-pass filter (\({\mathbf K}_0\) in the MST) to
the <a href='https://en.wikipedia.org/?title=Unit_impulse&amp;redirect=no'>unit impulse</a><span class='footnote-mark'><a href='#fn24x0' id='fn24x0-bk'><sup class='textsuperscript'>24</sup></a></span><a id='x1-15001f24'></a>
is known as the <span class='ecti-1000'>scaling function </span>and is usually denoted by \(\tilde \phi \), the response of the
analysis high-pass filter (\({\mathbf K}_1\)) is known as the <span class='ecti-1000'>wavelet function </span>and it is usually denoted
by \(\tilde \psi \), the response of the synthesis low-pass filter (\({\mathbf K}^{-1}_0\)) is denoted by \(\phi \) and the synthesis
high-pass filter (\({\mathbf K}^{-1}_1\)) is represented by \(\psi \), that are the dual scaling and wavelet
functions.
</p><!-- l. 773 --><p class='indent'>   For the MST it holds that \(\tilde \phi \bot \tilde \psi \), \(\tilde \phi =\psi \) and \(\tilde \psi =\phi \), and this is also true for all orthogonal DWTs.
Another important characteristic of orthogonal DWTs is that the filters cannot be
<a href='https://en.wikipedia.org/wiki/Symmetry'>symmetric</a>.<span class='footnote-mark'><a href='#fn25x0' id='fn25x0-bk'><sup class='textsuperscript'>25</sup></a></span><a id='x1-15002f25'></a>
</p><!-- l. 787 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.2.8   </span> <a id='x1-160001.2.8'></a>Example of a DWT using “high”-order filters</h5>
<!-- l. 790 --><p class='noindent'>The previous MST-based DWT is similar to other transforms such as the <a href='https://en.wikipedia.org/wiki/Haar_wavelet'>Haar
transform</a>, in which we are using an 1-order predictor for removing the temporal
redundancy. Let’s extend the idea of lifting to a prediction of order two. For that, we
define the predict step as \begin {equation}  {\mathbf h}^l_i = {\mathbf l}^{l-1}_{2i+1} - \frac {1}{2}({\mathbf l}^{l-1}_{2i} + {\mathbf l}^{l-1}_{2i+2})  \end {equation}
and the update step as \begin {equation}  {\mathbf l}^l_i = {\mathbf l}^{l-1}_{2i} + \frac {1}{4}({\mathbf h}^l_{i-1} + {\mathbf h}^l_i),  \end {equation}
where the factor \(1/4\) is used to preserve the energy <span class='cite'>[<a href='#Xsweldens1997building'>9</a>]</span>. This transform
is known as the <a href='https://en.wikipedia.org/wiki/Biorthogonal_wavelet'>biorthogonal</a> (2,2) of Cohen-Daubechies-Feauveau.
Biorthogonal<span class='footnote-mark'><a href='#fn26x0' id='fn26x0-bk'><sup class='textsuperscript'>26</sup></a></span><a id='x1-16001f26'></a>
filters can be <a href='http://wavelets.pybytes.com/'>easely recognized</a> because they are always symmetric. When the filters
of the PRFB are biorthogonal, they also satisfy that \(\psi \bot \tilde \phi \) and \(\phi \bot \tilde \psi \).
</p><!-- l. 816 --><p class='indent'>   This linear transform is also invertible by simply reversing the steps: \begin {equation}  \begin {array}{rcl} {\mathbf l}^{l-1}_{2i} &amp; = &amp; {\mathbf l}^l_i - \frac {1}{4}({\mathbf h}^l_{i-1} + {\mathbf h}^l_i)\\ {\mathbf l}^{l-1}_{2i+1} &amp; = &amp; {\mathbf h}^l_i + \frac {1}{2}({\mathbf l}^{l-1}_{2i} + {\mathbf l}^{l-1}_{2i+2}). \end {array}  \end {equation}
</p><!-- l. 826 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead'><span class='titlemark'>1.2.9   </span> <a id='x1-170001.2.9'></a>Quantization of the DWT subbands</h5>
<!-- l. 828 --><p class='noindent'>The QSSe to be used in the different subbands of a (orthogonal) decomposition should be
inversely<span class='footnote-mark'><a href='#fn27x0' id='fn27x0-bk'><sup class='textsuperscript'>27</sup></a></span><a id='x1-17001f27'></a>
                                                                  

                                                                  
proportional the gain of the synthesis filters. The gain of a filter correspond to the L\(^2\)
norm of its taps, and the final gain applied to a subband depends logically on the
number of times that we have applied the filter in the cascade. Notice that, if we
don’t know the taps, we can use the algorithm described in the Section <a href='#x1-70001.1.4'>1.1.4<!-- tex4ht:ref: sec:quantization_subbands_spatial  --></a> to find
the gain of the subbands.
</p><!-- l. 840 --><p class='indent'>   Finally, notice that if the transform in orthonormal, by definition, the gain of the
analysis and synthesis filters is always 1, and also this is the gain of the
subbands.
</p><!-- l. 848 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.3   </span> <a id='x1-180001.3'></a><a href='https://en.wikipedia.org/wiki/Lapped_transform'>Overlapped block transforms</a> for minimizing the distortion</h4>
<!-- l. 851 --><p class='noindent'>Transform Coding implies to split the signal into blocks of data (chunks), and to
compute the transform of each chunk. When the output coefficients are
quantized, it is possible that significative (and unpleasant) distortions may
appear in the border frames of the chunks (see Fig. <a href='#x1-18001r3'>3<!-- tex4ht:ref: fig:3_chunks  --></a>). This is a consequence
that in the prediction step used by the DWT in the limits of the chunks
generate different predictions at the beginning and the end of the adjacent
chunks.
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<div class='tabular'> <table class='tabular' id='TBL-2'><colgroup id='TBL-2-1g'><col id='TBL-2-1' /><col id='TBL-2-2' /></colgroup><tr id='TBL-2-1-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-1-1' style='white-space:nowrap; text-align:center;'> <div style='text-align:center;'> <img src='3_chunks.svg' /> </div>   </td><td class='td11' id='TBL-2-1-2' style='white-space:nowrap; text-align:center;'> <div style='text-align:center;'> <img src='without.svg' /> </div>   </td>
</tr><tr id='TBL-2-2-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-2-1' style='white-space:nowrap; text-align:center;'> <div style='text-align:center;'> <img src='extended.svg' /> </div>   </td><td class='td11' id='TBL-2-2-2' style='white-space:nowrap; text-align:center;'> <div style='text-align:center;'> <img src='reconstructed.svg' /> </div>   </td>
</tr></table>
</div> <a id='x1-18001r3'></a>
<a id='x1-18002'></a>
<figcaption class='caption'><span class='id'>Figure 3:  </span><span class='content'>On  the  top-left,  three  consecutive  chunks  of  a  real  mono  audio
sequence.  On  the  top-right,  the  reconstruction  of  the  chunks  without
overlapping.  On  the  bottom-left,  the  extended  central  chunk.  On  the
bottom-right,  the  reconstruction  of  the  extended  chunk.  See  the  notebook
<a href='https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/quantization_DWT.ipynb'>Quantization in the DWT domain</a>.
</span></figcaption><!-- tex4ht:label?: x1-18001r1  -->
                                                                  

                                                                  
   </figure>
<!-- l. 876 --><p class='indent'>   One solution to avoid signal discontinuitites between chunks is to overlap the
chunks. Thus, the current (\(i\)-th) chunk uses also the last frames of the previous (\((i-1)\)-th)
chunk and the first frames of the next (\((i+1)\)-th) chunk to compute the transform of the
current extended (\(i\)-th) chunk (see the Fig. <a href='#x1-20009r4'>4<!-- tex4ht:ref: fig:subbands  --></a>). This has been described in the
following algorithm:
</p>
   <h4 class='likesubsectionHead'><a id='x1-190001.3'></a>Encoder:</h4>
<!-- l. 884 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-19002x1'>\({\mathbf C}_{-1}\leftarrow {\mathbf 0}\), a zero chunk.
     </li>
<li class='enumerate' id='x1-19004x2'>Input \({\mathbf C}_0\).
     </li>
<li class='enumerate' id='x1-19006x3'>
     <!-- l. 887 --><p class='noindent'>For \(i\in \{0,1,\cdots \}\):
         </p><ol class='enumerate2'>
<li class='enumerate' id='x1-19008x1'>Input \({\mathbf C}_{i+1}\).
         </li>
<li class='enumerate' id='x1-19010x2'>Build  the  extended  chunk  \({\mathbf E}={\mathbf C}_{i-1}[-o:]|{\mathbf C}_i|{\mathbf C}_{i+1}[:o]\),  where  \(\cdot |\cdot \)  denotes  the  concatenation  of
         chunks, \(o\) is the overlapped area size in frames, \({\mathbf C}_{i-1}[-o:]\) the last \(o\) frames of
         chunk \({\mathbf C}_{i-1}\), and \({\mathbf C}_{i+1}[:o]\) are the first \(o\) frames of the chunk \({\mathbf C}_{i+1}\).
         </li>
<li class='enumerate' id='x1-19012x3'>Compute the decomposition \({\mathbf D}_i \leftarrow \text {DWT}^l({\mathbf E})\), where \(l\) is the number of levels of the
         DWT (\(l=2\) in the Fig. <a href='#x1-20009r4'>4<!-- tex4ht:ref: fig:subbands  --></a>).
         </li>
                                                                  

                                                                  
<li class='enumerate' id='x1-19014x4'>Output the decomposition \({\mathbf D}_i\).
         </li>
<li class='enumerate' id='x1-19016x5'>\({\mathbf C}_{i-1}\leftarrow {\mathbf C}_i\) (notice that we can assign the pointers, not the contents).
         </li>
<li class='enumerate' id='x1-19018x6'>\({\mathbf C}_i\leftarrow {\mathbf C}_{i+1}\).</li></ol>
     </li></ol>
<!-- l. 906 --><p class='noindent'>Notice that we are following the <a href='https://numpy.org/doc/stable/reference/'>NumPy</a> <span class='cite'>[<a href='#Xnumpy'>1</a>, <a href='#Xharris2020array'>5</a>]</span> <a href='https://www.pythoninformer.com/python-libraries/numpy/index-and-slice/'>slicing</a> notation.
</p><!-- l. 915 --><p class='noindent'>
</p>
   <h4 class='likesubsectionHead'><a id='x1-200001.3'></a>Decoder:</h4>
<!-- l. 916 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-20002x1'>
     <!-- l. 917 --><p class='noindent'>For \(i\in \{0,1,\cdots \}\):
         </p><ol class='enumerate2'>
<li class='enumerate' id='x1-20004x1'>Input decomposition \({\mathbf D}_i\).
         </li>
<li class='enumerate' id='x1-20006x2'>Compute extended chunk \({\mathbf E}\leftarrow \text {DWT}^{-l}({\mathbf D}_i)\).
         </li>
<li class='enumerate' id='x1-20008x3'>Output chunk \({\mathbf C}_i={\mathbf E}[o:-o]\).</li></ol>
     </li></ol>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 936 --><p class='noindent'><div style='text-align:center;'> <img src='graphics/subbands.svg' /> </div>  <a id='x1-20009r4'></a>
<a id='x1-20010'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 4: </span><span class='content'>Structure in the DWT domain of an extended chunk for \(l=2\). \(o\) is the
number of overlapped frames between adajacent chunks. \({\mathbf C}_{i-1}[-o:]\) represents the last \(o\)
frames of chunk \({\mathbf C}_{i-1}\), and \({\mathbf C}_{i+1}[:o]\) the first \(o\) frames of the chunk \({\mathbf C}_{i+1}\).                     </span></figcaption><!-- tex4ht:label?: x1-20009r1  -->
                                                                  

                                                                  
   </figure>
<!-- l. 945 --><p class='indent'>   This idea has been implemented in the notebook <a href='https://github.com/Tecnologias-multimedia/intercom/blob/master/docs/overlapped_DWT_I.ipynb'>Overlapped DWT</a>, and the
result can be seen in the Fig. <a href='#x1-18001r3'>3<!-- tex4ht:ref: fig:3_chunks  --></a>.
</p>
   <h4 class='subsectionHead'><span class='titlemark'>1.4   </span> <a id='x1-210001.4'></a>Reducing the data overhead</h4>
<!-- l. 956 --><p class='noindent'>Unfortunately, the previous algorithm sends twice the DWT coefficients of the
overlapped areas (in the Fig. <a href='#x1-20009r4'>4<!-- tex4ht:ref: fig:subbands  --></a>, \(\{{\mathbf D}_i.{\mathbf l}^2[-o/4:], {\mathbf D}_i.{\mathbf l}^2[:o/4], {\mathbf D}_i.{\mathbf h}^2[-o/4:], {\mathbf D}_i.{\mathbf h}^2[:o/4], {\mathbf D}_i.{\mathbf h}^1[-o/2:], {\mathbf D}_i.{\mathbf h}^1[:o/2]\}\)). To avoid this waste of bandwidth, we can reuse the
received coefficients of the overlapped areas. This procedure has been described in
the Fig. <a href='#x1-21001r5'>5<!-- tex4ht:ref: fig:overlapping  --></a>, and, as it can be seen, the encoding algorithm is identical to the
previous one except in that only the central (stereo) coefficients are sent.
The rest of coefficients that are needed to compute the inverse transform
are extracted from the neighbor chunks (represented in the DWT domain).
Notice that now, the number of sent coefficients is \(\text {len}({\mathbf C}_i)\), the number of samples in
\({\mathbf C}_i\).
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 973 --><p class='noindent'><div style='text-align:center;'> <img src='graphics/overlapping.svg' /> </div>  <a id='x1-21001r5'></a>
<a id='x1-21002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 5:  </span><span class='content'>Block  overlapping  in  the  DWT  domain  for  \(l=2\).  Only  the  shadded
coefficients  are  transmitted.  Notice  that,  to  be  reconstructed,  each  chunk
depends on some coefficients of the adjacent blocks (only some dependencies
have been indicated).                                                </span></figcaption><!-- tex4ht:label?: x1-21001r1  -->
                                                                  

                                                                  
   </figure>
<!-- l. 993 --><p class='indent'>   The codec now can be described by:
</p>
   <h4 class='likesubsectionHead'><a id='x1-220001.4'></a>Encoder:</h4>
<!-- l. 996 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-22002x1'>\({\mathbf C}_{-1}\leftarrow {\mathbf 0}\), a zero chunk.
     </li>
<li class='enumerate' id='x1-22004x2'>Input \({\mathbf C}_0\).
     </li>
<li class='enumerate' id='x1-22006x3'>
     <!-- l. 999 --><p class='noindent'>For \(i\in \{0,1,\cdots \}\):
         </p><ol class='enumerate2'>
<li class='enumerate' id='x1-22008x1'>Input \({\mathbf C}_{i+1}\).
         </li>
<li class='enumerate' id='x1-22010x2'>Build the extended chunk \({\mathbf E} = {\mathbf C}_{i-1}[-o:]|{\mathbf C}_i|{\mathbf C}_{i+1}[:o]\).
         </li>
<li class='enumerate' id='x1-22012x3'>Compute the decomposition \({\mathbf D}_i \leftarrow \text {DWT}^l({\mathbf E})\).
         </li>
<li class='enumerate' id='x1-22014x4'>Output the decomposition subset \(\Big \{{\mathbf D}_i.{\mathbf l}^l[\frac {o}{2^l}:-\frac {o}{2^l}], {\mathbf D}_i.{\mathbf h}^l[\frac {o}{2^l}:-\frac {o}{2^l}], {\mathbf D}_i.{\mathbf h}^{l-1}[\frac {o}{2^{l-1}}:-\frac {o}{2^{l-1}}], \cdots , {\mathbf D}_i.{\mathbf h}^1[\frac {o}{2^1}:-\frac {o}{2^1}]\Big \}\).
         </li>
<li class='enumerate' id='x1-22016x5'>\({\mathbf C}_{i-1}\leftarrow {\mathbf C}_i\).
                                                                  

                                                                  
         </li>
<li class='enumerate' id='x1-22018x6'>\({\mathbf C}_i\leftarrow {\mathbf C}_{i+1}\).</li></ol>
     </li></ol>
<!-- l. 1025 --><p class='noindent'>
</p>
   <h4 class='likesubsectionHead'><a id='x1-230001.4'></a>Decoder (ignores overlapping):</h4>
<!-- l. 1026 --><p class='noindent'>This decoder ignores the adjacent chunks in the DWT domain, but notice that it uses
the right coefficients (those computed using overlapping chunks). This should provide
reconstructions of the chunks with a higher quality that in the previous
milestone.
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-23002x1'>
     <!-- l. 1028 --><p class='noindent'>For \(i\in \{0,1,\cdots \}\):
         </p><ol class='enumerate2'>
<li class='enumerate' id='x1-23004x1'>Input the decomposition subset \({\mathbf D}_i\).
         </li>
<li class='enumerate' id='x1-23006x2'>Compute the chunk \({\mathbf C}_i\leftarrow \text {DWT}^{-l}({\mathbf D}_i)\).
         </li>
<li class='enumerate' id='x1-23008x3'>Output \({\mathbf C}_i\).</li></ol>
     </li></ol>
<!-- l. 1036 --><p class='noindent'>
</p>
   <h4 class='likesubsectionHead'><a id='x1-240001.4'></a>Decoder (uses overlapping):</h4>
<!-- l. 1038 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-24002x1'>\({\mathbf D}_{-1}\leftarrow {\mathbf 0}\).
                                                                  

                                                                  
     </li>
<li class='enumerate' id='x1-24004x2'>Input decomposition \({\mathbf D}_0\).
     </li>
<li class='enumerate' id='x1-24006x3'>
     <!-- l. 1041 --><p class='noindent'>For \(i\in \{0,1,\cdots \}\):
         </p><ol class='enumerate2'>
<li class='enumerate' id='x1-24008x1'>Input decomposition \({\mathbf D}_{i+1}\).
         </li>
<li class='enumerate' id='x1-24010x2'>Build the extended decomposition \({\mathbf E}_i = {\mathbf D}_{i-1}.{\mathbf l}^l[-\frac {o}{2^l}:]|{\mathbf D}_i.{\mathbf l}^l|{\mathbf D}_{i+1}.{\mathbf l}^l[:\frac {o}{2^l}]|{\mathbf D}_{i-1}.{\mathbf h}^l[-\frac {o}{2^l}:]|{\mathbf D}_i.{\mathbf h}^l|{\mathbf D}_{i+1}.{\mathbf h}^l[:\frac {o}{2^l}]|\cdots |{\mathbf D}_{i-1}.{\mathbf h}^1[-\frac {o}{2^1}:]|{\mathbf D}_i.{\mathbf h}^1|{\mathbf D}_{i+1}.{\mathbf h}^1[:\frac {o}{2^1}]\).
         </li>
<li class='enumerate' id='x1-24012x3'>Compute the extended chunk \({\mathbf C}_i\leftarrow \text {DWT}^{-l}({\mathbf E}_i)\).
         </li>
<li class='enumerate' id='x1-24014x4'>Output \({\mathbf C}_i[o:-o]\).
         </li>
<li class='enumerate' id='x1-24016x5'>\({\mathbf D}_{i-1} \leftarrow {\mathbf D}_i\).
         </li>
<li class='enumerate' id='x1-24018x6'>\({\mathbf D}_i \leftarrow {\mathbf D}_{i+1}\).</li></ol>
     </li></ol>
<!-- l. 1065 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>2   </span> <a id='x1-250002'></a>What you have to do?</h3>
                                                                  

                                                                  
<!-- l. 1068 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>2.1   </span> <a id='x1-260002.1'></a>Determine the RD curves for the MST</h4>
<!-- l. 1070 --><p class='noindent'>As we did in the previous milestone, generate the RD curves for a set of simulated
transmission contexts. Use the modules <span class='ectt-1000'>stereo_MST_coding{|_16|_32}.py</span>. As you
can see, they differs in how the transform has been implemented.
</p><!-- l. 1076 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>2.2   </span> <a id='x1-270002.2'></a>Determine the RD curves for the DWT</h4>
<!-- l. 1079 --><p class='noindent'>Rebuild the RD curves considering also the temporal decorrelation. Use
<span class='obeylines-h'><span class='verb'><span class='ectt-1000'>temporal_no_overlapped_DWT_coding.py</span></span></span>. Notice that the number of levels \(l\) of
the DWT (computed using <a href='https://pywavelets.readthedocs.io/en/latest/'>PyWavelets</a> <span class='cite'>[<a href='#Xlee2019pywavelets'>6</a>]</span>) can have a high impact on the
amount of energy concentration achieved by the DWT, and therefore, on the
efficiency of coding system. Show such impact. Experiment also with the wavelet
name.
</p><!-- l. 1089 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>2.3   </span> <a id='x1-280002.3'></a>Determine the RD curves for the overlapped DWT</h4>
<!-- l. 1092 --><p class='noindent'>Finally, redo the curves considering now the block overlapping
(<span class='obeylines-h'><span class='verb'><span class='ectt-1000'>temporal_overlapped_DWT_coding.py</span></span></span>). It is a good idea to put all the RD curves
together (in the same graph), to compare easely,
</p><!-- l. 1098 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>2.4   </span> <a id='x1-290002.4'></a>Answer these questions</h4>
<!-- l. 1101 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-29002x1'>Which has been the gain of the filters used in your experiments?
     </li>
<li class='enumerate' id='x1-29004x2'>Does the computation of the DWT using chunk overlapping increase the
     latency of the whole system? And the jitter? In which amount?
     </li>
                                                                  

                                                                  
<li class='enumerate' id='x1-29006x3'>Which other transform(s) are used in audio encoding systems (such as
     MP3) for exploiting the temporal redundancy? Enumerate the systems
     and the used transform(s).
</li></ol>
<!-- l. 1120 --><p class='noindent'>
</p>
   <h4 class='subsectionHead'><span class='titlemark'>2.5   </span> <a id='x1-300002.5'></a>Visualize</h4>
<!-- l. 1123 --><p class='noindent'>Visualize the effects (in the DWT domain) of quantization.
                                                                  

                                                                  
</p>
   <pre class='verbatim' id='verbatim-1'>
qjackctl &amp; # Select sampling frequency 44100 Hz
python temporal_overlapped_DWT_coding.py -i 6 -o 6 --show_stats -q 8192
# Connect the output of temporal_overlapped_DWT_coding.py to the input of dwt5.py
python dwt5.py -d 9
</pre>
<!-- l. 1129 --><p class='nopar'>
</p><!-- l. 1135 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>3   </span> <a id='x1-310003'></a>Deliverables</h3>
<!-- l. 1136 --><p class='noindent'>A description of the experiments and their results.
</p><!-- l. 1138 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>4   </span> <a id='x1-320004'></a>Resources</h3>
    <div class='thebibliography'>
    <p class='bibitem'><span class='biblabel'>
  [1]<span class='bibsp'>   </span></span><a id='Xnumpy'></a>S. Berg et al. <a href='https://numpy.org/'>The NumPy project</a>.
    </p>
    <p class='bibitem'><span class='biblabel'>
  [2]<span class='bibsp'>   </span></span><a id='Xbosi2003intro'></a>M. Bosi and R.E. Goldberd. <a href='https://last.hit.bme.hu/download/vidtechlab/fcc/literature/audio/audio_coding_standards_book.pdf'><span class='ecti-1000'>Introduction to Digital Audio Coding and
    </span><span class='ecti-1000'>Standards</span></a>. Kluwer Academic Publishers, 2003.
    </p>
    <p class='bibitem'><span class='biblabel'>
  [3]<span class='bibsp'>   </span></span><a id='Xburrus2013wavelets'></a>C.S.  Burrus,  R. Gopinath,  and  H. Guo.     <a href='https://cnx.org/contents/EQurkhlI@6.9:ZcNjPhDo@15/Preface'><span class='ecti-1000'>Wavelets  and  Wavelet
    </span><span class='ecti-1000'>Transforms</span></a>. Rice University, 2013.
    </p>
    <p class='bibitem'><span class='biblabel'>
  [4]<span class='bibsp'>   </span></span><a id='Xthinkstats'></a>A.B. Downey. <a href='https://greenteapress.com/thinkstats/thinkstats.pdf'><span class='ecti-1000'>Think Stats Probability and Statistics for Programmers</span></a>.
    O’Reilly, 2011.
                                                                  

                                                                  
    </p>
    <p class='bibitem'><span class='biblabel'>
  [5]<span class='bibsp'>   </span></span><a id='Xharris2020array'></a>C. R.  Harris,  K. J.  Millman,  S. J.  van der  Walt,  R. Gommers,
    P. Virtanen, D. Cournapeau, E. Wieser, J. Taylor, S. Berg, N. J. Smith,
    et al. <a href='https://www.nature.com/articles/s41586-020-2649-2'>Array programming with NumPy</a>. <span class='ecti-1000'>Nature</span>, 585(7825):357–362, 2020.
    </p>
    <p class='bibitem'><span class='biblabel'>
  [6]<span class='bibsp'>   </span></span><a id='Xlee2019pywavelets'></a>G. Lee, R. Gommers, F. Waselewski, K. Wohlfahrt, and A. O’Leary.
    PyWavelets:  A  Python  package  for  wavelet  analysis.   <span class='ecti-1000'>Journal of Open
    </span><span class='ecti-1000'>Source Software</span>, 4(36):1237, 2019.
    </p>
    <p class='bibitem'><span class='biblabel'>
  [7]<span class='bibsp'>   </span></span><a id='Xsayood2017introduction'></a>K. Sayood.  <a href='http://rahilshaikh.weebly.com/uploads/1/1/6/3/11635894/data_compression.pdf'><span class='ecti-1000'>Introduction to Data Compression</span></a>.  Morgan Kaufmann,
    2017.
    </p>
    <p class='bibitem'><span class='biblabel'>
  [8]<span class='bibsp'>   </span></span><a id='Xstrang4linear'></a>G. Strang.    <a href='https://ia802906.us.archive.org/18/items/StrangG.LinearAlgebraAndItsApplications45881001/%5BStrang_G.%5D_Linear_algebra_and_its_applications%284%29%5B5881001%5D.pdf'><span class='ecti-1000'>Linear  Algebra  and  Its  Applications</span></a>.    Belmont,  CA:
    Thomson, Brooks/Cole, 2006.
    </p>
    <p class='bibitem'><span class='biblabel'>
  [9]<span class='bibsp'>   </span></span><a id='Xsweldens1997building'></a>W. Sweldens and P. Schröder. <a href='http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.5600&amp;rep=rep1&amp;type=pdf'>Building Your Own Wavelets at Home</a>.
    <span class='ecti-1000'>Wavelets in Computer Graphics</span>, 1997.
    </p>
    <p class='bibitem'><span class='biblabel'>
 [10]<span class='bibsp'>   </span></span><a id='Xvetterli1995wavelets'></a>M. Vetterli  and  J. Kovačević.    <a href='http://waveletsandsubbandcoding.org/Repository/VetterliKovacevic95_Manuscript.pdf'><span class='ecti-1000'>Wavelets  and  Subband  Coding</span></a>.
    Prentice-hall, 1995.
    </p>
    <p class='bibitem'><span class='biblabel'>
 [11]<span class='bibsp'>   </span></span><a id='Xvetterli2014foundations'></a>M. Vetterli, J. Kovačević, and V.K. Goyal.  <a href='http://www.fourierandwavelets.org/FSP_v1.1_2014.pdf'><span class='ecti-1000'>Foundations of Signal
    </span><span class='ecti-1000'>Processing</span></a>. Cambridge University Press, 2014.
</p>
    </div>
<p><a id='Q1-1-38'></a></p>
                                                                  

                                                                  
   <div class='footnotes'><!-- l. 64 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>Adding two vectors in the plane produces a third one also in the plane; multiplying a vector
</span><span class='ecrm-0800'>by a real scalar produces a second vector also in the plane. These two ingrained facts make the real
</span><span class='ecrm-0800'>plane be a vector space. </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xvetterli2014foundations'><span class='ecrm-0800'>11</span></a><span class='ecrm-0800'>]</span></span></p>
<!-- l. 174 --><p class='indent'>     <span class='footnote-mark'><a href='#fn2x0-bk' id='fn2x0'><sup class='textsuperscript'>2</sup></a></span><span class='ecrm-0800'>The inner product between two vectors is in some sense a measure of how “similar” they are
</span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xsayood2017introduction'><span class='ecrm-0800'>7</span></a><span class='ecrm-0800'>]</span></span><span class='ecrm-0800'>. In fact, the dot product computes the norm (a measure of the distance between vectors). </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xvetterli2014foundations'><span class='ecrm-0800'>11</span></a><span class='ecrm-0800'>]</span></span>
<span class='ecrm-0800'>Notice also, that the inner product is </span><a href='https://math.stackexchange.com/questions/476738/difference-between-dot-product-and-inner-product'><span class='ecrm-0800'>also called</span></a> <span class='ecrm-0800'>the </span><a href='https://en.wikipedia.org/wiki/Dot_product'><span class='ecrm-0800'>dot product</span></a> <span class='ecrm-0800'>and the scalar product when we
</span><span class='ecrm-0800'>work with </span><a href='https://en.wikipedia.org/wiki/Real_number'><span class='ecrm-0800'>real</span></a> <span class='ecrm-0800'>signals. </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xvetterli2014foundations'><span class='ecrm-0800'>11</span></a><span class='ecrm-0800'>]</span></span></p>
<!-- l. 182 --><p class='indent'>     <span class='footnote-mark'><a href='#fn3x0-bk' id='fn3x0'><sup class='textsuperscript'>3</sup></a></span><span class='ecrm-0800'>When we are working with discrete signals, we usually talk about vectors instead of
</span><span class='ecrm-0800'>functions. These vectors are sampled versions of the corresponding functions, or as happen in our
</span><span class='ecrm-0800'>case, the </span><a href='https://en.wikipedia.org/wiki/Finite_impulse_response'><span class='ecrm-0800'>taps</span></a> <span class='ecrm-0800'>of the filters, each one representing a </span><a href='https://en.wikipedia.org/wiki/Basis_(linear_algebra)'><span class='ecrm-0800'>basis vectors</span></a><span class='ecrm-0800'>.</span></p>
<!-- l. 190 --><p class='indent'>     <span class='footnote-mark'><a href='#fn4x0-bk' id='fn4x0'><sup class='textsuperscript'>4</sup></a></span><span class='ecrm-0800'>If a set of vectors are linearly independent, then the set is called a basis for the subspace
</span><span class='ecrm-0800'>generated by linear combinations of this set. The basis set contains the smallest number of linearly
</span><span class='ecrm-0800'>independent vectors required to represent each element of the vector (sub)space. The number of
</span><span class='ecrm-0800'>basis vectors required to generate the space is called the dimension of the vector space </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xsayood2017introduction'><span class='ecrm-0800'>7</span></a><span class='ecrm-0800'>]</span></span><span class='ecrm-0800'>. In our
</span><span class='ecrm-0800'>case, for the MST, we have two basis vectors.</span></p>
<!-- l. 217 --><p class='indent'>     <span class='footnote-mark'><a href='#fn5x0-bk' id='fn5x0'><sup class='textsuperscript'>5</sup></a></span><span class='ecrm-0800'>In terms of orthogonality, this means that we cannot derive one from the other using the
</span><span class='ecrm-0800'>operations that define a vector space, and therefore the basis vectors can be a part a basis
</span><span class='ecrm-0800'>(set) </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xstrang4linear'><span class='ecrm-0800'>8</span></a><span class='ecrm-0800'>]</span></span><span class='ecrm-0800'>.</span></p>
<!-- l. 227 --><p class='indent'>     <span class='footnote-mark'><a href='#fn6x0-bk' id='fn6x0'><sup class='textsuperscript'>6</sup></a></span><span class='ecrm-0800'>Remember that for the MST a subband has only one coefficient. For other transforms,</span> \({\mathbf w}_i\) <span class='ecrm-0800'>can
</span><span class='ecrm-0800'>be made up of more than one coefficient and therefore, we would be speaking of the coefficients of
</span><span class='ecrm-0800'>the subband, instead of only one coefficient.</span></p>
<!-- l. 241 --><p class='indent'>     <span class='footnote-mark'><a href='#fn7x0-bk' id='fn7x0'><sup class='textsuperscript'>7</sup></a></span><span class='ecrm-0800'>The total </span><a href='https://en.wikipedia.org/wiki/Distortion'><span class='ecrm-0800'>distortion</span></a> <span class='ecrm-0800'>is the sum of the distortion contribution of each subband </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xsayood2017introduction'><span class='ecrm-0800'>7</span></a><span class='ecrm-0800'>]</span></span><span class='ecrm-0800'>.</span></p>
<!-- l. 283 --><p class='indent'>     <span class='footnote-mark'><a href='#fn8x0-bk' id='fn8x0'><sup class='textsuperscript'>8</sup></a></span><span class='ecrm-0800'>Notice, however, that this would solve the problem of controlling the bit-rate because using
</span><span class='ecrm-0800'>the RD curves we know how many bits will require each subband.</span></p>
<!-- l. 307 --><p class='indent'>     <span class='footnote-mark'><a href='#fn9x0-bk' id='fn9x0'><sup class='textsuperscript'>9</sup></a></span><span class='ecrm-0800'>Notice that the quantization error is generated in the transform domain and perceived in the
</span><span class='ecrm-0800'>signal domain after appliying the inverse transform.</span></p>
<!-- l. 317 --><p class='indent'>     <span class='footnote-mark'><a href='#fn10x0-bk' id='fn10x0'><sup class='textsuperscript'>10</sup></a></span><span class='ecrm-0800'>Notice that the important here is the relative gain of each subband. For example, if the gain
</span><span class='ecrm-0800'>of</span> \({\mathbf K}_0^{-1}\) <span class='ecrm-0800'>were</span> \(2\) <span class='ecrm-0800'>and the gain of</span> \({\mathbf K}_1^{-1}\) <span class='ecrm-0800'>were</span> \(1\)<span class='ecrm-0800'>, we should use</span> \(\Delta _1=2\Delta _0\) <span class='ecrm-0800'>to minimize the distortion, because a
</span><span class='ecrm-0800'>quantization error of a coefficient in</span> \(\mathbf {w}_0\) <span class='ecrm-0800'>is two times the quantization error of a coefficient in</span>
\(\mathbf {w}_0\)<span class='ecrm-0800'>.</span></p>
<!-- l. 336 --><p class='indent'>     <span class='footnote-mark'><a href='#fn11x0-bk' id='fn11x0'><sup class='textsuperscript'>11</sup></a></span><span class='ecrm-0800'>L</span>\(_2(f)\) <span class='ecrm-0800'>(where</span> \(f\) <span class='ecrm-0800'>is a function) is the set of all functions with finite energy and constitues a
</span><span class='ecrm-0800'>vector space </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xsayood2017introduction'><span class='ecrm-0800'>7</span></a><span class='ecrm-0800'>]</span></span><span class='ecrm-0800'>.</span> \(L_2({\mathbb R})\) <span class='ecrm-0800'>of simply</span> \(L_2\) <span class='ecrm-0800'>is the space of all functions</span> \(f(t)\) <span class='ecrm-0800'>with a well defined integral of
</span><span class='ecrm-0800'>the square of the modulus of the function. The</span> \(L\) <span class='ecrm-0800'>signifies a Lebesque integral, the “2”
</span><span class='ecrm-0800'>denotes the integral of the square of the modulus of the function, and</span> \(\mathbb R\) <span class='ecrm-0800'>states that the
</span><span class='ecrm-0800'>independent variable of integration is a number over the whole real line. For a function</span>
\(g(t)\) <span class='ecrm-0800'>to be a member of that space is denoted:</span> \(g\in L^2({\mathbb R})\) <span class='ecrm-0800'>or simply</span> \(g\in L^2\)<span class='ecrm-0800'> </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xburrus2013wavelets'><span class='ecrm-0800'>3</span></a><span class='ecrm-0800'>]</span></span><span class='ecrm-0800'>. The computation of the L</span>\(^2\)
<span class='ecrm-0800'>form is equivalent to compute the </span><a href='https://en.wikipedia.org/wiki/Euclidean_distance'><span class='ecrm-0800'>Euclidean distance</span></a> <span class='ecrm-0800'>in</span> \(N\)<span class='ecrm-0800'>-dimensional (in our case,</span> \(N=2\)<span class='ecrm-0800'>)</span>
<a href='https://en.wikipedia.org/wiki/Vector_space'><span class='ecrm-0800'>spaces</span></a><span class='ecrm-0800'>.</span></p>
<!-- l. 369 --><p class='indent'>     <span class='footnote-mark'><a href='#fn12x0-bk' id='fn12x0'><sup class='textsuperscript'>12</sup></a></span><span class='ecrm-0800'>Notice that this operation will “extract” the</span> \(i\)<span class='ecrm-0800'>-th column from</span> \({\mathbf K}^{-1}\) <span class='ecrm-0800'>that is equivalent
</span><span class='ecrm-0800'>to say that will “extract” the</span> \(i\)<span class='ecrm-0800'>-th row of</span> \(\mathbf K\)<span class='ecrm-0800'>,</span> \({\mathbf K}_i\) <span class='ecrm-0800'>(remember that for orthogonal transforms,</span>
\({\mathbf K}^{-1}={\mathbf K}^{\text T}\)<span class='ecrm-0800'>).</span></p>
<!-- l. 430 --><p class='indent'>     <span class='footnote-mark'><a href='#fn13x0-bk' id='fn13x0'><sup class='textsuperscript'>13</sup></a></span><span class='ecrm-0800'>Notice that, beacuse the MST and the transform used in this milestone are both lineal, the
</span><span class='ecrm-0800'>order in which the transforms are applied is irrelevant. For this reason, we could also have used
</span><span class='ecrm-0800'>the temporal transform inside of each channel of samples, and then, remove the spatial
</span><span class='ecrm-0800'>redundancy.</span></p>
<!-- l. 463 --><p class='indent'>     <span class='footnote-mark'><a href='#fn14x0-bk' id='fn14x0'><sup class='textsuperscript'>14</sup></a></span><span class='ecrm-0800'>Notice that is we dead-zone quantize a decomposition and most of the coefficients
</span><span class='ecrm-0800'>are close to zero, the information removed from the signal will be those with a smaller
</span><span class='ecrm-0800'>energy.</span></p>
<!-- l. 476 --><p class='indent'>     <span class='footnote-mark'><a href='#fn15x0-bk' id='fn15x0'><sup class='textsuperscript'>15</sup></a></span><a href='https://en.wikipedia.org/wiki/Sub-band_coding'><span class='ecrm-0800'>In signal processing, sub-band coding (SBC) is any form of transform coding that breaks a
</span><span class='ecrm-0800'>signal into a number of different frequency bands</span></a><span class='ecrm-0800'>.</span></p>
<!-- l. 479 --><p class='indent'>     <span class='footnote-mark'><a href='#fn16x0-bk' id='fn16x0'><sup class='textsuperscript'>16</sup></a></span><span class='ecrm-0800'>In theory, such rows could be any mathematical operation, not necessarily a
</span><span class='ecrm-0800'>filter.</span></p>
<!-- l. 514 --><p class='indent'>     <span class='footnote-mark'><a href='#fn17x0-bk' id='fn17x0'><sup class='textsuperscript'>17</sup></a></span><span class='ecrm-0800'>The response (in the frequency domain) of the filter to the </span><a href='https://en.wikipedia.org/?title=Unit_impulse&amp;redirect=no'><span class='ecrm-0800'>unit impulse</span></a><span class='ecrm-0800'>.</span></p>
<!-- l. 533 --><p class='indent'>     <span class='footnote-mark'><a href='#fn18x0-bk' id='fn18x0'><sup class='textsuperscript'>18</sup></a></span><span class='ecrm-0800'>Because the filters are not ideal, the bandwidth of the filtered signals</span> \({\mathbf w}_0\) <span class='ecrm-0800'>and</span> \({\mathbf w}_1\) <span class='ecrm-0800'>is bigger than
</span><span class='ecrm-0800'>half of the bandwidth of</span> \(\mathbf x\)<span class='ecrm-0800'>. Therefore, subsampling at a ratio of one of each two coefficients, we are
</span><span class='ecrm-0800'>generating aliasing. See the </span><a href='https://en.wikipedia.org/wiki/Nyquist-Shannon_sampling_theorem'><span class='ecrm-0800'>sampling theorem</span></a><span class='ecrm-0800'>.</span></p>
<!-- l. 555 --><p class='indent'>     <span class='footnote-mark'><a href='#fn19x0-bk' id='fn19x0'><sup class='textsuperscript'>19</sup></a></span><span class='ecrm-0800'>Notice that our matrix</span> \(K\) <span class='ecrm-0800'>would have</span> \(M\) <span class='ecrm-0800'>rows in this case, and also</span> \(M\) <span class='ecrm-0800'>columns, to satisfy that</span> \({\mathbf K}^{-1}={\mathbf K}^{\text T}\) <span class='ecrm-0800'>if
</span><span class='ecrm-0800'>we are implementing an orthogonal transform.</span></p>
<!-- l. 567 --><p class='indent'>     <span class='footnote-mark'><a href='#fn20x0-bk' id='fn20x0'><sup class='textsuperscript'>20</sup></a></span><span class='ecrm-0800'>You need to generate tonal sounds with different frequency and amplitudes.</span></p>
<!-- l. 571 --><p class='indent'>     <span class='footnote-mark'><a href='#fn21x0-bk' id='fn21x0'><sup class='textsuperscript'>21</sup></a></span><span class='ecrm-0800'>And also, we are more sensitive to low frequencies that to high ones.</span></p>
<!-- l. 644 --><p class='noindent'><span class='footnote-mark'><a href='#fn22x0-bk' id='fn22x0'><sup class='textsuperscript'>22</sup></a></span><span class='ecrm-0800'>Notice that in a typical cascade, the filters are always the same. Therefore, we only need
</span><span class='ecrm-0800'>to store in memory only a copy of each different filter.</span></p>
<!-- l. 717 --><p class='noindent'><span class='footnote-mark'><a href='#fn23x0-bk' id='fn23x0'><sup class='textsuperscript'>23</sup></a></span><span class='ecrm-0800'>The coefficient</span> \({\mathbf l}^l_0\) <span class='ecrm-0800'>is called the DC (Direct Current) coefficient, and the rest of</span> \(\mathbf h\) <span class='ecrm-0800'>coefficients are
</span><span class='ecrm-0800'>called AC (Alternating Current) coefficients.</span></p>
<!-- l. 765 --><p class='indent'>     <span class='footnote-mark'><a href='#fn24x0-bk' id='fn24x0'><sup class='textsuperscript'>24</sup></a></span><span class='ecrm-0800'>The response of a filter to the unit impulse characterize the filter because the output of the
</span><span class='ecrm-0800'>filter is the set of taps of the filter.</span></p>
<!-- l. 780 --><p class='indent'>     <span class='footnote-mark'><a href='#fn25x0-bk' id='fn25x0'><sup class='textsuperscript'>25</sup></a></span><span class='ecrm-0800'>The symmetry of the filters is important to produce the same type of artifacts in the
</span><span class='ecrm-0800'>boundaries of the signal and also to avoid the phase-shifting of the coefficients in the wavelet
</span><span class='ecrm-0800'>domain.</span></p><!-- l. 810 --><p class='indent'> <span class='footnote-mark'><a href='#fn26x0-bk' id='fn26x0'><sup class='textsuperscript'>26</sup></a></span><span class='ecrm-0800'>All transforms express a change of basis. When the basis are not orthogonal, the
</span><span class='ecrm-0800'>synthesis transform is not the transpose of the analysis transform. When the synthesis
</span><span class='ecrm-0800'>filters are orthogonal to their corresponding “</span><span class='ecti-0800'>dual</span><span class='ecrm-0800'>” analysis filters, the transform is said
</span><span class='ecrm-0800'>biorthogonal. </span><span class='cite'><span class='ecrm-0800'>[</span><a href='#Xvetterli2014foundations'><span class='ecrm-0800'>11</span></a><span class='ecrm-0800'>]</span></span></p>
<!-- l. 832 --><p class='indent'>     <span class='footnote-mark'><a href='#fn27x0-bk' id='fn27x0'><sup class='textsuperscript'>27</sup></a></span><span class='ecrm-0800'>Remember that if the QSS is higher, the quantization error is also higher. Therefore,
</span><span class='ecrm-0800'>those subbands with a higher amplification in the inverse transform should be quantized
</span><span class='ecrm-0800'>less.</span></p>                                                                                                                    </div>
                                                                  

                                                                  
 
</body> 
</html>